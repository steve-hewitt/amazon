{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.initializers import Constant\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for available GPU.\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loader functions\n",
    "# Inspiration: https://towardsdatascience.com/writing-custom-keras-generators-fe815d992c5a\n",
    "\n",
    "def get_input(path):\n",
    "    # Load array.\n",
    "    t_input = np.load(path)\n",
    "    # Pad to even number of pixels\n",
    "    t_input = np.pad(t_input, [(0,0),(0,1),(0,1)])\n",
    "    # Resize to include a channel dimension.\n",
    "    t_input = tf.expand_dims(t_input, axis = -1)\n",
    "    return t_input\n",
    "\n",
    "def get_output(path):\n",
    "    # Load array.\n",
    "    t_output = np.load(path)\n",
    "    # Pad to even number of pixels\n",
    "    #t_output = np.pad(t_output, [(0,0),(0,1),(0,1)])\n",
    "    # Resize to include a channel dimension.\n",
    "    #t_output = tf.expand_dims(t_output, axis = -1)\n",
    "    t_output = t_output.sum()\n",
    "    return t_output\n",
    "\n",
    "def data_generator(samples, batch_size = 64):\n",
    "    \n",
    "    while True:\n",
    "        # Select files (paths/indices) for the batch\n",
    "        batch_samples  = np.random.choice(a = samples.index, \n",
    "                                      size = batch_size)\n",
    "        batch_input  = []\n",
    "        batch_output = [] \n",
    "\n",
    "        # Read in each input, perform preprocessing and get labels\n",
    "        for sample in batch_samples:\n",
    "          input = get_input(samples.loc[sample].features)\n",
    "          output = get_output(samples.loc[sample].labels)\n",
    "\n",
    "          batch_input += [input]\n",
    "          batch_output += [output]\n",
    "        # Return a tuple of (input, output) to feed the network\n",
    "        batch_x = np.array(batch_input)\n",
    "        batch_y = np.array(batch_output)\n",
    "        \n",
    "        yield(batch_x, batch_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Lon</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Date</th>\n",
       "      <th>features</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>356962</td>\n",
       "      <td>-53.345535</td>\n",
       "      <td>-6.535028</td>\n",
       "      <td>2017-07-30</td>\n",
       "      <td>Sample_Dataset/train/features/356962.npy</td>\n",
       "      <td>Sample_Dataset/train/labels/356962.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>546517</td>\n",
       "      <td>-47.329685</td>\n",
       "      <td>-8.260676</td>\n",
       "      <td>2017-08-20</td>\n",
       "      <td>Sample_Dataset/train/features/546517.npy</td>\n",
       "      <td>Sample_Dataset/train/labels/546517.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>799359</td>\n",
       "      <td>-50.967861</td>\n",
       "      <td>-8.255809</td>\n",
       "      <td>2017-09-04</td>\n",
       "      <td>Sample_Dataset/train/features/799359.npy</td>\n",
       "      <td>Sample_Dataset/train/labels/799359.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>714590</td>\n",
       "      <td>-66.144379</td>\n",
       "      <td>-12.624272</td>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>Sample_Dataset/train/features/714590.npy</td>\n",
       "      <td>Sample_Dataset/train/labels/714590.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>240012</td>\n",
       "      <td>-48.350338</td>\n",
       "      <td>-11.838207</td>\n",
       "      <td>2017-07-14</td>\n",
       "      <td>Sample_Dataset/train/features/240012.npy</td>\n",
       "      <td>Sample_Dataset/train/labels/240012.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6491</th>\n",
       "      <td>173827</td>\n",
       "      <td>-54.326607</td>\n",
       "      <td>-11.983384</td>\n",
       "      <td>2017-06-20</td>\n",
       "      <td>Sample_Dataset/train/features/173827.npy</td>\n",
       "      <td>Sample_Dataset/train/labels/173827.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6492</th>\n",
       "      <td>1377764</td>\n",
       "      <td>-47.425915</td>\n",
       "      <td>-7.486426</td>\n",
       "      <td>2017-09-26</td>\n",
       "      <td>Sample_Dataset/train/features/1377764.npy</td>\n",
       "      <td>Sample_Dataset/train/labels/1377764.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6493</th>\n",
       "      <td>1444041</td>\n",
       "      <td>-65.172768</td>\n",
       "      <td>-10.714162</td>\n",
       "      <td>2017-10-02</td>\n",
       "      <td>Sample_Dataset/train/features/1444041.npy</td>\n",
       "      <td>Sample_Dataset/train/labels/1444041.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6494</th>\n",
       "      <td>644793</td>\n",
       "      <td>-53.701656</td>\n",
       "      <td>-15.977278</td>\n",
       "      <td>2017-08-27</td>\n",
       "      <td>Sample_Dataset/train/features/644793.npy</td>\n",
       "      <td>Sample_Dataset/train/labels/644793.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6495</th>\n",
       "      <td>1780752</td>\n",
       "      <td>-51.322929</td>\n",
       "      <td>-3.104345</td>\n",
       "      <td>2017-10-25</td>\n",
       "      <td>Sample_Dataset/train/features/1780752.npy</td>\n",
       "      <td>Sample_Dataset/train/labels/1780752.npy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6496 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0        Lon        Lat        Date  \\\n",
       "0         356962 -53.345535  -6.535028  2017-07-30   \n",
       "1         546517 -47.329685  -8.260676  2017-08-20   \n",
       "2         799359 -50.967861  -8.255809  2017-09-04   \n",
       "3         714590 -66.144379 -12.624272  2017-08-31   \n",
       "4         240012 -48.350338 -11.838207  2017-07-14   \n",
       "...          ...        ...        ...         ...   \n",
       "6491      173827 -54.326607 -11.983384  2017-06-20   \n",
       "6492     1377764 -47.425915  -7.486426  2017-09-26   \n",
       "6493     1444041 -65.172768 -10.714162  2017-10-02   \n",
       "6494      644793 -53.701656 -15.977278  2017-08-27   \n",
       "6495     1780752 -51.322929  -3.104345  2017-10-25   \n",
       "\n",
       "                                       features  \\\n",
       "0      Sample_Dataset/train/features/356962.npy   \n",
       "1      Sample_Dataset/train/features/546517.npy   \n",
       "2      Sample_Dataset/train/features/799359.npy   \n",
       "3      Sample_Dataset/train/features/714590.npy   \n",
       "4      Sample_Dataset/train/features/240012.npy   \n",
       "...                                         ...   \n",
       "6491   Sample_Dataset/train/features/173827.npy   \n",
       "6492  Sample_Dataset/train/features/1377764.npy   \n",
       "6493  Sample_Dataset/train/features/1444041.npy   \n",
       "6494   Sample_Dataset/train/features/644793.npy   \n",
       "6495  Sample_Dataset/train/features/1780752.npy   \n",
       "\n",
       "                                       labels  \n",
       "0      Sample_Dataset/train/labels/356962.npy  \n",
       "1      Sample_Dataset/train/labels/546517.npy  \n",
       "2      Sample_Dataset/train/labels/799359.npy  \n",
       "3      Sample_Dataset/train/labels/714590.npy  \n",
       "4      Sample_Dataset/train/labels/240012.npy  \n",
       "...                                       ...  \n",
       "6491   Sample_Dataset/train/labels/173827.npy  \n",
       "6492  Sample_Dataset/train/labels/1377764.npy  \n",
       "6493  Sample_Dataset/train/labels/1444041.npy  \n",
       "6494   Sample_Dataset/train/labels/644793.npy  \n",
       "6495  Sample_Dataset/train/labels/1780752.npy  \n",
       "\n",
       "[6496 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = pd.read_csv('Sample_Dataset/train/meta.csv')\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 31, 31)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get data from one chip\n",
    "sample_input = np.load('Sample_Dataset/train/features/3243.npy')\n",
    "\n",
    "# Pad to even number of pixels\n",
    "a = np.pad(sample_input, [(0,0),(0,1),(0,1)])\n",
    "# Resize to include a channel dimension.\n",
    "a = tf.expand_dims(a, axis = -1)\n",
    "# Resize to include a batch dimension.\n",
    "a = tf.expand_dims(a, axis = 0)\n",
    "# Display shape for verification.\n",
    "a.shape\n",
    "sample_input.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment with basic model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 4, 32, 32, 64])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = tf.keras.layers.Conv3D(64, (3,3,3), padding = 'same', activation='relu', bias_initializer=Constant(0.01), \n",
    "                           input_shape=(a))(a)\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 4, 32, 32, 64])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = tf.keras.layers.Conv3D(64, (3,3,3), padding = 'same', activation='relu', bias_initializer=Constant(0.01) \n",
    "                           )(b)\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 2, 16, 16, 64])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = layers.MaxPooling3D((2,2,2))(c)\n",
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 2, 16, 16, 128])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = tf.keras.layers.Conv3D(128, (3,3,3), padding = 'same', activation='relu')(d)\n",
    "e.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 2, 16, 16, 128])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = tf.keras.layers.Conv3D(128, (3,3,3), padding = 'same', activation='relu')(e)\n",
    "f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 2, 8, 8, 128])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = layers.MaxPooling3D((1,2,2))(f)\n",
    "g.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 2, 8, 8, 256])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = tf.keras.layers.Conv3D(256, (3,3,3), padding = 'same', activation='relu')(g)\n",
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 2, 8, 8, 256])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = tf.keras.layers.Conv3D(256, (3,3,3), padding = 'same', activation='relu')(h)\n",
    "i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 2, 4, 4, 256])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j = layers.MaxPooling3D((1,2,2))(i)\n",
    "j.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 2, 4, 4, 512])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = tf.keras.layers.Conv3D(512, (3,3,3), padding = 'same', activation='relu')(j)\n",
    "k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 2, 4, 4, 512])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = tf.keras.layers.Conv3D(512, (3,3,3), padding = 'same', activation='relu')(k)\n",
    "l.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 1, 1, 1, 512])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = layers.MaxPooling3D((2,4,4))(l)\n",
    "m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 512])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = layers.Flatten()(m)\n",
    "n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 64])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o = layers.Dense(64, activation='relu')(n)\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 32])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = layers.Dense(32, activation='relu')(o)\n",
    "p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 16])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = layers.Dense(16, activation='relu')(p)\n",
    "q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = layers.Dense(1, activation='linear')(q)\n",
    "r.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model assembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = layers.Input(shape=((4,32,32,1)))\n",
    "b = tf.keras.layers.Conv3D(32, (3,3,3), padding = 'same', activation='gelu', bias_initializer=Constant(0.01))(inputs)\n",
    "c = tf.keras.layers.Conv3D(32, (3,3,3), padding = 'same', activation='gelu', bias_initializer=Constant(0.01))(b)\n",
    "d = layers.MaxPooling3D((2,2,2))(c)\n",
    "d = layers.BatchNormalization()(d)\n",
    "d = layers.Dropout(0.3)(d)\n",
    "e = tf.keras.layers.Conv3D(64, (3,3,3), padding = 'same', activation='gelu')(d)\n",
    "f = tf.keras.layers.Conv3D(64, (3,3,3), padding = 'same', activation='gelu')(e)\n",
    "g = layers.MaxPooling3D((1,2,2))(f)\n",
    "g = layers.BatchNormalization()(g)\n",
    "g = layers.Dropout(0.3)(g)\n",
    "h = tf.keras.layers.Conv3D(128, (3,3,3), padding = 'same', activation='gelu')(g)\n",
    "i = tf.keras.layers.Conv3D(128, (3,3,3), padding = 'same', activation='gelu')(h)\n",
    "j = layers.MaxPooling3D((1,2,2))(i)\n",
    "j = layers.BatchNormalization()(j)\n",
    "j = layers.Dropout(0.3)(j)\n",
    "k = tf.keras.layers.Conv3D(256, (3,3,3), padding = 'same', activation='gelu')(j)\n",
    "l = tf.keras.layers.Conv3D(256, (3,3,3), padding = 'same', activation='gelu')(k)\n",
    "m = layers.MaxPooling3D((2,4,4))(l)\n",
    "m = layers.BatchNormalization()(m)\n",
    "m = layers.Dropout(0.3)(m)\n",
    "n = layers.Flatten()(m)\n",
    "o = layers.Dense(1024, activation='gelu')(n)\n",
    "o = layers.BatchNormalization()(o)\n",
    "o = layers.Dropout(0.3)(o)\n",
    "p = layers.Dense(1024, activation='gelu')(o)\n",
    "p = layers.BatchNormalization()(p)\n",
    "p = layers.Dropout(0.3)(p)\n",
    "q = layers.Dense(1024, activation='gelu')(p)\n",
    "q = layers.BatchNormalization()(q)\n",
    "q = layers.Dropout(0.3)(q)\n",
    "outputs = layers.Dense(1, activation='linear')(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_model = tf.keras.Model(inputs, outputs, name=\"3D_CNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 203ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify output shape.\n",
    "forecast_model.predict(a).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"3D_CNN\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 4, 32, 32, 1)]    0         \n",
      "                                                                 \n",
      " conv3d_8 (Conv3D)           (None, 4, 32, 32, 32)     896       \n",
      "                                                                 \n",
      " conv3d_9 (Conv3D)           (None, 4, 32, 32, 32)     27680     \n",
      "                                                                 \n",
      " max_pooling3d_4 (MaxPooling  (None, 2, 16, 16, 32)    0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 2, 16, 16, 32)    128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 2, 16, 16, 32)     0         \n",
      "                                                                 \n",
      " conv3d_10 (Conv3D)          (None, 2, 16, 16, 64)     55360     \n",
      "                                                                 \n",
      " conv3d_11 (Conv3D)          (None, 2, 16, 16, 64)     110656    \n",
      "                                                                 \n",
      " max_pooling3d_5 (MaxPooling  (None, 2, 8, 8, 64)      0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 2, 8, 8, 64)      256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 2, 8, 8, 64)       0         \n",
      "                                                                 \n",
      " conv3d_12 (Conv3D)          (None, 2, 8, 8, 128)      221312    \n",
      "                                                                 \n",
      " conv3d_13 (Conv3D)          (None, 2, 8, 8, 128)      442496    \n",
      "                                                                 \n",
      " max_pooling3d_6 (MaxPooling  (None, 2, 4, 4, 128)     0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 2, 4, 4, 128)     512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 2, 4, 4, 128)      0         \n",
      "                                                                 \n",
      " conv3d_14 (Conv3D)          (None, 2, 4, 4, 256)      884992    \n",
      "                                                                 \n",
      " conv3d_15 (Conv3D)          (None, 2, 4, 4, 256)      1769728   \n",
      "                                                                 \n",
      " max_pooling3d_7 (MaxPooling  (None, 1, 1, 1, 256)     0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 1, 1, 1, 256)     1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 1, 1, 1, 256)      0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1024)              263168    \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 1024)             4096      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1024)              1049600   \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 1024)             4096      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1024)              1049600   \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 1024)             4096      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 1025      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,890,721\n",
      "Trainable params: 5,883,617\n",
      "Non-trainable params: 7,104\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Display model details.\n",
    "forecast_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model.\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
    "forecast_model.compile(loss = tf.keras.losses.MeanSquaredError(), \n",
    "                       optimizer=opt, \n",
    "                       metrics = [tf.keras.metrics.MeanSquaredError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loaders.\n",
    "batch_size = 64\n",
    "meta_t = pd.read_csv('Sample_Dataset/train/meta.csv')\n",
    "meta_v = pd.read_csv('Sample_Dataset/val/meta.csv')\n",
    "t_gen = data_generator(meta_t, batch_size = batch_size)\n",
    "v_gen = data_generator(meta_v, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "101/101 [==============================] - 13s 112ms/step - loss: 443.9440 - mean_squared_error: 443.9440 - val_loss: 229.1947 - val_mean_squared_error: 229.1947\n",
      "Epoch 2/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 347.9968 - mean_squared_error: 347.9968 - val_loss: 210.2433 - val_mean_squared_error: 210.2433\n",
      "Epoch 3/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 427.1677 - mean_squared_error: 427.1677 - val_loss: 336.3713 - val_mean_squared_error: 336.3713\n",
      "Epoch 4/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 417.6918 - mean_squared_error: 417.6918 - val_loss: 385.0517 - val_mean_squared_error: 385.0517\n",
      "Epoch 5/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 444.8734 - mean_squared_error: 444.8734 - val_loss: 379.7544 - val_mean_squared_error: 379.7544\n",
      "Epoch 6/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 385.5735 - mean_squared_error: 385.5735 - val_loss: 306.2787 - val_mean_squared_error: 306.2787\n",
      "Epoch 7/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 404.7115 - mean_squared_error: 404.7115 - val_loss: 308.1142 - val_mean_squared_error: 308.1142\n",
      "Epoch 8/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 347.2272 - mean_squared_error: 347.2272 - val_loss: 332.0074 - val_mean_squared_error: 332.0074\n",
      "Epoch 9/500\n",
      "101/101 [==============================] - 11s 109ms/step - loss: 346.9218 - mean_squared_error: 346.9218 - val_loss: 325.0707 - val_mean_squared_error: 325.0707\n",
      "Epoch 10/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 362.3947 - mean_squared_error: 362.3947 - val_loss: 296.5299 - val_mean_squared_error: 296.5299\n",
      "Epoch 11/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 353.6969 - mean_squared_error: 353.6969 - val_loss: 251.3381 - val_mean_squared_error: 251.3381\n",
      "Epoch 12/500\n",
      "101/101 [==============================] - 11s 109ms/step - loss: 378.5653 - mean_squared_error: 378.5653 - val_loss: 393.3574 - val_mean_squared_error: 393.3574\n",
      "Epoch 13/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 401.1682 - mean_squared_error: 401.1682 - val_loss: 295.3297 - val_mean_squared_error: 295.3297\n",
      "Epoch 14/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 348.0027 - mean_squared_error: 348.0027 - val_loss: 302.6651 - val_mean_squared_error: 302.6651\n",
      "Epoch 15/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 399.6879 - mean_squared_error: 399.6879 - val_loss: 281.6732 - val_mean_squared_error: 281.6732\n",
      "Epoch 16/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 380.0587 - mean_squared_error: 380.0587 - val_loss: 265.4257 - val_mean_squared_error: 265.4257\n",
      "Epoch 17/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 351.3836 - mean_squared_error: 351.3836 - val_loss: 291.4984 - val_mean_squared_error: 291.4984\n",
      "Epoch 18/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 348.0626 - mean_squared_error: 348.0626 - val_loss: 205.8109 - val_mean_squared_error: 205.8109\n",
      "Epoch 19/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 384.1175 - mean_squared_error: 384.1175 - val_loss: 237.8139 - val_mean_squared_error: 237.8139\n",
      "Epoch 20/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 360.5671 - mean_squared_error: 360.5671 - val_loss: 256.8989 - val_mean_squared_error: 256.8989\n",
      "Epoch 21/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 326.5864 - mean_squared_error: 326.5864 - val_loss: 291.5588 - val_mean_squared_error: 291.5588\n",
      "Epoch 22/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 340.0606 - mean_squared_error: 340.0606 - val_loss: 342.0990 - val_mean_squared_error: 342.0990\n",
      "Epoch 23/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 394.3773 - mean_squared_error: 394.3773 - val_loss: 275.8851 - val_mean_squared_error: 275.8851\n",
      "Epoch 24/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 395.7506 - mean_squared_error: 395.7506 - val_loss: 280.3591 - val_mean_squared_error: 280.3591\n",
      "Epoch 25/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 358.8711 - mean_squared_error: 358.8711 - val_loss: 205.3298 - val_mean_squared_error: 205.3298\n",
      "Epoch 26/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 375.2261 - mean_squared_error: 375.2261 - val_loss: 273.4757 - val_mean_squared_error: 273.4757\n",
      "Epoch 27/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 364.7082 - mean_squared_error: 364.7082 - val_loss: 297.2886 - val_mean_squared_error: 297.2886\n",
      "Epoch 28/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 345.6735 - mean_squared_error: 345.6735 - val_loss: 381.0448 - val_mean_squared_error: 381.0448\n",
      "Epoch 29/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 361.4179 - mean_squared_error: 361.4179 - val_loss: 292.0507 - val_mean_squared_error: 292.0507\n",
      "Epoch 30/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 350.2277 - mean_squared_error: 350.2277 - val_loss: 273.8355 - val_mean_squared_error: 273.8355\n",
      "Epoch 31/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 334.8835 - mean_squared_error: 334.8835 - val_loss: 276.2785 - val_mean_squared_error: 276.2785\n",
      "Epoch 32/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 343.6089 - mean_squared_error: 343.6089 - val_loss: 232.7560 - val_mean_squared_error: 232.7560\n",
      "Epoch 33/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 356.8200 - mean_squared_error: 356.8200 - val_loss: 235.7420 - val_mean_squared_error: 235.7420\n",
      "Epoch 34/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 354.5652 - mean_squared_error: 354.5652 - val_loss: 261.1875 - val_mean_squared_error: 261.1875\n",
      "Epoch 35/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 375.1988 - mean_squared_error: 375.1988 - val_loss: 334.2806 - val_mean_squared_error: 334.2806\n",
      "Epoch 36/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 377.1826 - mean_squared_error: 377.1826 - val_loss: 240.2338 - val_mean_squared_error: 240.2338\n",
      "Epoch 37/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 340.6687 - mean_squared_error: 340.6687 - val_loss: 279.9088 - val_mean_squared_error: 279.9088\n",
      "Epoch 38/500\n",
      "101/101 [==============================] - 11s 109ms/step - loss: 338.3431 - mean_squared_error: 338.3431 - val_loss: 250.0022 - val_mean_squared_error: 250.0022\n",
      "Epoch 39/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 332.4491 - mean_squared_error: 332.4491 - val_loss: 222.1897 - val_mean_squared_error: 222.1897\n",
      "Epoch 40/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 348.9940 - mean_squared_error: 348.9940 - val_loss: 405.3832 - val_mean_squared_error: 405.3832\n",
      "Epoch 41/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 375.1710 - mean_squared_error: 375.1710 - val_loss: 249.6661 - val_mean_squared_error: 249.6661\n",
      "Epoch 42/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 357.7970 - mean_squared_error: 357.7970 - val_loss: 250.6522 - val_mean_squared_error: 250.6522\n",
      "Epoch 43/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 355.0414 - mean_squared_error: 355.0414 - val_loss: 215.1571 - val_mean_squared_error: 215.1571\n",
      "Epoch 44/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 330.4446 - mean_squared_error: 330.4446 - val_loss: 266.8476 - val_mean_squared_error: 266.8476\n",
      "Epoch 45/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 332.7917 - mean_squared_error: 332.7917 - val_loss: 202.9138 - val_mean_squared_error: 202.9138\n",
      "Epoch 46/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 292.2384 - mean_squared_error: 292.2384 - val_loss: 328.2793 - val_mean_squared_error: 328.2793\n",
      "Epoch 47/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 346.8400 - mean_squared_error: 346.8400 - val_loss: 322.2505 - val_mean_squared_error: 322.2505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 329.2280 - mean_squared_error: 329.2280 - val_loss: 204.8325 - val_mean_squared_error: 204.8325\n",
      "Epoch 49/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 322.1095 - mean_squared_error: 322.1095 - val_loss: 235.2814 - val_mean_squared_error: 235.2814\n",
      "Epoch 50/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 331.7734 - mean_squared_error: 331.7734 - val_loss: 257.7411 - val_mean_squared_error: 257.7411\n",
      "Epoch 51/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 327.0166 - mean_squared_error: 327.0166 - val_loss: 257.8368 - val_mean_squared_error: 257.8368\n",
      "Epoch 52/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 355.0177 - mean_squared_error: 355.0177 - val_loss: 257.7937 - val_mean_squared_error: 257.7937\n",
      "Epoch 53/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 314.6850 - mean_squared_error: 314.6850 - val_loss: 250.8866 - val_mean_squared_error: 250.8866\n",
      "Epoch 54/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 328.5389 - mean_squared_error: 328.5389 - val_loss: 345.5479 - val_mean_squared_error: 345.5479\n",
      "Epoch 55/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 334.3600 - mean_squared_error: 334.3600 - val_loss: 226.4647 - val_mean_squared_error: 226.4647\n",
      "Epoch 56/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 324.2780 - mean_squared_error: 324.2780 - val_loss: 332.7881 - val_mean_squared_error: 332.7881\n",
      "Epoch 57/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 323.2657 - mean_squared_error: 323.2657 - val_loss: 251.7337 - val_mean_squared_error: 251.7337\n",
      "Epoch 58/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 307.3058 - mean_squared_error: 307.3058 - val_loss: 182.2116 - val_mean_squared_error: 182.2116\n",
      "Epoch 59/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 385.4788 - mean_squared_error: 385.4788 - val_loss: 277.3723 - val_mean_squared_error: 277.3723\n",
      "Epoch 60/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 339.9554 - mean_squared_error: 339.9554 - val_loss: 212.9785 - val_mean_squared_error: 212.9785\n",
      "Epoch 61/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 347.4838 - mean_squared_error: 347.4838 - val_loss: 294.5382 - val_mean_squared_error: 294.5382\n",
      "Epoch 62/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 313.8574 - mean_squared_error: 313.8574 - val_loss: 233.9503 - val_mean_squared_error: 233.9503\n",
      "Epoch 63/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 348.8657 - mean_squared_error: 348.8657 - val_loss: 253.1357 - val_mean_squared_error: 253.1357\n",
      "Epoch 64/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 311.4564 - mean_squared_error: 311.4564 - val_loss: 316.7007 - val_mean_squared_error: 316.7007\n",
      "Epoch 65/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 332.3000 - mean_squared_error: 332.3000 - val_loss: 320.4996 - val_mean_squared_error: 320.4996\n",
      "Epoch 66/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 324.3155 - mean_squared_error: 324.3155 - val_loss: 271.1900 - val_mean_squared_error: 271.1900\n",
      "Epoch 67/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 355.3760 - mean_squared_error: 355.3760 - val_loss: 253.3315 - val_mean_squared_error: 253.3315\n",
      "Epoch 68/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 322.2406 - mean_squared_error: 322.2406 - val_loss: 294.3710 - val_mean_squared_error: 294.3710\n",
      "Epoch 69/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 302.3051 - mean_squared_error: 302.3051 - val_loss: 290.8223 - val_mean_squared_error: 290.8223\n",
      "Epoch 70/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 309.8556 - mean_squared_error: 309.8556 - val_loss: 250.0125 - val_mean_squared_error: 250.0125\n",
      "Epoch 71/500\n",
      "101/101 [==============================] - 11s 109ms/step - loss: 286.7325 - mean_squared_error: 286.7325 - val_loss: 302.8089 - val_mean_squared_error: 302.8089\n",
      "Epoch 72/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 288.9774 - mean_squared_error: 288.9774 - val_loss: 245.3940 - val_mean_squared_error: 245.3940\n",
      "Epoch 73/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 284.5294 - mean_squared_error: 284.5294 - val_loss: 223.2236 - val_mean_squared_error: 223.2236\n",
      "Epoch 74/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 301.5791 - mean_squared_error: 301.5791 - val_loss: 248.7134 - val_mean_squared_error: 248.7134\n",
      "Epoch 75/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 292.9106 - mean_squared_error: 292.9106 - val_loss: 272.0761 - val_mean_squared_error: 272.0761\n",
      "Epoch 76/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 302.9734 - mean_squared_error: 302.9734 - val_loss: 362.3784 - val_mean_squared_error: 362.3784\n",
      "Epoch 77/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 282.0434 - mean_squared_error: 282.0434 - val_loss: 282.5532 - val_mean_squared_error: 282.5532\n",
      "Epoch 78/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 315.0320 - mean_squared_error: 315.0320 - val_loss: 279.7590 - val_mean_squared_error: 279.7590\n",
      "Epoch 79/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 296.4449 - mean_squared_error: 296.4449 - val_loss: 251.0766 - val_mean_squared_error: 251.0766\n",
      "Epoch 80/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 345.7107 - mean_squared_error: 345.7107 - val_loss: 272.7526 - val_mean_squared_error: 272.7526\n",
      "Epoch 81/500\n",
      "101/101 [==============================] - 11s 109ms/step - loss: 270.6871 - mean_squared_error: 270.6871 - val_loss: 288.6232 - val_mean_squared_error: 288.6232\n",
      "Epoch 82/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 274.1179 - mean_squared_error: 274.1179 - val_loss: 269.3304 - val_mean_squared_error: 269.3304\n",
      "Epoch 83/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 277.5131 - mean_squared_error: 277.5131 - val_loss: 262.0129 - val_mean_squared_error: 262.0129\n",
      "Epoch 84/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 272.8347 - mean_squared_error: 272.8347 - val_loss: 270.6535 - val_mean_squared_error: 270.6535\n",
      "Epoch 85/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 312.7705 - mean_squared_error: 312.7705 - val_loss: 278.2946 - val_mean_squared_error: 278.2946\n",
      "Epoch 86/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 269.1300 - mean_squared_error: 269.1300 - val_loss: 258.5738 - val_mean_squared_error: 258.5738\n",
      "Epoch 87/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 272.6547 - mean_squared_error: 272.6547 - val_loss: 239.4232 - val_mean_squared_error: 239.4232\n",
      "Epoch 88/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 276.6190 - mean_squared_error: 276.6190 - val_loss: 255.5460 - val_mean_squared_error: 255.5460\n",
      "Epoch 89/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 273.6331 - mean_squared_error: 273.6331 - val_loss: 197.8256 - val_mean_squared_error: 197.8256\n",
      "Epoch 90/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 313.1031 - mean_squared_error: 313.1031 - val_loss: 293.9923 - val_mean_squared_error: 293.9923\n",
      "Epoch 91/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 288.8502 - mean_squared_error: 288.8502 - val_loss: 235.7853 - val_mean_squared_error: 235.7853\n",
      "Epoch 92/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 265.5991 - mean_squared_error: 265.5991 - val_loss: 244.8085 - val_mean_squared_error: 244.8085\n",
      "Epoch 93/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 261.5245 - mean_squared_error: 261.5245 - val_loss: 318.7416 - val_mean_squared_error: 318.7416\n",
      "Epoch 94/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 300.3551 - mean_squared_error: 300.3551 - val_loss: 265.6727 - val_mean_squared_error: 265.6727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 305.6370 - mean_squared_error: 305.6370 - val_loss: 237.7872 - val_mean_squared_error: 237.7872\n",
      "Epoch 96/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 256.2441 - mean_squared_error: 256.2441 - val_loss: 325.1250 - val_mean_squared_error: 325.1250\n",
      "Epoch 97/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 244.5465 - mean_squared_error: 244.5465 - val_loss: 267.6264 - val_mean_squared_error: 267.6264\n",
      "Epoch 98/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 251.6413 - mean_squared_error: 251.6413 - val_loss: 399.6370 - val_mean_squared_error: 399.6370\n",
      "Epoch 99/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 271.3947 - mean_squared_error: 271.3947 - val_loss: 258.0857 - val_mean_squared_error: 258.0857\n",
      "Epoch 100/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 243.1299 - mean_squared_error: 243.1299 - val_loss: 258.5257 - val_mean_squared_error: 258.5257\n",
      "Epoch 101/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 238.6285 - mean_squared_error: 238.6285 - val_loss: 365.4778 - val_mean_squared_error: 365.4778\n",
      "Epoch 102/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 242.7382 - mean_squared_error: 242.7382 - val_loss: 237.4729 - val_mean_squared_error: 237.4729\n",
      "Epoch 103/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 249.2013 - mean_squared_error: 249.2013 - val_loss: 245.1012 - val_mean_squared_error: 245.1012\n",
      "Epoch 104/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 227.9606 - mean_squared_error: 227.9606 - val_loss: 352.0673 - val_mean_squared_error: 352.0673\n",
      "Epoch 105/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 225.3810 - mean_squared_error: 225.3810 - val_loss: 225.5457 - val_mean_squared_error: 225.5457\n",
      "Epoch 106/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 249.2534 - mean_squared_error: 249.2534 - val_loss: 363.5671 - val_mean_squared_error: 363.5671\n",
      "Epoch 107/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 223.8000 - mean_squared_error: 223.8000 - val_loss: 218.3535 - val_mean_squared_error: 218.3535\n",
      "Epoch 108/500\n",
      "101/101 [==============================] - 11s 109ms/step - loss: 239.4851 - mean_squared_error: 239.4851 - val_loss: 308.9008 - val_mean_squared_error: 308.9008\n",
      "Epoch 109/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 242.4294 - mean_squared_error: 242.4294 - val_loss: 353.1657 - val_mean_squared_error: 353.1657\n",
      "Epoch 110/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 235.6424 - mean_squared_error: 235.6424 - val_loss: 311.0020 - val_mean_squared_error: 311.0020\n",
      "Epoch 111/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 227.3456 - mean_squared_error: 227.3456 - val_loss: 268.5728 - val_mean_squared_error: 268.5728\n",
      "Epoch 112/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 237.0026 - mean_squared_error: 237.0026 - val_loss: 237.9362 - val_mean_squared_error: 237.9362\n",
      "Epoch 113/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 220.0406 - mean_squared_error: 220.0406 - val_loss: 350.5789 - val_mean_squared_error: 350.5789\n",
      "Epoch 114/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 228.0899 - mean_squared_error: 228.0899 - val_loss: 322.7369 - val_mean_squared_error: 322.7369\n",
      "Epoch 115/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 207.4497 - mean_squared_error: 207.4497 - val_loss: 245.4647 - val_mean_squared_error: 245.4647\n",
      "Epoch 116/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 233.4966 - mean_squared_error: 233.4966 - val_loss: 263.5982 - val_mean_squared_error: 263.5982\n",
      "Epoch 117/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 210.9734 - mean_squared_error: 210.9734 - val_loss: 312.4647 - val_mean_squared_error: 312.4647\n",
      "Epoch 118/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 233.3496 - mean_squared_error: 233.3496 - val_loss: 270.7543 - val_mean_squared_error: 270.7543\n",
      "Epoch 119/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 219.0576 - mean_squared_error: 219.0576 - val_loss: 311.1069 - val_mean_squared_error: 311.1069\n",
      "Epoch 120/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 222.7200 - mean_squared_error: 222.7200 - val_loss: 410.8492 - val_mean_squared_error: 410.8492\n",
      "Epoch 121/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 217.4768 - mean_squared_error: 217.4768 - val_loss: 330.7348 - val_mean_squared_error: 330.7348\n",
      "Epoch 122/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 213.9538 - mean_squared_error: 213.9538 - val_loss: 362.0957 - val_mean_squared_error: 362.0957\n",
      "Epoch 123/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 212.8914 - mean_squared_error: 212.8914 - val_loss: 250.0608 - val_mean_squared_error: 250.0608\n",
      "Epoch 124/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 207.2539 - mean_squared_error: 207.2539 - val_loss: 365.5706 - val_mean_squared_error: 365.5706\n",
      "Epoch 125/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 189.6791 - mean_squared_error: 189.6791 - val_loss: 301.0334 - val_mean_squared_error: 301.0334\n",
      "Epoch 126/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 222.3989 - mean_squared_error: 222.3989 - val_loss: 473.8143 - val_mean_squared_error: 473.8143\n",
      "Epoch 127/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 204.0447 - mean_squared_error: 204.0447 - val_loss: 291.0705 - val_mean_squared_error: 291.0705\n",
      "Epoch 128/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 208.9634 - mean_squared_error: 208.9634 - val_loss: 311.7702 - val_mean_squared_error: 311.7702\n",
      "Epoch 129/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 201.2220 - mean_squared_error: 201.2220 - val_loss: 291.9325 - val_mean_squared_error: 291.9325\n",
      "Epoch 130/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 203.5314 - mean_squared_error: 203.5314 - val_loss: 393.5983 - val_mean_squared_error: 393.5983\n",
      "Epoch 131/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 200.7476 - mean_squared_error: 200.7476 - val_loss: 351.0681 - val_mean_squared_error: 351.0681\n",
      "Epoch 132/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 233.9666 - mean_squared_error: 233.9666 - val_loss: 270.5158 - val_mean_squared_error: 270.5158\n",
      "Epoch 133/500\n",
      "101/101 [==============================] - 11s 114ms/step - loss: 186.0542 - mean_squared_error: 186.0542 - val_loss: 245.3864 - val_mean_squared_error: 245.3864\n",
      "Epoch 134/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 199.3789 - mean_squared_error: 199.3789 - val_loss: 235.3849 - val_mean_squared_error: 235.3849\n",
      "Epoch 135/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 183.9692 - mean_squared_error: 183.9692 - val_loss: 444.1501 - val_mean_squared_error: 444.1501\n",
      "Epoch 136/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 187.6730 - mean_squared_error: 187.6730 - val_loss: 321.3792 - val_mean_squared_error: 321.3792\n",
      "Epoch 137/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 193.4178 - mean_squared_error: 193.4178 - val_loss: 398.4056 - val_mean_squared_error: 398.4056\n",
      "Epoch 138/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 181.1034 - mean_squared_error: 181.1034 - val_loss: 223.4538 - val_mean_squared_error: 223.4538\n",
      "Epoch 139/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 175.0868 - mean_squared_error: 175.0868 - val_loss: 294.6429 - val_mean_squared_error: 294.6429\n",
      "Epoch 140/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 196.8738 - mean_squared_error: 196.8738 - val_loss: 219.4099 - val_mean_squared_error: 219.4099\n",
      "Epoch 141/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 194.9645 - mean_squared_error: 194.9645 - val_loss: 314.2408 - val_mean_squared_error: 314.2408\n",
      "Epoch 142/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 180.8050 - mean_squared_error: 180.8050 - val_loss: 236.4442 - val_mean_squared_error: 236.4442\n",
      "Epoch 143/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 177.7183 - mean_squared_error: 177.7183 - val_loss: 237.6627 - val_mean_squared_error: 237.6627\n",
      "Epoch 144/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 166.6367 - mean_squared_error: 166.6367 - val_loss: 250.0160 - val_mean_squared_error: 250.0160\n",
      "Epoch 145/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 172.8092 - mean_squared_error: 172.8092 - val_loss: 233.6148 - val_mean_squared_error: 233.6148\n",
      "Epoch 146/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 180.5917 - mean_squared_error: 180.5917 - val_loss: 339.0009 - val_mean_squared_error: 339.0009\n",
      "Epoch 147/500\n",
      "101/101 [==============================] - 11s 109ms/step - loss: 168.1853 - mean_squared_error: 168.1853 - val_loss: 274.2451 - val_mean_squared_error: 274.2451\n",
      "Epoch 148/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 186.8968 - mean_squared_error: 186.8968 - val_loss: 353.0522 - val_mean_squared_error: 353.0522\n",
      "Epoch 149/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 179.0717 - mean_squared_error: 179.0717 - val_loss: 315.0897 - val_mean_squared_error: 315.0897\n",
      "Epoch 150/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 173.3261 - mean_squared_error: 173.3261 - val_loss: 320.8435 - val_mean_squared_error: 320.8435\n",
      "Epoch 151/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 169.8907 - mean_squared_error: 169.8907 - val_loss: 259.9315 - val_mean_squared_error: 259.9315\n",
      "Epoch 152/500\n",
      "101/101 [==============================] - 12s 114ms/step - loss: 181.3963 - mean_squared_error: 181.3963 - val_loss: 279.8411 - val_mean_squared_error: 279.8411\n",
      "Epoch 153/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 172.6338 - mean_squared_error: 172.6338 - val_loss: 246.1394 - val_mean_squared_error: 246.1394\n",
      "Epoch 154/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 172.5997 - mean_squared_error: 172.5997 - val_loss: 243.9870 - val_mean_squared_error: 243.9870\n",
      "Epoch 155/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 164.9214 - mean_squared_error: 164.9214 - val_loss: 365.8860 - val_mean_squared_error: 365.8860\n",
      "Epoch 156/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 171.5863 - mean_squared_error: 171.5863 - val_loss: 212.0539 - val_mean_squared_error: 212.0539\n",
      "Epoch 157/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 164.6784 - mean_squared_error: 164.6784 - val_loss: 394.5208 - val_mean_squared_error: 394.5208\n",
      "Epoch 158/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 171.3647 - mean_squared_error: 171.3647 - val_loss: 231.8977 - val_mean_squared_error: 231.8977\n",
      "Epoch 159/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 176.4670 - mean_squared_error: 176.4670 - val_loss: 291.9954 - val_mean_squared_error: 291.9954\n",
      "Epoch 160/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 157.8633 - mean_squared_error: 157.8633 - val_loss: 330.6901 - val_mean_squared_error: 330.6901\n",
      "Epoch 161/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 150.9396 - mean_squared_error: 150.9396 - val_loss: 232.1692 - val_mean_squared_error: 232.1692\n",
      "Epoch 162/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 165.3460 - mean_squared_error: 165.3460 - val_loss: 297.0192 - val_mean_squared_error: 297.0192\n",
      "Epoch 163/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 155.7626 - mean_squared_error: 155.7626 - val_loss: 237.0743 - val_mean_squared_error: 237.0743\n",
      "Epoch 164/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 157.4781 - mean_squared_error: 157.4781 - val_loss: 230.9900 - val_mean_squared_error: 230.9900\n",
      "Epoch 165/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 163.6675 - mean_squared_error: 163.6675 - val_loss: 237.7473 - val_mean_squared_error: 237.7473\n",
      "Epoch 166/500\n",
      "101/101 [==============================] - 12s 115ms/step - loss: 165.5482 - mean_squared_error: 165.5482 - val_loss: 224.9083 - val_mean_squared_error: 224.9083\n",
      "Epoch 167/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 175.2382 - mean_squared_error: 175.2382 - val_loss: 332.0178 - val_mean_squared_error: 332.0178\n",
      "Epoch 168/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 155.6922 - mean_squared_error: 155.6922 - val_loss: 271.0348 - val_mean_squared_error: 271.0348\n",
      "Epoch 169/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 163.7319 - mean_squared_error: 163.7319 - val_loss: 240.0587 - val_mean_squared_error: 240.0587\n",
      "Epoch 170/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 149.9105 - mean_squared_error: 149.9105 - val_loss: 217.0587 - val_mean_squared_error: 217.0587\n",
      "Epoch 171/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 171.9949 - mean_squared_error: 171.9949 - val_loss: 261.4580 - val_mean_squared_error: 261.4580\n",
      "Epoch 172/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 166.7789 - mean_squared_error: 166.7789 - val_loss: 346.0805 - val_mean_squared_error: 346.0805\n",
      "Epoch 173/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 149.5282 - mean_squared_error: 149.5282 - val_loss: 256.9655 - val_mean_squared_error: 256.9655\n",
      "Epoch 174/500\n",
      "101/101 [==============================] - 11s 114ms/step - loss: 135.4508 - mean_squared_error: 135.4508 - val_loss: 297.5005 - val_mean_squared_error: 297.5005\n",
      "Epoch 175/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 155.4573 - mean_squared_error: 155.4573 - val_loss: 372.2353 - val_mean_squared_error: 372.2353\n",
      "Epoch 176/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 147.6562 - mean_squared_error: 147.6562 - val_loss: 252.3819 - val_mean_squared_error: 252.3819\n",
      "Epoch 177/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 144.6343 - mean_squared_error: 144.6343 - val_loss: 307.1911 - val_mean_squared_error: 307.1911\n",
      "Epoch 178/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 168.2631 - mean_squared_error: 168.2631 - val_loss: 234.8266 - val_mean_squared_error: 234.8266\n",
      "Epoch 179/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 151.2234 - mean_squared_error: 151.2234 - val_loss: 245.3020 - val_mean_squared_error: 245.3020\n",
      "Epoch 180/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 165.7890 - mean_squared_error: 165.7890 - val_loss: 349.6048 - val_mean_squared_error: 349.6048\n",
      "Epoch 181/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 149.6040 - mean_squared_error: 149.6040 - val_loss: 215.8540 - val_mean_squared_error: 215.8540\n",
      "Epoch 182/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 158.6846 - mean_squared_error: 158.6846 - val_loss: 265.6068 - val_mean_squared_error: 265.6068\n",
      "Epoch 183/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 159.6807 - mean_squared_error: 159.6807 - val_loss: 350.8416 - val_mean_squared_error: 350.8416\n",
      "Epoch 184/500\n",
      "101/101 [==============================] - 11s 114ms/step - loss: 151.7338 - mean_squared_error: 151.7338 - val_loss: 276.7179 - val_mean_squared_error: 276.7179\n",
      "Epoch 185/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 146.5217 - mean_squared_error: 146.5217 - val_loss: 269.8975 - val_mean_squared_error: 269.8975\n",
      "Epoch 186/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 150.8047 - mean_squared_error: 150.8047 - val_loss: 307.7319 - val_mean_squared_error: 307.7319\n",
      "Epoch 187/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101/101 [==============================] - 11s 112ms/step - loss: 136.7203 - mean_squared_error: 136.7203 - val_loss: 402.0381 - val_mean_squared_error: 402.0381\n",
      "Epoch 188/500\n",
      "101/101 [==============================] - 11s 114ms/step - loss: 139.9059 - mean_squared_error: 139.9059 - val_loss: 217.8896 - val_mean_squared_error: 217.8896\n",
      "Epoch 189/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 148.8888 - mean_squared_error: 148.8888 - val_loss: 194.1525 - val_mean_squared_error: 194.1525\n",
      "Epoch 190/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 140.2042 - mean_squared_error: 140.2042 - val_loss: 318.3857 - val_mean_squared_error: 318.3857\n",
      "Epoch 191/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 151.4960 - mean_squared_error: 151.4960 - val_loss: 281.1996 - val_mean_squared_error: 281.1996\n",
      "Epoch 192/500\n",
      "101/101 [==============================] - 11s 114ms/step - loss: 145.8223 - mean_squared_error: 145.8223 - val_loss: 234.3902 - val_mean_squared_error: 234.3902\n",
      "Epoch 193/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 147.8786 - mean_squared_error: 147.8786 - val_loss: 296.9202 - val_mean_squared_error: 296.9202\n",
      "Epoch 194/500\n",
      "101/101 [==============================] - 11s 114ms/step - loss: 152.9418 - mean_squared_error: 152.9418 - val_loss: 253.2771 - val_mean_squared_error: 253.2771\n",
      "Epoch 195/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 136.8812 - mean_squared_error: 136.8812 - val_loss: 253.8920 - val_mean_squared_error: 253.8920\n",
      "Epoch 196/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 141.5838 - mean_squared_error: 141.5838 - val_loss: 281.6661 - val_mean_squared_error: 281.6661\n",
      "Epoch 197/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 127.9094 - mean_squared_error: 127.9094 - val_loss: 182.4062 - val_mean_squared_error: 182.4062\n",
      "Epoch 198/500\n",
      "101/101 [==============================] - 11s 114ms/step - loss: 136.1500 - mean_squared_error: 136.1500 - val_loss: 308.6484 - val_mean_squared_error: 308.6484\n",
      "Epoch 199/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 128.3255 - mean_squared_error: 128.3255 - val_loss: 194.4087 - val_mean_squared_error: 194.4087\n",
      "Epoch 200/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 137.5236 - mean_squared_error: 137.5236 - val_loss: 284.1181 - val_mean_squared_error: 284.1181\n",
      "Epoch 201/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 139.1434 - mean_squared_error: 139.1434 - val_loss: 321.0918 - val_mean_squared_error: 321.0918\n",
      "Epoch 202/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 142.1484 - mean_squared_error: 142.1484 - val_loss: 228.0383 - val_mean_squared_error: 228.0383\n",
      "Epoch 203/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 143.2269 - mean_squared_error: 143.2269 - val_loss: 275.9353 - val_mean_squared_error: 275.9353\n",
      "Epoch 204/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 131.7796 - mean_squared_error: 131.7796 - val_loss: 304.1626 - val_mean_squared_error: 304.1626\n",
      "Epoch 205/500\n",
      "101/101 [==============================] - 11s 114ms/step - loss: 117.4836 - mean_squared_error: 117.4836 - val_loss: 244.4604 - val_mean_squared_error: 244.4604\n",
      "Epoch 206/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 126.9851 - mean_squared_error: 126.9851 - val_loss: 196.8951 - val_mean_squared_error: 196.8951\n",
      "Epoch 207/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 137.3153 - mean_squared_error: 137.3153 - val_loss: 329.2449 - val_mean_squared_error: 329.2449\n",
      "Epoch 208/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 136.0032 - mean_squared_error: 136.0032 - val_loss: 213.5729 - val_mean_squared_error: 213.5729\n",
      "Epoch 209/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 126.4821 - mean_squared_error: 126.4821 - val_loss: 262.5977 - val_mean_squared_error: 262.5977\n",
      "Epoch 210/500\n",
      "101/101 [==============================] - 12s 116ms/step - loss: 130.3432 - mean_squared_error: 130.3432 - val_loss: 348.8348 - val_mean_squared_error: 348.8348\n",
      "Epoch 211/500\n",
      "101/101 [==============================] - 12s 116ms/step - loss: 117.2536 - mean_squared_error: 117.2536 - val_loss: 246.5724 - val_mean_squared_error: 246.5724\n",
      "Epoch 212/500\n",
      "101/101 [==============================] - 11s 114ms/step - loss: 123.1041 - mean_squared_error: 123.1041 - val_loss: 267.5050 - val_mean_squared_error: 267.5050\n",
      "Epoch 213/500\n",
      "101/101 [==============================] - 12s 115ms/step - loss: 124.2388 - mean_squared_error: 124.2388 - val_loss: 239.3138 - val_mean_squared_error: 239.3138\n",
      "Epoch 214/500\n",
      "101/101 [==============================] - 11s 114ms/step - loss: 143.2194 - mean_squared_error: 143.2194 - val_loss: 234.0491 - val_mean_squared_error: 234.0491\n",
      "Epoch 215/500\n",
      "101/101 [==============================] - 11s 114ms/step - loss: 121.3275 - mean_squared_error: 121.3275 - val_loss: 233.4771 - val_mean_squared_error: 233.4771\n",
      "Epoch 216/500\n",
      "101/101 [==============================] - 11s 114ms/step - loss: 118.6875 - mean_squared_error: 118.6875 - val_loss: 277.4407 - val_mean_squared_error: 277.4407\n",
      "Epoch 217/500\n",
      "101/101 [==============================] - 11s 114ms/step - loss: 124.3213 - mean_squared_error: 124.3213 - val_loss: 283.4691 - val_mean_squared_error: 283.4691\n",
      "Epoch 218/500\n",
      "101/101 [==============================] - 12s 114ms/step - loss: 117.7563 - mean_squared_error: 117.7563 - val_loss: 267.9116 - val_mean_squared_error: 267.9116\n",
      "Epoch 219/500\n",
      "101/101 [==============================] - 11s 114ms/step - loss: 138.0466 - mean_squared_error: 138.0466 - val_loss: 188.7117 - val_mean_squared_error: 188.7117\n",
      "Epoch 220/500\n",
      "101/101 [==============================] - 12s 115ms/step - loss: 132.0457 - mean_squared_error: 132.0457 - val_loss: 284.3984 - val_mean_squared_error: 284.3984\n",
      "Epoch 221/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 118.8854 - mean_squared_error: 118.8854 - val_loss: 306.0324 - val_mean_squared_error: 306.0324\n",
      "Epoch 222/500\n",
      "101/101 [==============================] - 11s 114ms/step - loss: 119.3789 - mean_squared_error: 119.3789 - val_loss: 318.3736 - val_mean_squared_error: 318.3736\n",
      "Epoch 223/500\n",
      "101/101 [==============================] - 12s 115ms/step - loss: 123.8563 - mean_squared_error: 123.8563 - val_loss: 204.3876 - val_mean_squared_error: 204.3876\n",
      "Epoch 224/500\n",
      "101/101 [==============================] - 11s 114ms/step - loss: 125.4266 - mean_squared_error: 125.4266 - val_loss: 280.9002 - val_mean_squared_error: 280.9002\n",
      "Epoch 225/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 121.1401 - mean_squared_error: 121.1401 - val_loss: 226.2854 - val_mean_squared_error: 226.2854\n",
      "Epoch 226/500\n",
      "101/101 [==============================] - 11s 114ms/step - loss: 122.4001 - mean_squared_error: 122.4001 - val_loss: 213.1448 - val_mean_squared_error: 213.1448\n",
      "Epoch 227/500\n",
      "101/101 [==============================] - 12s 115ms/step - loss: 119.6778 - mean_squared_error: 119.6778 - val_loss: 213.1166 - val_mean_squared_error: 213.1166\n",
      "Epoch 228/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 116.6481 - mean_squared_error: 116.6481 - val_loss: 164.3051 - val_mean_squared_error: 164.3051\n",
      "Epoch 229/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 131.4545 - mean_squared_error: 131.4545 - val_loss: 189.4728 - val_mean_squared_error: 189.4728\n",
      "Epoch 230/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 120.9905 - mean_squared_error: 120.9905 - val_loss: 347.5965 - val_mean_squared_error: 347.5965\n",
      "Epoch 231/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 125.1466 - mean_squared_error: 125.1466 - val_loss: 247.8296 - val_mean_squared_error: 247.8296\n",
      "Epoch 232/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 129.2593 - mean_squared_error: 129.2593 - val_loss: 207.9090 - val_mean_squared_error: 207.9090\n",
      "Epoch 233/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 116.4462 - mean_squared_error: 116.4462 - val_loss: 201.9593 - val_mean_squared_error: 201.9593\n",
      "Epoch 234/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 115.4336 - mean_squared_error: 115.4336 - val_loss: 296.8839 - val_mean_squared_error: 296.8839\n",
      "Epoch 235/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 117.0851 - mean_squared_error: 117.0851 - val_loss: 224.9159 - val_mean_squared_error: 224.9159\n",
      "Epoch 236/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 115.6114 - mean_squared_error: 115.6114 - val_loss: 211.1138 - val_mean_squared_error: 211.1138\n",
      "Epoch 237/500\n",
      "101/101 [==============================] - 11s 114ms/step - loss: 120.8435 - mean_squared_error: 120.8435 - val_loss: 256.4252 - val_mean_squared_error: 256.4252\n",
      "Epoch 238/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 115.7868 - mean_squared_error: 115.7868 - val_loss: 227.5335 - val_mean_squared_error: 227.5335\n",
      "Epoch 239/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 111.0892 - mean_squared_error: 111.0892 - val_loss: 300.5440 - val_mean_squared_error: 300.5440\n",
      "Epoch 240/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 121.5109 - mean_squared_error: 121.5109 - val_loss: 223.0061 - val_mean_squared_error: 223.0061\n",
      "Epoch 241/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 120.3353 - mean_squared_error: 120.3353 - val_loss: 178.7990 - val_mean_squared_error: 178.7990\n",
      "Epoch 242/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 114.2613 - mean_squared_error: 114.2613 - val_loss: 245.7710 - val_mean_squared_error: 245.7710\n",
      "Epoch 243/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 117.3461 - mean_squared_error: 117.3461 - val_loss: 203.1822 - val_mean_squared_error: 203.1822\n",
      "Epoch 244/500\n",
      "101/101 [==============================] - 11s 114ms/step - loss: 110.9321 - mean_squared_error: 110.9321 - val_loss: 224.3761 - val_mean_squared_error: 224.3761\n",
      "Epoch 245/500\n",
      "101/101 [==============================] - 11s 114ms/step - loss: 115.0812 - mean_squared_error: 115.0812 - val_loss: 250.0415 - val_mean_squared_error: 250.0415\n",
      "Epoch 246/500\n",
      "101/101 [==============================] - 12s 115ms/step - loss: 122.6597 - mean_squared_error: 122.6597 - val_loss: 195.7294 - val_mean_squared_error: 195.7294\n",
      "Epoch 247/500\n",
      "101/101 [==============================] - 12s 115ms/step - loss: 109.4254 - mean_squared_error: 109.4254 - val_loss: 308.8835 - val_mean_squared_error: 308.8835\n",
      "Epoch 248/500\n",
      "101/101 [==============================] - 12s 114ms/step - loss: 105.8777 - mean_squared_error: 105.8777 - val_loss: 304.2932 - val_mean_squared_error: 304.2932\n",
      "Epoch 249/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 112.4991 - mean_squared_error: 112.4991 - val_loss: 215.8044 - val_mean_squared_error: 215.8044\n",
      "Epoch 250/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 107.3187 - mean_squared_error: 107.3187 - val_loss: 309.7512 - val_mean_squared_error: 309.7512\n",
      "Epoch 251/500\n",
      "101/101 [==============================] - 12s 115ms/step - loss: 110.4717 - mean_squared_error: 110.4717 - val_loss: 190.6955 - val_mean_squared_error: 190.6955\n",
      "Epoch 252/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 109.4815 - mean_squared_error: 109.4815 - val_loss: 229.5507 - val_mean_squared_error: 229.5507\n",
      "Epoch 253/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 110.2068 - mean_squared_error: 110.2068 - val_loss: 178.5493 - val_mean_squared_error: 178.5493\n",
      "Epoch 254/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 103.5072 - mean_squared_error: 103.5072 - val_loss: 297.7126 - val_mean_squared_error: 297.7126\n",
      "Epoch 255/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 109.5187 - mean_squared_error: 109.5187 - val_loss: 261.7768 - val_mean_squared_error: 261.7768\n",
      "Epoch 256/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 112.8164 - mean_squared_error: 112.8164 - val_loss: 265.5732 - val_mean_squared_error: 265.5732\n",
      "Epoch 257/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 114.1130 - mean_squared_error: 114.1130 - val_loss: 201.7995 - val_mean_squared_error: 201.7995\n",
      "Epoch 258/500\n",
      "101/101 [==============================] - 11s 114ms/step - loss: 121.7720 - mean_squared_error: 121.7720 - val_loss: 245.7108 - val_mean_squared_error: 245.7108\n",
      "Epoch 259/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 117.3138 - mean_squared_error: 117.3138 - val_loss: 282.4467 - val_mean_squared_error: 282.4467\n",
      "Epoch 260/500\n",
      "101/101 [==============================] - 11s 114ms/step - loss: 106.6709 - mean_squared_error: 106.6709 - val_loss: 264.5782 - val_mean_squared_error: 264.5782\n",
      "Epoch 261/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 105.2447 - mean_squared_error: 105.2447 - val_loss: 333.6097 - val_mean_squared_error: 333.6097\n",
      "Epoch 262/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 104.1900 - mean_squared_error: 104.1900 - val_loss: 218.1663 - val_mean_squared_error: 218.1663\n",
      "Epoch 263/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 111.1923 - mean_squared_error: 111.1923 - val_loss: 207.7900 - val_mean_squared_error: 207.7900\n",
      "Epoch 264/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 116.3002 - mean_squared_error: 116.3002 - val_loss: 279.8322 - val_mean_squared_error: 279.8322\n",
      "Epoch 265/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 97.8869 - mean_squared_error: 97.8869 - val_loss: 191.2043 - val_mean_squared_error: 191.2043\n",
      "Epoch 266/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 106.6960 - mean_squared_error: 106.6960 - val_loss: 258.1153 - val_mean_squared_error: 258.1153\n",
      "Epoch 267/500\n",
      "101/101 [==============================] - 11s 114ms/step - loss: 102.1251 - mean_squared_error: 102.1251 - val_loss: 232.0863 - val_mean_squared_error: 232.0863\n",
      "Epoch 268/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 102.7080 - mean_squared_error: 102.7080 - val_loss: 270.2844 - val_mean_squared_error: 270.2844\n",
      "Epoch 269/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 107.6129 - mean_squared_error: 107.6129 - val_loss: 262.3878 - val_mean_squared_error: 262.3878\n",
      "Epoch 270/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 117.6659 - mean_squared_error: 117.6659 - val_loss: 178.8252 - val_mean_squared_error: 178.8252\n",
      "Epoch 271/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 100.4736 - mean_squared_error: 100.4736 - val_loss: 282.0943 - val_mean_squared_error: 282.0943\n",
      "Epoch 272/500\n",
      "101/101 [==============================] - 11s 114ms/step - loss: 107.8761 - mean_squared_error: 107.8761 - val_loss: 213.2557 - val_mean_squared_error: 213.2557\n",
      "Epoch 273/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 100.8731 - mean_squared_error: 100.8731 - val_loss: 229.8634 - val_mean_squared_error: 229.8634\n",
      "Epoch 274/500\n",
      "101/101 [==============================] - 11s 114ms/step - loss: 100.1180 - mean_squared_error: 100.1180 - val_loss: 223.3086 - val_mean_squared_error: 223.3086\n",
      "Epoch 275/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 99.3839 - mean_squared_error: 99.3839 - val_loss: 289.8060 - val_mean_squared_error: 289.8060\n",
      "Epoch 276/500\n",
      "101/101 [==============================] - 12s 115ms/step - loss: 98.5919 - mean_squared_error: 98.5919 - val_loss: 239.9559 - val_mean_squared_error: 239.9559\n",
      "Epoch 277/500\n",
      "101/101 [==============================] - 12s 115ms/step - loss: 104.4204 - mean_squared_error: 104.4204 - val_loss: 261.5348 - val_mean_squared_error: 261.5348\n",
      "Epoch 278/500\n",
      "101/101 [==============================] - 11s 114ms/step - loss: 100.1932 - mean_squared_error: 100.1932 - val_loss: 220.0393 - val_mean_squared_error: 220.0393\n",
      "Epoch 279/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 94.6016 - mean_squared_error: 94.6016 - val_loss: 258.8622 - val_mean_squared_error: 258.8622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 280/500\n",
      "101/101 [==============================] - 11s 114ms/step - loss: 93.4776 - mean_squared_error: 93.4776 - val_loss: 235.9167 - val_mean_squared_error: 235.9167\n",
      "Epoch 281/500\n",
      "101/101 [==============================] - 11s 114ms/step - loss: 94.1084 - mean_squared_error: 94.1084 - val_loss: 166.8974 - val_mean_squared_error: 166.8974\n",
      "Epoch 282/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 103.6996 - mean_squared_error: 103.6996 - val_loss: 244.5537 - val_mean_squared_error: 244.5537\n",
      "Epoch 283/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 97.5821 - mean_squared_error: 97.5821 - val_loss: 373.7126 - val_mean_squared_error: 373.7126\n",
      "Epoch 284/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 102.8815 - mean_squared_error: 102.8815 - val_loss: 206.1993 - val_mean_squared_error: 206.1993\n",
      "Epoch 285/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 99.9134 - mean_squared_error: 99.9134 - val_loss: 306.6152 - val_mean_squared_error: 306.6152\n",
      "Epoch 286/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 93.7025 - mean_squared_error: 93.7025 - val_loss: 254.7151 - val_mean_squared_error: 254.7151\n",
      "Epoch 287/500\n",
      "101/101 [==============================] - 11s 114ms/step - loss: 94.1142 - mean_squared_error: 94.1142 - val_loss: 180.4809 - val_mean_squared_error: 180.4809\n",
      "Epoch 288/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 95.7053 - mean_squared_error: 95.7053 - val_loss: 233.1619 - val_mean_squared_error: 233.1619\n",
      "Epoch 289/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 104.2266 - mean_squared_error: 104.2266 - val_loss: 244.4896 - val_mean_squared_error: 244.4896\n",
      "Epoch 290/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 103.3231 - mean_squared_error: 103.3231 - val_loss: 271.6955 - val_mean_squared_error: 271.6955\n",
      "Epoch 291/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 98.4432 - mean_squared_error: 98.4432 - val_loss: 248.2752 - val_mean_squared_error: 248.2752\n",
      "Epoch 292/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 91.7734 - mean_squared_error: 91.7734 - val_loss: 295.5580 - val_mean_squared_error: 295.5580\n",
      "Epoch 293/500\n",
      "101/101 [==============================] - 12s 115ms/step - loss: 95.0728 - mean_squared_error: 95.0728 - val_loss: 285.2254 - val_mean_squared_error: 285.2254\n",
      "Epoch 294/500\n",
      "101/101 [==============================] - 11s 114ms/step - loss: 99.1568 - mean_squared_error: 99.1568 - val_loss: 325.5390 - val_mean_squared_error: 325.5390\n",
      "Epoch 295/500\n",
      "101/101 [==============================] - 12s 116ms/step - loss: 87.7050 - mean_squared_error: 87.7050 - val_loss: 205.1941 - val_mean_squared_error: 205.1941\n",
      "Epoch 296/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 96.5690 - mean_squared_error: 96.5690 - val_loss: 258.9716 - val_mean_squared_error: 258.9716\n",
      "Epoch 297/500\n",
      "101/101 [==============================] - 11s 114ms/step - loss: 98.2566 - mean_squared_error: 98.2566 - val_loss: 229.2024 - val_mean_squared_error: 229.2024\n",
      "Epoch 298/500\n",
      "101/101 [==============================] - 11s 114ms/step - loss: 87.8681 - mean_squared_error: 87.8681 - val_loss: 285.4769 - val_mean_squared_error: 285.4769\n",
      "Epoch 299/500\n",
      "101/101 [==============================] - 11s 114ms/step - loss: 84.8385 - mean_squared_error: 84.8385 - val_loss: 260.2757 - val_mean_squared_error: 260.2757\n",
      "Epoch 300/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 92.4838 - mean_squared_error: 92.4838 - val_loss: 248.6342 - val_mean_squared_error: 248.6342\n",
      "Epoch 301/500\n",
      "101/101 [==============================] - 11s 114ms/step - loss: 87.4086 - mean_squared_error: 87.4086 - val_loss: 193.2447 - val_mean_squared_error: 193.2447\n",
      "Epoch 302/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 87.4719 - mean_squared_error: 87.4719 - val_loss: 215.8990 - val_mean_squared_error: 215.8990\n",
      "Epoch 303/500\n",
      "101/101 [==============================] - 12s 116ms/step - loss: 92.1169 - mean_squared_error: 92.1169 - val_loss: 212.4892 - val_mean_squared_error: 212.4892\n",
      "Epoch 304/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 99.0328 - mean_squared_error: 99.0328 - val_loss: 304.7709 - val_mean_squared_error: 304.7709\n",
      "Epoch 305/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 94.3927 - mean_squared_error: 94.3927 - val_loss: 248.6829 - val_mean_squared_error: 248.6829\n",
      "Epoch 306/500\n",
      "101/101 [==============================] - 12s 116ms/step - loss: 93.1661 - mean_squared_error: 93.1661 - val_loss: 272.5326 - val_mean_squared_error: 272.5326\n",
      "Epoch 307/500\n",
      "101/101 [==============================] - 12s 115ms/step - loss: 90.5702 - mean_squared_error: 90.5702 - val_loss: 184.6601 - val_mean_squared_error: 184.6601\n",
      "Epoch 308/500\n",
      "101/101 [==============================] - 11s 114ms/step - loss: 92.5475 - mean_squared_error: 92.5475 - val_loss: 279.1693 - val_mean_squared_error: 279.1693\n",
      "Epoch 309/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 88.3945 - mean_squared_error: 88.3945 - val_loss: 284.5612 - val_mean_squared_error: 284.5612\n",
      "Epoch 310/500\n",
      "101/101 [==============================] - 12s 115ms/step - loss: 89.7025 - mean_squared_error: 89.7025 - val_loss: 171.0498 - val_mean_squared_error: 171.0498\n",
      "Epoch 311/500\n",
      "101/101 [==============================] - 11s 114ms/step - loss: 98.1050 - mean_squared_error: 98.1050 - val_loss: 206.9526 - val_mean_squared_error: 206.9526\n",
      "Epoch 312/500\n",
      "101/101 [==============================] - 11s 114ms/step - loss: 84.6105 - mean_squared_error: 84.6105 - val_loss: 357.4450 - val_mean_squared_error: 357.4450\n",
      "Epoch 313/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 89.9508 - mean_squared_error: 89.9508 - val_loss: 204.3160 - val_mean_squared_error: 204.3160\n",
      "Epoch 314/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 88.6456 - mean_squared_error: 88.6456 - val_loss: 245.0208 - val_mean_squared_error: 245.0208\n",
      "Epoch 315/500\n",
      "101/101 [==============================] - 12s 115ms/step - loss: 89.7734 - mean_squared_error: 89.7734 - val_loss: 244.1444 - val_mean_squared_error: 244.1444\n",
      "Epoch 316/500\n",
      "101/101 [==============================] - 12s 115ms/step - loss: 89.5274 - mean_squared_error: 89.5274 - val_loss: 233.8384 - val_mean_squared_error: 233.8384\n",
      "Epoch 317/500\n",
      "101/101 [==============================] - 12s 115ms/step - loss: 85.6630 - mean_squared_error: 85.6630 - val_loss: 181.6218 - val_mean_squared_error: 181.6218\n",
      "Epoch 318/500\n",
      "101/101 [==============================] - 12s 116ms/step - loss: 88.2112 - mean_squared_error: 88.2112 - val_loss: 261.7937 - val_mean_squared_error: 261.7937\n",
      "Epoch 319/500\n",
      "101/101 [==============================] - 12s 115ms/step - loss: 86.6605 - mean_squared_error: 86.6605 - val_loss: 182.8728 - val_mean_squared_error: 182.8728\n",
      "Epoch 320/500\n",
      "101/101 [==============================] - 11s 114ms/step - loss: 86.9352 - mean_squared_error: 86.9352 - val_loss: 197.4302 - val_mean_squared_error: 197.4302\n",
      "Epoch 321/500\n",
      "101/101 [==============================] - 12s 118ms/step - loss: 92.6895 - mean_squared_error: 92.6895 - val_loss: 201.4868 - val_mean_squared_error: 201.4868\n",
      "Epoch 322/500\n",
      "101/101 [==============================] - 12s 119ms/step - loss: 84.4401 - mean_squared_error: 84.4401 - val_loss: 183.4784 - val_mean_squared_error: 183.4784\n",
      "Epoch 323/500\n",
      "101/101 [==============================] - 12s 115ms/step - loss: 85.1539 - mean_squared_error: 85.1539 - val_loss: 287.1295 - val_mean_squared_error: 287.1295\n",
      "Epoch 324/500\n",
      "101/101 [==============================] - 12s 115ms/step - loss: 89.4418 - mean_squared_error: 89.4418 - val_loss: 201.0166 - val_mean_squared_error: 201.0166\n",
      "Epoch 325/500\n",
      "101/101 [==============================] - 11s 114ms/step - loss: 88.0520 - mean_squared_error: 88.0520 - val_loss: 225.8418 - val_mean_squared_error: 225.8418\n",
      "Epoch 326/500\n",
      "101/101 [==============================] - 12s 116ms/step - loss: 81.2007 - mean_squared_error: 81.2007 - val_loss: 174.3188 - val_mean_squared_error: 174.3188\n",
      "Epoch 327/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101/101 [==============================] - 12s 115ms/step - loss: 84.4465 - mean_squared_error: 84.4465 - val_loss: 254.4992 - val_mean_squared_error: 254.4992\n",
      "Epoch 328/500\n",
      "101/101 [==============================] - 12s 115ms/step - loss: 86.5419 - mean_squared_error: 86.5419 - val_loss: 200.2990 - val_mean_squared_error: 200.2990\n",
      "Epoch 329/500\n",
      "101/101 [==============================] - 12s 115ms/step - loss: 80.3608 - mean_squared_error: 80.3608 - val_loss: 211.2236 - val_mean_squared_error: 211.2236\n",
      "Epoch 330/500\n",
      "101/101 [==============================] - 12s 115ms/step - loss: 83.6231 - mean_squared_error: 83.6231 - val_loss: 221.8524 - val_mean_squared_error: 221.8524\n",
      "Epoch 331/500\n",
      "101/101 [==============================] - 11s 114ms/step - loss: 83.4936 - mean_squared_error: 83.4936 - val_loss: 256.8626 - val_mean_squared_error: 256.8626\n",
      "Epoch 332/500\n",
      "101/101 [==============================] - 12s 116ms/step - loss: 84.1047 - mean_squared_error: 84.1047 - val_loss: 201.4485 - val_mean_squared_error: 201.4485\n",
      "Epoch 333/500\n",
      "101/101 [==============================] - 12s 115ms/step - loss: 80.2304 - mean_squared_error: 80.2304 - val_loss: 227.1898 - val_mean_squared_error: 227.1898\n",
      "Epoch 334/500\n",
      "101/101 [==============================] - 12s 116ms/step - loss: 80.3534 - mean_squared_error: 80.3534 - val_loss: 184.4515 - val_mean_squared_error: 184.4515\n",
      "Epoch 335/500\n",
      "101/101 [==============================] - 12s 115ms/step - loss: 77.0379 - mean_squared_error: 77.0379 - val_loss: 250.4292 - val_mean_squared_error: 250.4292\n",
      "Epoch 336/500\n",
      "101/101 [==============================] - 12s 115ms/step - loss: 79.2167 - mean_squared_error: 79.2167 - val_loss: 228.8612 - val_mean_squared_error: 228.8612\n",
      "Epoch 337/500\n",
      "101/101 [==============================] - 11s 114ms/step - loss: 84.4885 - mean_squared_error: 84.4885 - val_loss: 271.1425 - val_mean_squared_error: 271.1425\n",
      "Epoch 338/500\n",
      "101/101 [==============================] - 11s 114ms/step - loss: 80.4470 - mean_squared_error: 80.4470 - val_loss: 226.4141 - val_mean_squared_error: 226.4141\n",
      "Epoch 339/500\n",
      "101/101 [==============================] - 12s 116ms/step - loss: 81.2362 - mean_squared_error: 81.2362 - val_loss: 227.6135 - val_mean_squared_error: 227.6135\n",
      "Epoch 340/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 80.5021 - mean_squared_error: 80.5021 - val_loss: 230.2882 - val_mean_squared_error: 230.2882\n",
      "Epoch 341/500\n",
      "101/101 [==============================] - 12s 115ms/step - loss: 76.6866 - mean_squared_error: 76.6866 - val_loss: 179.2893 - val_mean_squared_error: 179.2893\n",
      "Epoch 342/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 80.5629 - mean_squared_error: 80.5629 - val_loss: 309.3020 - val_mean_squared_error: 309.3020\n",
      "Epoch 343/500\n",
      "101/101 [==============================] - 12s 115ms/step - loss: 77.4827 - mean_squared_error: 77.4827 - val_loss: 298.2881 - val_mean_squared_error: 298.2881\n",
      "Epoch 344/500\n",
      "101/101 [==============================] - 11s 114ms/step - loss: 87.6104 - mean_squared_error: 87.6104 - val_loss: 246.1497 - val_mean_squared_error: 246.1497\n",
      "Epoch 345/500\n",
      "101/101 [==============================] - 12s 115ms/step - loss: 83.6037 - mean_squared_error: 83.6037 - val_loss: 244.1447 - val_mean_squared_error: 244.1447\n",
      "Epoch 346/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 76.6298 - mean_squared_error: 76.6298 - val_loss: 302.8045 - val_mean_squared_error: 302.8045\n",
      "Epoch 347/500\n",
      "101/101 [==============================] - 11s 114ms/step - loss: 79.1889 - mean_squared_error: 79.1889 - val_loss: 273.1400 - val_mean_squared_error: 273.1400\n",
      "Epoch 348/500\n",
      "101/101 [==============================] - 12s 118ms/step - loss: 77.4809 - mean_squared_error: 77.4809 - val_loss: 288.5249 - val_mean_squared_error: 288.5249\n",
      "Epoch 349/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 75.6900 - mean_squared_error: 75.6900 - val_loss: 209.7769 - val_mean_squared_error: 209.7769\n",
      "Epoch 350/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 84.1536 - mean_squared_error: 84.1536 - val_loss: 309.4829 - val_mean_squared_error: 309.4829\n",
      "Epoch 351/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 75.4098 - mean_squared_error: 75.4098 - val_loss: 197.7092 - val_mean_squared_error: 197.7092\n",
      "Epoch 352/500\n",
      "101/101 [==============================] - 12s 114ms/step - loss: 87.6614 - mean_squared_error: 87.6614 - val_loss: 228.8898 - val_mean_squared_error: 228.8898\n",
      "Epoch 353/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 82.6050 - mean_squared_error: 82.6050 - val_loss: 222.7415 - val_mean_squared_error: 222.7415\n",
      "Epoch 354/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 78.2860 - mean_squared_error: 78.2860 - val_loss: 238.9822 - val_mean_squared_error: 238.9822\n",
      "Epoch 355/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 73.3036 - mean_squared_error: 73.3036 - val_loss: 227.5278 - val_mean_squared_error: 227.5278\n",
      "Epoch 356/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 88.1527 - mean_squared_error: 88.1527 - val_loss: 308.5186 - val_mean_squared_error: 308.5186\n",
      "Epoch 357/500\n",
      "101/101 [==============================] - 11s 114ms/step - loss: 81.3099 - mean_squared_error: 81.3099 - val_loss: 280.2976 - val_mean_squared_error: 280.2976\n",
      "Epoch 358/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 78.7708 - mean_squared_error: 78.7708 - val_loss: 217.4740 - val_mean_squared_error: 217.4740\n",
      "Epoch 359/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 79.8640 - mean_squared_error: 79.8640 - val_loss: 193.6108 - val_mean_squared_error: 193.6108\n",
      "Epoch 360/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 77.7321 - mean_squared_error: 77.7321 - val_loss: 211.9372 - val_mean_squared_error: 211.9372\n",
      "Epoch 361/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 69.4428 - mean_squared_error: 69.4428 - val_loss: 235.8224 - val_mean_squared_error: 235.8224\n",
      "Epoch 362/500\n",
      "101/101 [==============================] - 11s 114ms/step - loss: 80.2918 - mean_squared_error: 80.2918 - val_loss: 231.5347 - val_mean_squared_error: 231.5347\n",
      "Epoch 363/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 74.2750 - mean_squared_error: 74.2750 - val_loss: 235.9298 - val_mean_squared_error: 235.9298\n",
      "Epoch 364/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 69.3996 - mean_squared_error: 69.3996 - val_loss: 196.1581 - val_mean_squared_error: 196.1581\n",
      "Epoch 365/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 76.0261 - mean_squared_error: 76.0261 - val_loss: 224.9882 - val_mean_squared_error: 224.9882\n",
      "Epoch 366/500\n",
      "101/101 [==============================] - 11s 114ms/step - loss: 70.6476 - mean_squared_error: 70.6476 - val_loss: 180.3671 - val_mean_squared_error: 180.3671\n",
      "Epoch 367/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 69.2447 - mean_squared_error: 69.2447 - val_loss: 192.0367 - val_mean_squared_error: 192.0367\n",
      "Epoch 368/500\n",
      "101/101 [==============================] - 11s 114ms/step - loss: 73.1348 - mean_squared_error: 73.1348 - val_loss: 211.1594 - val_mean_squared_error: 211.1594\n",
      "Epoch 369/500\n",
      "101/101 [==============================] - 12s 115ms/step - loss: 72.5536 - mean_squared_error: 72.5536 - val_loss: 183.7338 - val_mean_squared_error: 183.7338\n",
      "Epoch 370/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 75.4828 - mean_squared_error: 75.4828 - val_loss: 181.5491 - val_mean_squared_error: 181.5491\n",
      "Epoch 371/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 70.9910 - mean_squared_error: 70.9910 - val_loss: 244.0303 - val_mean_squared_error: 244.0303\n",
      "Epoch 372/500\n",
      "101/101 [==============================] - 11s 114ms/step - loss: 72.3241 - mean_squared_error: 72.3241 - val_loss: 205.4080 - val_mean_squared_error: 205.4080\n",
      "Epoch 373/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 68.6279 - mean_squared_error: 68.6279 - val_loss: 204.2848 - val_mean_squared_error: 204.2848\n",
      "Epoch 374/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 68.0093 - mean_squared_error: 68.0093 - val_loss: 180.8338 - val_mean_squared_error: 180.8338\n",
      "Epoch 375/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 72.0927 - mean_squared_error: 72.0927 - val_loss: 203.8691 - val_mean_squared_error: 203.8691\n",
      "Epoch 376/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 70.1476 - mean_squared_error: 70.1476 - val_loss: 242.8461 - val_mean_squared_error: 242.8461\n",
      "Epoch 377/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 73.7855 - mean_squared_error: 73.7855 - val_loss: 185.0238 - val_mean_squared_error: 185.0238\n",
      "Epoch 378/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 70.1543 - mean_squared_error: 70.1543 - val_loss: 247.5250 - val_mean_squared_error: 247.5250\n",
      "Epoch 379/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 74.5596 - mean_squared_error: 74.5596 - val_loss: 352.9596 - val_mean_squared_error: 352.9596\n",
      "Epoch 380/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 76.5854 - mean_squared_error: 76.5854 - val_loss: 297.7192 - val_mean_squared_error: 297.7192\n",
      "Epoch 381/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 76.4297 - mean_squared_error: 76.4297 - val_loss: 216.8917 - val_mean_squared_error: 216.8917\n",
      "Epoch 382/500\n",
      "101/101 [==============================] - 12s 114ms/step - loss: 73.5716 - mean_squared_error: 73.5716 - val_loss: 212.0162 - val_mean_squared_error: 212.0162\n",
      "Epoch 383/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 71.5390 - mean_squared_error: 71.5390 - val_loss: 207.2854 - val_mean_squared_error: 207.2854\n",
      "Epoch 384/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 71.3522 - mean_squared_error: 71.3522 - val_loss: 232.4379 - val_mean_squared_error: 232.4379\n",
      "Epoch 385/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 70.9261 - mean_squared_error: 70.9261 - val_loss: 235.6198 - val_mean_squared_error: 235.6198\n",
      "Epoch 386/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 71.5398 - mean_squared_error: 71.5398 - val_loss: 147.2839 - val_mean_squared_error: 147.2839\n",
      "Epoch 387/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 70.2576 - mean_squared_error: 70.2576 - val_loss: 235.0452 - val_mean_squared_error: 235.0452\n",
      "Epoch 388/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 63.6519 - mean_squared_error: 63.6519 - val_loss: 206.0618 - val_mean_squared_error: 206.0618\n",
      "Epoch 389/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 71.7090 - mean_squared_error: 71.7090 - val_loss: 178.2737 - val_mean_squared_error: 178.2737\n",
      "Epoch 390/500\n",
      "101/101 [==============================] - 11s 109ms/step - loss: 63.8554 - mean_squared_error: 63.8554 - val_loss: 208.2841 - val_mean_squared_error: 208.2841\n",
      "Epoch 391/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 69.8177 - mean_squared_error: 69.8177 - val_loss: 236.0165 - val_mean_squared_error: 236.0165\n",
      "Epoch 392/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 68.9558 - mean_squared_error: 68.9558 - val_loss: 290.5216 - val_mean_squared_error: 290.5216\n",
      "Epoch 393/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 70.0770 - mean_squared_error: 70.0770 - val_loss: 303.5676 - val_mean_squared_error: 303.5676\n",
      "Epoch 394/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 64.9651 - mean_squared_error: 64.9651 - val_loss: 198.0931 - val_mean_squared_error: 198.0931\n",
      "Epoch 395/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 64.7834 - mean_squared_error: 64.7834 - val_loss: 257.1564 - val_mean_squared_error: 257.1564\n",
      "Epoch 396/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 69.2056 - mean_squared_error: 69.2056 - val_loss: 296.1884 - val_mean_squared_error: 296.1884\n",
      "Epoch 397/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 70.2381 - mean_squared_error: 70.2381 - val_loss: 184.1086 - val_mean_squared_error: 184.1086\n",
      "Epoch 398/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 63.0839 - mean_squared_error: 63.0839 - val_loss: 242.5078 - val_mean_squared_error: 242.5078\n",
      "Epoch 399/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 69.3428 - mean_squared_error: 69.3428 - val_loss: 208.1128 - val_mean_squared_error: 208.1128\n",
      "Epoch 400/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 71.2780 - mean_squared_error: 71.2780 - val_loss: 270.4648 - val_mean_squared_error: 270.4648\n",
      "Epoch 401/500\n",
      "101/101 [==============================] - 11s 109ms/step - loss: 64.6066 - mean_squared_error: 64.6066 - val_loss: 181.0307 - val_mean_squared_error: 181.0307\n",
      "Epoch 402/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 66.7812 - mean_squared_error: 66.7812 - val_loss: 242.9580 - val_mean_squared_error: 242.9580\n",
      "Epoch 403/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 67.4430 - mean_squared_error: 67.4430 - val_loss: 213.9695 - val_mean_squared_error: 213.9695\n",
      "Epoch 404/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 64.8288 - mean_squared_error: 64.8288 - val_loss: 192.2479 - val_mean_squared_error: 192.2479\n",
      "Epoch 405/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 69.2883 - mean_squared_error: 69.2883 - val_loss: 148.0766 - val_mean_squared_error: 148.0766\n",
      "Epoch 406/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 64.7355 - mean_squared_error: 64.7355 - val_loss: 213.6647 - val_mean_squared_error: 213.6647\n",
      "Epoch 407/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 68.1915 - mean_squared_error: 68.1915 - val_loss: 204.3583 - val_mean_squared_error: 204.3583\n",
      "Epoch 408/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 60.9136 - mean_squared_error: 60.9136 - val_loss: 263.0411 - val_mean_squared_error: 263.0411\n",
      "Epoch 409/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 64.3455 - mean_squared_error: 64.3455 - val_loss: 252.0199 - val_mean_squared_error: 252.0199\n",
      "Epoch 410/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 59.2739 - mean_squared_error: 59.2739 - val_loss: 245.1330 - val_mean_squared_error: 245.1330\n",
      "Epoch 411/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 67.9134 - mean_squared_error: 67.9134 - val_loss: 249.3214 - val_mean_squared_error: 249.3214\n",
      "Epoch 412/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 64.6959 - mean_squared_error: 64.6959 - val_loss: 236.2298 - val_mean_squared_error: 236.2298\n",
      "Epoch 413/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 65.0297 - mean_squared_error: 65.0297 - val_loss: 199.1769 - val_mean_squared_error: 199.1769\n",
      "Epoch 414/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 62.2386 - mean_squared_error: 62.2386 - val_loss: 216.5573 - val_mean_squared_error: 216.5573\n",
      "Epoch 415/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 68.6106 - mean_squared_error: 68.6106 - val_loss: 179.0183 - val_mean_squared_error: 179.0183\n",
      "Epoch 416/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 61.7985 - mean_squared_error: 61.7985 - val_loss: 239.7035 - val_mean_squared_error: 239.7035\n",
      "Epoch 417/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 61.4381 - mean_squared_error: 61.4381 - val_loss: 235.3487 - val_mean_squared_error: 235.3487\n",
      "Epoch 418/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 66.9333 - mean_squared_error: 66.9333 - val_loss: 242.3021 - val_mean_squared_error: 242.3021\n",
      "Epoch 419/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 56.9935 - mean_squared_error: 56.9935 - val_loss: 248.5107 - val_mean_squared_error: 248.5107\n",
      "Epoch 420/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 60.3102 - mean_squared_error: 60.3102 - val_loss: 245.3064 - val_mean_squared_error: 245.3064\n",
      "Epoch 421/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101/101 [==============================] - 11s 111ms/step - loss: 61.0587 - mean_squared_error: 61.0587 - val_loss: 168.1682 - val_mean_squared_error: 168.1682\n",
      "Epoch 422/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 63.2163 - mean_squared_error: 63.2163 - val_loss: 307.3358 - val_mean_squared_error: 307.3358\n",
      "Epoch 423/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 64.1031 - mean_squared_error: 64.1031 - val_loss: 294.1678 - val_mean_squared_error: 294.1678\n",
      "Epoch 424/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 62.8870 - mean_squared_error: 62.8870 - val_loss: 248.8612 - val_mean_squared_error: 248.8612\n",
      "Epoch 425/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 64.0409 - mean_squared_error: 64.0409 - val_loss: 217.7764 - val_mean_squared_error: 217.7764\n",
      "Epoch 426/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 58.9700 - mean_squared_error: 58.9700 - val_loss: 227.2755 - val_mean_squared_error: 227.2755\n",
      "Epoch 427/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 59.7925 - mean_squared_error: 59.7925 - val_loss: 264.7171 - val_mean_squared_error: 264.7171\n",
      "Epoch 428/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 56.9519 - mean_squared_error: 56.9519 - val_loss: 210.6312 - val_mean_squared_error: 210.6312\n",
      "Epoch 429/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 65.2022 - mean_squared_error: 65.2022 - val_loss: 216.6388 - val_mean_squared_error: 216.6388\n",
      "Epoch 430/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 63.8389 - mean_squared_error: 63.8389 - val_loss: 192.9277 - val_mean_squared_error: 192.9277\n",
      "Epoch 431/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 61.3885 - mean_squared_error: 61.3885 - val_loss: 215.5927 - val_mean_squared_error: 215.5927\n",
      "Epoch 432/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 58.2455 - mean_squared_error: 58.2455 - val_loss: 211.0857 - val_mean_squared_error: 211.0857\n",
      "Epoch 433/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 60.5968 - mean_squared_error: 60.5968 - val_loss: 202.9471 - val_mean_squared_error: 202.9471\n",
      "Epoch 434/500\n",
      "101/101 [==============================] - 11s 109ms/step - loss: 59.1793 - mean_squared_error: 59.1793 - val_loss: 208.1813 - val_mean_squared_error: 208.1813\n",
      "Epoch 435/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 57.5598 - mean_squared_error: 57.5598 - val_loss: 286.9412 - val_mean_squared_error: 286.9412\n",
      "Epoch 436/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 57.1479 - mean_squared_error: 57.1479 - val_loss: 204.0203 - val_mean_squared_error: 204.0203\n",
      "Epoch 437/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 55.3487 - mean_squared_error: 55.3487 - val_loss: 233.1687 - val_mean_squared_error: 233.1687\n",
      "Epoch 438/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 57.1124 - mean_squared_error: 57.1124 - val_loss: 214.2562 - val_mean_squared_error: 214.2562\n",
      "Epoch 439/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 55.8857 - mean_squared_error: 55.8857 - val_loss: 283.9340 - val_mean_squared_error: 283.9340\n",
      "Epoch 440/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 56.2016 - mean_squared_error: 56.2016 - val_loss: 196.6277 - val_mean_squared_error: 196.6277\n",
      "Epoch 441/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 60.3427 - mean_squared_error: 60.3427 - val_loss: 196.9450 - val_mean_squared_error: 196.9450\n",
      "Epoch 442/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 58.2773 - mean_squared_error: 58.2773 - val_loss: 224.6939 - val_mean_squared_error: 224.6939\n",
      "Epoch 443/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 51.4713 - mean_squared_error: 51.4713 - val_loss: 232.5049 - val_mean_squared_error: 232.5049\n",
      "Epoch 444/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 60.0797 - mean_squared_error: 60.0797 - val_loss: 271.2823 - val_mean_squared_error: 271.2823\n",
      "Epoch 445/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 57.0241 - mean_squared_error: 57.0241 - val_loss: 189.3001 - val_mean_squared_error: 189.3001\n",
      "Epoch 446/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 61.2455 - mean_squared_error: 61.2455 - val_loss: 203.9026 - val_mean_squared_error: 203.9026\n",
      "Epoch 447/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 65.4954 - mean_squared_error: 65.4954 - val_loss: 260.7364 - val_mean_squared_error: 260.7364\n",
      "Epoch 448/500\n",
      "101/101 [==============================] - 12s 116ms/step - loss: 57.9536 - mean_squared_error: 57.9536 - val_loss: 240.1601 - val_mean_squared_error: 240.1601\n",
      "Epoch 449/500\n",
      "101/101 [==============================] - 11s 114ms/step - loss: 61.5333 - mean_squared_error: 61.5333 - val_loss: 189.7058 - val_mean_squared_error: 189.7058\n",
      "Epoch 450/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 55.8263 - mean_squared_error: 55.8263 - val_loss: 207.4614 - val_mean_squared_error: 207.4614\n",
      "Epoch 451/500\n",
      "101/101 [==============================] - 12s 116ms/step - loss: 59.8792 - mean_squared_error: 59.8792 - val_loss: 169.8125 - val_mean_squared_error: 169.8125\n",
      "Epoch 452/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 57.7429 - mean_squared_error: 57.7429 - val_loss: 218.1379 - val_mean_squared_error: 218.1379\n",
      "Epoch 453/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 57.6522 - mean_squared_error: 57.6522 - val_loss: 240.3182 - val_mean_squared_error: 240.3182\n",
      "Epoch 454/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 56.5744 - mean_squared_error: 56.5744 - val_loss: 161.8204 - val_mean_squared_error: 161.8204\n",
      "Epoch 455/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 56.9514 - mean_squared_error: 56.9514 - val_loss: 299.1065 - val_mean_squared_error: 299.1065\n",
      "Epoch 456/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 64.6626 - mean_squared_error: 64.6626 - val_loss: 210.7837 - val_mean_squared_error: 210.7837\n",
      "Epoch 457/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 56.9002 - mean_squared_error: 56.9002 - val_loss: 213.7198 - val_mean_squared_error: 213.7198\n",
      "Epoch 458/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 52.3133 - mean_squared_error: 52.3133 - val_loss: 194.4438 - val_mean_squared_error: 194.4438\n",
      "Epoch 459/500\n",
      "101/101 [==============================] - 12s 115ms/step - loss: 56.2514 - mean_squared_error: 56.2514 - val_loss: 256.8930 - val_mean_squared_error: 256.8930\n",
      "Epoch 460/500\n",
      "101/101 [==============================] - 11s 114ms/step - loss: 58.2850 - mean_squared_error: 58.2850 - val_loss: 213.6905 - val_mean_squared_error: 213.6905\n",
      "Epoch 461/500\n",
      "101/101 [==============================] - 12s 115ms/step - loss: 60.2499 - mean_squared_error: 60.2499 - val_loss: 201.9519 - val_mean_squared_error: 201.9519\n",
      "Epoch 462/500\n",
      "101/101 [==============================] - 11s 114ms/step - loss: 60.1557 - mean_squared_error: 60.1557 - val_loss: 167.4510 - val_mean_squared_error: 167.4510\n",
      "Epoch 463/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 53.9151 - mean_squared_error: 53.9151 - val_loss: 305.6415 - val_mean_squared_error: 305.6415\n",
      "Epoch 464/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 52.0678 - mean_squared_error: 52.0678 - val_loss: 199.4608 - val_mean_squared_error: 199.4608\n",
      "Epoch 465/500\n",
      "101/101 [==============================] - 11s 114ms/step - loss: 52.7287 - mean_squared_error: 52.7287 - val_loss: 257.0715 - val_mean_squared_error: 257.0715\n",
      "Epoch 466/500\n",
      "101/101 [==============================] - 12s 115ms/step - loss: 49.7060 - mean_squared_error: 49.7060 - val_loss: 231.7454 - val_mean_squared_error: 231.7454\n",
      "Epoch 467/500\n",
      "101/101 [==============================] - 11s 114ms/step - loss: 52.9906 - mean_squared_error: 52.9906 - val_loss: 194.5091 - val_mean_squared_error: 194.5091\n",
      "Epoch 468/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 53.1895 - mean_squared_error: 53.1895 - val_loss: 281.2539 - val_mean_squared_error: 281.2539\n",
      "Epoch 469/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 52.8354 - mean_squared_error: 52.8354 - val_loss: 174.2533 - val_mean_squared_error: 174.2533\n",
      "Epoch 470/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 53.7258 - mean_squared_error: 53.7258 - val_loss: 196.8078 - val_mean_squared_error: 196.8078\n",
      "Epoch 471/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 52.0761 - mean_squared_error: 52.0761 - val_loss: 165.1703 - val_mean_squared_error: 165.1703\n",
      "Epoch 472/500\n",
      "101/101 [==============================] - 11s 114ms/step - loss: 54.1246 - mean_squared_error: 54.1246 - val_loss: 216.9700 - val_mean_squared_error: 216.9700\n",
      "Epoch 473/500\n",
      "101/101 [==============================] - 11s 114ms/step - loss: 57.2537 - mean_squared_error: 57.2537 - val_loss: 242.9883 - val_mean_squared_error: 242.9883\n",
      "Epoch 474/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 51.2797 - mean_squared_error: 51.2797 - val_loss: 264.2331 - val_mean_squared_error: 264.2331\n",
      "Epoch 475/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 54.9210 - mean_squared_error: 54.9210 - val_loss: 324.1960 - val_mean_squared_error: 324.1960\n",
      "Epoch 476/500\n",
      "101/101 [==============================] - 11s 109ms/step - loss: 52.2258 - mean_squared_error: 52.2258 - val_loss: 249.2504 - val_mean_squared_error: 249.2504\n",
      "Epoch 477/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 55.5209 - mean_squared_error: 55.5209 - val_loss: 292.3338 - val_mean_squared_error: 292.3338\n",
      "Epoch 478/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 56.7559 - mean_squared_error: 56.7559 - val_loss: 310.8493 - val_mean_squared_error: 310.8493\n",
      "Epoch 479/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 49.8162 - mean_squared_error: 49.8162 - val_loss: 243.0110 - val_mean_squared_error: 243.0110\n",
      "Epoch 480/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 47.2580 - mean_squared_error: 47.2580 - val_loss: 231.1706 - val_mean_squared_error: 231.1706\n",
      "Epoch 481/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 50.2291 - mean_squared_error: 50.2291 - val_loss: 255.1894 - val_mean_squared_error: 255.1894\n",
      "Epoch 482/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 54.1408 - mean_squared_error: 54.1408 - val_loss: 177.2099 - val_mean_squared_error: 177.2099\n",
      "Epoch 483/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 53.7190 - mean_squared_error: 53.7190 - val_loss: 205.5027 - val_mean_squared_error: 205.5027\n",
      "Epoch 484/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 57.7736 - mean_squared_error: 57.7736 - val_loss: 244.8993 - val_mean_squared_error: 244.8993\n",
      "Epoch 485/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 49.9530 - mean_squared_error: 49.9530 - val_loss: 262.5063 - val_mean_squared_error: 262.5063\n",
      "Epoch 486/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 50.0227 - mean_squared_error: 50.0227 - val_loss: 182.7657 - val_mean_squared_error: 182.7657\n",
      "Epoch 487/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 51.1417 - mean_squared_error: 51.1417 - val_loss: 183.7848 - val_mean_squared_error: 183.7848\n",
      "Epoch 488/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 47.5868 - mean_squared_error: 47.5868 - val_loss: 255.4002 - val_mean_squared_error: 255.4002\n",
      "Epoch 489/500\n",
      "101/101 [==============================] - 11s 114ms/step - loss: 48.3815 - mean_squared_error: 48.3815 - val_loss: 207.9353 - val_mean_squared_error: 207.9353\n",
      "Epoch 490/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 55.5206 - mean_squared_error: 55.5206 - val_loss: 244.4083 - val_mean_squared_error: 244.4083\n",
      "Epoch 491/500\n",
      "101/101 [==============================] - 11s 109ms/step - loss: 47.4003 - mean_squared_error: 47.4003 - val_loss: 228.4512 - val_mean_squared_error: 228.4512\n",
      "Epoch 492/500\n",
      "101/101 [==============================] - 11s 113ms/step - loss: 48.7578 - mean_squared_error: 48.7578 - val_loss: 231.0465 - val_mean_squared_error: 231.0465\n",
      "Epoch 493/500\n",
      "101/101 [==============================] - 12s 114ms/step - loss: 52.6918 - mean_squared_error: 52.6918 - val_loss: 245.5012 - val_mean_squared_error: 245.5012\n",
      "Epoch 494/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 54.8892 - mean_squared_error: 54.8892 - val_loss: 238.8674 - val_mean_squared_error: 238.8674\n",
      "Epoch 495/500\n",
      "101/101 [==============================] - 11s 112ms/step - loss: 49.0711 - mean_squared_error: 49.0711 - val_loss: 227.3988 - val_mean_squared_error: 227.3988\n",
      "Epoch 496/500\n",
      "101/101 [==============================] - 11s 111ms/step - loss: 48.7969 - mean_squared_error: 48.7969 - val_loss: 200.8812 - val_mean_squared_error: 200.8812\n",
      "Epoch 497/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 51.5978 - mean_squared_error: 51.5978 - val_loss: 229.2719 - val_mean_squared_error: 229.2719\n",
      "Epoch 498/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 51.7322 - mean_squared_error: 51.7322 - val_loss: 200.2755 - val_mean_squared_error: 200.2755\n",
      "Epoch 499/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 54.6676 - mean_squared_error: 54.6676 - val_loss: 290.1941 - val_mean_squared_error: 290.1941\n",
      "Epoch 500/500\n",
      "101/101 [==============================] - 11s 110ms/step - loss: 52.2052 - mean_squared_error: 52.2052 - val_loss: 153.4010 - val_mean_squared_error: 153.4010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ebe4e33e80>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model.\n",
    "forecast_model.fit(t_gen, \n",
    "                   epochs = 500, \n",
    "                   verbose = 1, \n",
    "                   validation_data = v_gen, \n",
    "                   steps_per_epoch = len(meta_t) // batch_size,\n",
    "                   validation_steps = len(meta_v) // batch_size,\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Models/005\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Models/005\\assets\n"
     ]
    }
   ],
   "source": [
    "# Save trained model.\n",
    "forecast_model.save('Models/005')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine how model is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get data from one chip\n",
    "sample_input = np.load('Sample_Dataset/val/features/2718135.npy')\n",
    "\n",
    "# Pad to even number of pixels\n",
    "a = np.pad(sample_input, [(0,0),(0,1),(0,1)])\n",
    "# Resize to include a channel dimension.\n",
    "a = tf.expand_dims(a, axis = -1)\n",
    "# Resize to include a batch dimension.\n",
    "a = tf.expand_dims(a, axis = 0)\n",
    "\n",
    "# Get data from one chip\n",
    "sample_output = np.load('Sample_Dataset/val/labels/2642208.npy')\n",
    "\n",
    "# Pad to even number of pixels\n",
    "b = np.pad(sample_output, [(0,0),(0,1),(0,1)])\n",
    "# Resize to include a channel dimension.\n",
    "#b = tf.expand_dims(b, axis = -1)\n",
    "# Resize to include a batch dimension.\n",
    "#b = tf.expand_dims(b, axis = 0)\n",
    "b.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 157ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.79931796"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_eval = forecast_model.predict(a)\n",
    "pred_eval[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 15ms/step\n",
      "0.0\n",
      "0.79931796\n",
      "\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "0.0\n",
      "0.79931796\n",
      "\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "2.0\n",
      "0.79931796\n",
      "\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "0.0\n",
      "0.79931796\n",
      "\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "0.0\n",
      "0.79931796\n",
      "\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "0.0\n",
      "0.79931796\n",
      "\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "0.0\n",
      "0.79931796\n",
      "\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "0.0\n",
      "0.79931796\n",
      "\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "2.0\n",
      "0.79931796\n",
      "\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "0.0\n",
      "0.79931796\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f_list = [\n",
    "    '2131880.npy',\n",
    "    '2149116.npy',\n",
    "    '2164143.npy',\n",
    "    '2200623.npy',\n",
    "    '2231628.npy',\n",
    "    '2249483.npy',\n",
    "    '2251208.npy',\n",
    "    '2290512.npy',\n",
    "    '2315187.npy',\n",
    "    '2327441.npy'\n",
    "]\n",
    "\n",
    "for x in range(0, 10):\n",
    "    a = np.load('Sample_Dataset/val/features/' + f_list[x])\n",
    "    a = np.pad(sample_input, [(0,0),(0,1),(0,1)])\n",
    "    a = tf.expand_dims(a, axis = -1)\n",
    "    a = tf.expand_dims(a, axis = 0)\n",
    "    b = np.load('Sample_Dataset/val/labels/' + f_list[x])\n",
    "    pred_eval = forecast_model.predict(a)\n",
    "    print(b.sum())\n",
    "    print(pred_eval[0][0])\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
