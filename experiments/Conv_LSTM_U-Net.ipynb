{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3a3b751",
   "metadata": {},
   "source": [
    "# Model Name TBD\n",
    "Combines the time-distributed feature extraction of Convolutional LSTMs with the upsampling and skip connections of a U-Net to convert video-like input features and time-distributed vector metadata into a next frame semantic segmentation map."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65090d11",
   "metadata": {},
   "source": [
    "### Import Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afec3342",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "#from tensorflow.keras.models import Sequential\n",
    "#from tensorflow.keras.initializers import Constant\n",
    "#from skimage.metrics import structural_similarity as ssim\n",
    "#from skimage.metrics import mean_squared_error\n",
    "#from math import log10, sqrt\n",
    "\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7194276",
   "metadata": {},
   "source": [
    "### Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07c37bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loader functions\n",
    "# Inspiration: https://towardsdatascience.com/writing-custom-keras-generators-fe815d992c5a\n",
    "\n",
    "def get_2d_input(path):\n",
    "    # Load array.\n",
    "    t_2d_input = np.load(path)\n",
    "    \n",
    "    return t_2d_input\n",
    "\n",
    "def get_1d_input(path):\n",
    "    # Load array.\n",
    "    t_1d_input = np.load(path)\n",
    "    \n",
    "    # Expand dimensions to match model input.\n",
    "    t_1d_input = tf.expand_dims(tf.expand_dims(t_1d_input, 2), 2)\n",
    "    \n",
    "    # Put channel dim at the end.\n",
    "    t_1d_input = np.moveaxis(t_1d_input, 1, -1)\n",
    "    \n",
    "    return t_1d_input\n",
    "\n",
    "def get_output(path):\n",
    "    # Load array.\n",
    "    t_output = np.load(path)\n",
    "    \n",
    "    # Put channel dim at the end.\n",
    "    t_output = np.moveaxis(t_output, 0, -1)\n",
    "    return t_output\n",
    "\n",
    "def data_generator(samples, num_samples, batch_size = 64, calculated_sample_weights = None):\n",
    "    \n",
    "    while True:\n",
    "        # Suffle data at the start of each epoch.\n",
    "        sample_indicies = np.arange(num_samples)\n",
    "        np.random.shuffle(sample_indicies)\n",
    "        n = 0\n",
    "        \n",
    "        while n + batch_size < num_samples:\n",
    "            # Get indicies for the batch\n",
    "            batch_samples  = sample_indicies[n:n + batch_size]\n",
    "            n += batch_size\n",
    "\n",
    "            batch_input_2d  = []\n",
    "            batch_input_1d  = []\n",
    "            batch_output = [] \n",
    "            batch_sample_weights = []\n",
    "\n",
    "            # Read in each input, perform preprocessing and get labels\n",
    "            for sample in batch_samples:\n",
    "                input_2d = get_2d_input(samples.iloc[sample].features_2d)\n",
    "                input_1d = get_1d_input(samples.iloc[sample].features_1d)\n",
    "                output = get_output(samples.iloc[sample].labels)\n",
    "                \n",
    "                batch_input_2d += [input_2d]\n",
    "                batch_input_1d += [input_1d]\n",
    "                batch_output += [output]\n",
    "\n",
    "                if type(calculated_sample_weights) != type(None):\n",
    "                    sample_weights = calculated_sample_weights[sample]\n",
    "                    batch_sample_weights += [sample_weights]\n",
    "                \n",
    "            # Return a tuple to feed the network\n",
    "            batch_x = np.array(batch_input_2d)\n",
    "            batch_v = np.array(batch_input_1d)\n",
    "            batch_y = np.array(batch_output)\n",
    "            \n",
    "            if type(calculated_sample_weights) == type(None):\n",
    "                yield([batch_x, batch_v], batch_y)\n",
    "            else:\n",
    "                batch_sample_weights = np.array(batch_sample_weights)\n",
    "                yield([batch_x, batch_v], batch_y, batch_sample_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ef16812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution for problem with class_weights not working with 3D outputs in tensorflow.\n",
    "# From: https://github.com/keras-team/keras/issues/3653\n",
    "def generate_sample_weights(training_data, class_weights): \n",
    "    #replaces values for up to 3 classes with the values from class_weights#\n",
    "    sample_weights = [np.where(y==0,class_weights[0],\n",
    "                        np.where(y==1,class_weights[1],\n",
    "                        y)) for y in training_data]\n",
    "    return np.asarray(sample_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dca14d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SSIM/PSNR loss functions.\n",
    "# Inspiration: https://stackoverflow.com/questions/57357146/use-ssim-loss-function-with-keras\n",
    "def ssim_loss(y_true, y_pred):\n",
    "    return 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, 1.0))\n",
    "\n",
    "def psnr_loss(y_true, y_pred):\n",
    "    return 100 - tf.reduce_mean(tf.image.psnr(y_true, y_pred, 1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9ebaa1",
   "metadata": {},
   "source": [
    "### Model Assembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf8370b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "top_features = 128\n",
    "condensed_features = 32\n",
    "upsample_filters = 256\n",
    "fc_filters = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d6ba115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs broken out by array and vector features.\n",
    "inputs_2d = layers.Input(shape=((10,32,32,2)))\n",
    "inputs_1d = layers.Input(shape=((10,1,1,192)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b5b15ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<KerasTensor: shape=(None, 10, 32, 32, 128) dtype=float32 (created by layer 'conv_lstm_top')>,\n",
       " <KerasTensor: shape=(None, 10, 16, 16, 128) dtype=float32 (created by layer 'conv_lstm_to16')>,\n",
       " <KerasTensor: shape=(None, 10, 8, 8, 128) dtype=float32 (created by layer 'conv_lstm_to8')>,\n",
       " <KerasTensor: shape=(None, 10, 4, 4, 128) dtype=float32 (created by layer 'conv_lstm_to4')>,\n",
       " <KerasTensor: shape=(None, 10, 2, 2, 128) dtype=float32 (created by layer 'conv_lstm_to2')>,\n",
       " <KerasTensor: shape=(None, 10, 1, 1, 64) dtype=float32 (created by layer 'conv_lstm_to1')>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Condense 10-day represenations to B * 2 * 2 * C shape.\n",
    "conv_a = layers.ConvLSTM2D(\n",
    "    filters=top_features,\n",
    "    kernel_size=(3, 3),\n",
    "    padding='same',\n",
    "    return_sequences=True,\n",
    "    activation='relu',\n",
    "    recurrent_dropout = 0,\n",
    "    name = 'conv_lstm_top'\n",
    ")(inputs_2d)\n",
    "conv_b = layers.ConvLSTM2D(\n",
    "    filters=top_features,\n",
    "    kernel_size=(2, 2),\n",
    "    strides = 2,\n",
    "    return_sequences=True,\n",
    "    activation='relu',\n",
    "    recurrent_dropout = 0,\n",
    "    name = 'conv_lstm_to16'\n",
    ")(conv_a)\n",
    "conv_c = layers.ConvLSTM2D(\n",
    "    filters=top_features,\n",
    "    kernel_size=(2, 2),\n",
    "    strides = 2,\n",
    "    return_sequences=True,\n",
    "    activation='relu',\n",
    "    recurrent_dropout = 0,\n",
    "    name = 'conv_lstm_to8'\n",
    ")(conv_b)\n",
    "conv_d = layers.ConvLSTM2D(\n",
    "    filters=top_features,\n",
    "    kernel_size=(2, 2),\n",
    "    strides = 2,\n",
    "    return_sequences=True,\n",
    "    activation='relu',\n",
    "    recurrent_dropout = 0,\n",
    "    name = 'conv_lstm_to4'\n",
    ")(conv_c)\n",
    "conv_e = layers.ConvLSTM2D(\n",
    "    filters=top_features,\n",
    "    kernel_size=(2, 2),\n",
    "    strides = 2,\n",
    "    return_sequences=True,\n",
    "    activation='relu',\n",
    "    recurrent_dropout = 0,\n",
    "    name = 'conv_lstm_to2'\n",
    ")(conv_d)\n",
    "conv_f = layers.ConvLSTM2D(\n",
    "    filters=64,\n",
    "    kernel_size=(2, 2),\n",
    "    strides = 2,\n",
    "    return_sequences=True,\n",
    "    activation='relu',\n",
    "    recurrent_dropout = 0,\n",
    "    name = 'conv_lstm_to1'\n",
    ")(conv_e)\n",
    "conv_a, conv_b, conv_c, conv_d, conv_e, conv_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d664e1a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 10, 1, 1, 256) dtype=float32 (created by layer 'concatenate')>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate vectorized features with 10-day fully-connected layer.\n",
    "vect_cat = tf.keras.layers.Concatenate()([conv_f, inputs_1d])\n",
    "vect_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c8e098e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<KerasTensor: shape=(None, 32, 32, 32) dtype=float32 (created by layer 'conv_lstm_top_daily')>,\n",
       " <KerasTensor: shape=(None, 16, 16, 64) dtype=float32 (created by layer 'conv_lstm_to16_daily')>,\n",
       " <KerasTensor: shape=(None, 8, 8, 128) dtype=float32 (created by layer 'conv_lstm_to8_daily')>,\n",
       " <KerasTensor: shape=(None, 4, 4, 256) dtype=float32 (created by layer 'conv_lstm_to4_daily')>,\n",
       " <KerasTensor: shape=(None, 2, 2, 512) dtype=float32 (created by layer 'conv_lstm_to2_daily')>,\n",
       " <KerasTensor: shape=(None, 1, 1, 256) dtype=float32 (created by layer 'conv_lstm_to1_daily')>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Condense 10-day representations down to single day.\n",
    "conv_a_daily = layers.ConvLSTM2D(\n",
    "    filters=condensed_features,\n",
    "    kernel_size=(3, 3),\n",
    "    padding='same',\n",
    "    return_sequences=False,\n",
    "    activation='relu',\n",
    "    recurrent_dropout = 0,\n",
    "    name = 'conv_lstm_top_daily'\n",
    ")(conv_a)\n",
    "conv_b_daily = layers.ConvLSTM2D(\n",
    "    filters=condensed_features * 2,\n",
    "    kernel_size=(3, 3),\n",
    "    padding='same',\n",
    "    return_sequences=False,\n",
    "    activation='relu',\n",
    "    recurrent_dropout = 0,\n",
    "    name = 'conv_lstm_to16_daily'\n",
    ")(conv_b)\n",
    "conv_c_daily = layers.ConvLSTM2D(\n",
    "    filters=condensed_features * 4,\n",
    "    kernel_size=(3, 3),\n",
    "    padding='same',\n",
    "    return_sequences=False,\n",
    "    activation='relu',\n",
    "    recurrent_dropout = 0,\n",
    "    name = 'conv_lstm_to8_daily'\n",
    ")(conv_c)\n",
    "conv_d_daily = layers.ConvLSTM2D(\n",
    "    filters=condensed_features * 8,\n",
    "    kernel_size=(3, 3),\n",
    "    padding='same',\n",
    "    return_sequences=False,\n",
    "    activation='relu',\n",
    "    recurrent_dropout = 0,\n",
    "    name = 'conv_lstm_to4_daily'\n",
    ")(conv_d)\n",
    "conv_e_daily = layers.ConvLSTM2D(\n",
    "    filters=condensed_features * 16,\n",
    "    kernel_size=(3, 3),\n",
    "    padding='same',\n",
    "    return_sequences=False,\n",
    "    activation='relu',\n",
    "    recurrent_dropout = 0,\n",
    "    name = 'conv_lstm_to2_daily'\n",
    ")(conv_e)\n",
    "conv_f_daily = layers.ConvLSTM2D(\n",
    "    filters=fc_filters,\n",
    "    kernel_size=(3, 3),\n",
    "    padding='same',\n",
    "    return_sequences=False,\n",
    "    activation='relu',\n",
    "    recurrent_dropout = 0,\n",
    "    name = 'conv_lstm_to1_daily'\n",
    ")(vect_cat)\n",
    "conv_a_daily, conv_b_daily, conv_c_daily, conv_d_daily, conv_e_daily, conv_f_daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "526779ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsample layers back to final shape using deconvolution.\n",
    "x = layers.Conv2D(upsample_filters, (3,3), padding=\"same\", activation='relu', name='UpConv_1_A')(conv_f_daily)\n",
    "x = layers.Conv2D(upsample_filters, (3,3), padding=\"same\", activation='relu', name='UpConv_1_B')(x)\n",
    "x = layers.Conv2DTranspose(upsample_filters, (3,3), strides=(2,2), activation='relu', padding='same', name = 'UpConv_to2')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.concatenate([x, conv_e_daily])\n",
    "x = layers.Conv2D(upsample_filters / 2, (3,3), padding=\"same\", activation='relu', name='UpConv_2_A')(x)\n",
    "x = layers.Conv2D(upsample_filters / 2, (3,3), padding=\"same\", activation='relu', name='UpConv_2_B')(x)\n",
    "x = layers.Conv2DTranspose(upsample_filters / 2, (3,3), strides=(2,2), activation='relu', padding='same', name = 'UpConv_to4')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.concatenate([x, conv_d_daily])\n",
    "x = layers.Conv2D(upsample_filters / 4, (3,3), padding=\"same\", activation='relu', name='UpConv_3_A')(x)\n",
    "x = layers.Conv2D(upsample_filters / 4, (3,3), padding=\"same\", activation='relu', name='UpConv_3_B')(x)\n",
    "x = layers.Conv2DTranspose(upsample_filters / 4, (3,3), strides=(2,2), activation='relu', padding='same', name = 'UpConv_to8')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.concatenate([x, conv_c_daily])\n",
    "x = layers.Conv2D(upsample_filters / 8, (3,3), padding=\"same\", activation='relu', name='UpConv_4_A')(x)\n",
    "x = layers.Conv2D(upsample_filters / 8, (3,3), padding=\"same\", activation='relu', name='UpConv_4_B')(x)\n",
    "x = layers.Conv2DTranspose(upsample_filters / 8, (3,3), strides=(2,2), activation='relu', padding='same', name = 'UpConv_to16')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.concatenate([x, conv_b_daily])\n",
    "x = layers.Conv2D(upsample_filters / 16, (3,3), padding=\"same\", activation='relu', name='UpConv_5_A')(x)\n",
    "x = layers.Conv2D(upsample_filters / 16, (3,3), padding=\"same\", activation='relu', name='UpConv_5_B')(x)\n",
    "x = layers.Conv2DTranspose(upsample_filters / 16, (3,3), strides=(2,2), activation='relu', padding='same', name = 'UpConv_to32')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.concatenate([x, conv_a_daily])\n",
    "x = layers.Conv2D(upsample_filters / 16, (3,3), padding=\"same\", activation='relu')(x)\n",
    "x = layers.Conv2D(upsample_filters / 16, (3,3), padding=\"same\", activation='relu')(x)\n",
    "outputs = layers.Conv2D(1, 1, padding='same', activation = 'sigmoid', name = 'outputs')(x)\n",
    "#outputs = tf.squeeze(x, axis = -1, name = 'squeezed_outputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a8eda4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "combo_model = tf.keras.Model(inputs = [inputs_2d, inputs_1d], outputs = outputs, name = 'lstm_u_net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c645b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"lstm_u_net\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 10, 32, 32,  0           []                               \n",
      "                                 2)]                                                              \n",
      "                                                                                                  \n",
      " conv_lstm_top (ConvLSTM2D)     (None, 10, 32, 32,   599552      ['input_1[0][0]']                \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv_lstm_to16 (ConvLSTM2D)    (None, 10, 16, 16,   524800      ['conv_lstm_top[0][0]']          \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv_lstm_to8 (ConvLSTM2D)     (None, 10, 8, 8, 12  524800      ['conv_lstm_to16[0][0]']         \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv_lstm_to4 (ConvLSTM2D)     (None, 10, 4, 4, 12  524800      ['conv_lstm_to8[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv_lstm_to2 (ConvLSTM2D)     (None, 10, 2, 2, 12  524800      ['conv_lstm_to4[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv_lstm_to1 (ConvLSTM2D)     (None, 10, 1, 1, 64  196864      ['conv_lstm_to2[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 10, 1, 1, 1  0           []                               \n",
      "                                92)]                                                              \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 10, 1, 1, 25  0           ['conv_lstm_to1[0][0]',          \n",
      "                                6)                                'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " conv_lstm_to1_daily (ConvLSTM2  (None, 1, 1, 256)   4719616     ['concatenate[0][0]']            \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " UpConv_1_A (Conv2D)            (None, 1, 1, 256)    590080      ['conv_lstm_to1_daily[0][0]']    \n",
      "                                                                                                  \n",
      " UpConv_1_B (Conv2D)            (None, 1, 1, 256)    590080      ['UpConv_1_A[0][0]']             \n",
      "                                                                                                  \n",
      " UpConv_to2 (Conv2DTranspose)   (None, 2, 2, 256)    590080      ['UpConv_1_B[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 2, 2, 256)   1024        ['UpConv_to2[0][0]']             \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv_lstm_to2_daily (ConvLSTM2  (None, 2, 2, 512)   11798528    ['conv_lstm_to2[0][0]']          \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 2, 2, 768)    0           ['batch_normalization[0][0]',    \n",
      "                                                                  'conv_lstm_to2_daily[0][0]']    \n",
      "                                                                                                  \n",
      " UpConv_2_A (Conv2D)            (None, 2, 2, 128)    884864      ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " UpConv_2_B (Conv2D)            (None, 2, 2, 128)    147584      ['UpConv_2_A[0][0]']             \n",
      "                                                                                                  \n",
      " UpConv_to4 (Conv2DTranspose)   (None, 4, 4, 128)    147584      ['UpConv_2_B[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 4, 4, 128)   512         ['UpConv_to4[0][0]']             \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv_lstm_to4_daily (ConvLSTM2  (None, 4, 4, 256)   3539968     ['conv_lstm_to4[0][0]']          \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 4, 4, 384)    0           ['batch_normalization_1[0][0]',  \n",
      "                                                                  'conv_lstm_to4_daily[0][0]']    \n",
      "                                                                                                  \n",
      " UpConv_3_A (Conv2D)            (None, 4, 4, 64)     221248      ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " UpConv_3_B (Conv2D)            (None, 4, 4, 64)     36928       ['UpConv_3_A[0][0]']             \n",
      "                                                                                                  \n",
      " UpConv_to8 (Conv2DTranspose)   (None, 8, 8, 64)     36928       ['UpConv_3_B[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 8, 8, 64)    256         ['UpConv_to8[0][0]']             \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv_lstm_to8_daily (ConvLSTM2  (None, 8, 8, 128)   1180160     ['conv_lstm_to8[0][0]']          \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 8, 8, 192)    0           ['batch_normalization_2[0][0]',  \n",
      "                                                                  'conv_lstm_to8_daily[0][0]']    \n",
      "                                                                                                  \n",
      " UpConv_4_A (Conv2D)            (None, 8, 8, 32)     55328       ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " UpConv_4_B (Conv2D)            (None, 8, 8, 32)     9248        ['UpConv_4_A[0][0]']             \n",
      "                                                                                                  \n",
      " UpConv_to16 (Conv2DTranspose)  (None, 16, 16, 32)   9248        ['UpConv_4_B[0][0]']             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 16, 16, 32)  128         ['UpConv_to16[0][0]']            \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv_lstm_to16_daily (ConvLSTM  (None, 16, 16, 64)  442624      ['conv_lstm_to16[0][0]']         \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 16, 16, 96)   0           ['batch_normalization_3[0][0]',  \n",
      "                                                                  'conv_lstm_to16_daily[0][0]']   \n",
      "                                                                                                  \n",
      " UpConv_5_A (Conv2D)            (None, 16, 16, 16)   13840       ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " UpConv_5_B (Conv2D)            (None, 16, 16, 16)   2320        ['UpConv_5_A[0][0]']             \n",
      "                                                                                                  \n",
      " UpConv_to32 (Conv2DTranspose)  (None, 32, 32, 16)   2320        ['UpConv_5_B[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 32, 32, 16)  64          ['UpConv_to32[0][0]']            \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv_lstm_top_daily (ConvLSTM2  (None, 32, 32, 32)  184448      ['conv_lstm_top[0][0]']          \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 32, 32, 48)   0           ['batch_normalization_4[0][0]',  \n",
      "                                                                  'conv_lstm_top_daily[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 32, 32, 16)   6928        ['concatenate_5[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 32, 32, 16)   2320        ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " outputs (Conv2D)               (None, 32, 32, 1)    17          ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 28,109,889\n",
      "Trainable params: 28,108,897\n",
      "Non-trainable params: 992\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "combo_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae43747a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model.\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "#loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "combo_model.compile(loss=loss_fn, \n",
    "                    optimizer=opt, \n",
    "                    metrics=[tf.keras.metrics.MeanSquaredError(name='MSE'),\n",
    "                             tf.keras.metrics.AUC(name='AUC'),\n",
    "                             ssim_loss,\n",
    "                             psnr_loss\n",
    "                            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8208ab51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4, 32, 32, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test on dummy data to see that shapes look right.\n",
    "img_batch = tf.zeros([4,10,32,32,2], dtype = 'float32')\n",
    "vector_batch = tf.zeros([4,10,1,1,192], dtype = 'float32')\n",
    "combo_model.predict([img_batch, vector_batch]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8adc91c",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38d6b54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata on yearly datasets.\n",
    "df_2017 = pd.read_csv('4fold_super/2017/meta.csv')\n",
    "df_2018 = pd.read_csv('4fold_super/2018/meta.csv')\n",
    "df_2019 = pd.read_csv('4fold_super/2019/meta.csv')\n",
    "df_2020 = pd.read_csv('4fold_super/2020/meta.csv')\n",
    "\n",
    "# Combine into desired train/val split.\n",
    "meta_t = pd.concat([df_2017,df_2018,df_2019]).reset_index()\n",
    "meta_v = df_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8f2472f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.5049593185573996, 1: 50.910151537247934}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load all labels from the training set into memory to get weights\n",
    "y_train = []\n",
    "\n",
    "# Iterate over dataset.\n",
    "for x in range(0,len(meta_t)):\n",
    "    y_train.append(np.load(meta_t.iloc[x].labels))\n",
    "\n",
    "y_train = np.stack(y_train)\n",
    "y_train = np.minimum(y_train,1)\n",
    "y_train = tf.expand_dims(y_train, axis = -1).numpy()\n",
    "\n",
    "# Get class weights for WBCE/MSE.\n",
    "weights = class_weight.compute_class_weight('balanced',\n",
    "                                            classes = [0,1],\n",
    "                                            y = y_train.flatten())\n",
    "# Examine weights.\n",
    "weights_dict = {0:weights[0], 1:weights[1]}\n",
    "weights_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "634b5158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get weights.\n",
    "calculated_sample_weights = generate_sample_weights(y_train, weights)\n",
    "\n",
    "# Drop y_train to save memory.\n",
    "y_train = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c820ec02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loaders.\n",
    "batch_size = 32\n",
    "t_gen = data_generator(meta_t, len(meta_t), batch_size = batch_size, calculated_sample_weights = calculated_sample_weights[:,0])\n",
    "v_gen = data_generator(meta_v, len(meta_v), batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32657102",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "502f5f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "468/468 [==============================] - 436s 892ms/step - loss: 0.3310 - MSE: 0.2471 - AUC: 0.7669 - ssim_loss: 0.9969 - psnr_loss: 93.4455 - val_loss: 0.3207 - val_MSE: 0.3207 - val_AUC: 0.8624 - val_ssim_loss: 0.9939 - val_psnr_loss: 94.9199 - lr: 1.0000e-04\n",
      "Epoch 2/400\n",
      "468/468 [==============================] - 428s 916ms/step - loss: 0.2362 - MSE: 0.1490 - AUC: 0.8970 - ssim_loss: 0.9894 - psnr_loss: 89.6906 - val_loss: 0.3255 - val_MSE: 0.3255 - val_AUC: 0.9090 - val_ssim_loss: 0.9957 - val_psnr_loss: 94.4384 - lr: 1.0000e-04\n",
      "Epoch 3/400\n",
      "468/468 [==============================] - 433s 925ms/step - loss: 0.2222 - MSE: 0.1392 - AUC: 0.9116 - ssim_loss: 0.9843 - psnr_loss: 88.8818 - val_loss: 0.1759 - val_MSE: 0.1759 - val_AUC: 0.9152 - val_ssim_loss: 0.9887 - val_psnr_loss: 90.6824 - lr: 1.0000e-04\n",
      "Epoch 4/400\n",
      "468/468 [==============================] - 433s 924ms/step - loss: 0.2181 - MSE: 0.1373 - AUC: 0.9162 - ssim_loss: 0.9820 - psnr_loss: 88.7641 - val_loss: 0.0784 - val_MSE: 0.0784 - val_AUC: 0.9138 - val_ssim_loss: 0.8093 - val_psnr_loss: 84.0433 - lr: 1.0000e-04\n",
      "Epoch 5/400\n",
      "468/468 [==============================] - 426s 910ms/step - loss: 0.2146 - MSE: 0.1337 - AUC: 0.9192 - ssim_loss: 0.9816 - psnr_loss: 88.6500 - val_loss: 0.1246 - val_MSE: 0.1246 - val_AUC: 0.9192 - val_ssim_loss: 0.8938 - val_psnr_loss: 87.7290 - lr: 1.0000e-04\n",
      "Epoch 6/400\n",
      "468/468 [==============================] - 433s 926ms/step - loss: 0.2128 - MSE: 0.1330 - AUC: 0.9208 - ssim_loss: 0.9797 - psnr_loss: 88.6076 - val_loss: 0.2693 - val_MSE: 0.2693 - val_AUC: 0.8919 - val_ssim_loss: 0.9948 - val_psnr_loss: 93.8679 - lr: 1.0000e-04\n",
      "Epoch 7/400\n",
      "468/468 [==============================] - ETA: 0s - loss: 0.2107 - MSE: 0.1309 - AUC: 0.9231 - ssim_loss: 0.9794 - psnr_loss: 88.5856\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "468/468 [==============================] - 434s 928ms/step - loss: 0.2107 - MSE: 0.1309 - AUC: 0.9231 - ssim_loss: 0.9794 - psnr_loss: 88.5856 - val_loss: 0.0897 - val_MSE: 0.0897 - val_AUC: 0.9158 - val_ssim_loss: 0.9101 - val_psnr_loss: 85.9641 - lr: 1.0000e-04\n",
      "Epoch 8/400\n",
      "468/468 [==============================] - 426s 911ms/step - loss: 0.2049 - MSE: 0.1268 - AUC: 0.9276 - ssim_loss: 0.9813 - psnr_loss: 88.4833 - val_loss: 0.1790 - val_MSE: 0.1790 - val_AUC: 0.9184 - val_ssim_loss: 0.9899 - val_psnr_loss: 90.9933 - lr: 1.0000e-05\n",
      "Epoch 9/400\n",
      "468/468 [==============================] - 448s 958ms/step - loss: 0.2031 - MSE: 0.1256 - AUC: 0.9289 - ssim_loss: 0.9764 - psnr_loss: 88.3942 - val_loss: 0.1135 - val_MSE: 0.1135 - val_AUC: 0.9210 - val_ssim_loss: 0.9526 - val_psnr_loss: 87.7355 - lr: 1.0000e-05\n",
      "Epoch 10/400\n",
      "468/468 [==============================] - ETA: 0s - loss: 0.2022 - MSE: 0.1245 - AUC: 0.9296 - ssim_loss: 0.9755 - psnr_loss: 88.3154\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "468/468 [==============================] - 428s 915ms/step - loss: 0.2022 - MSE: 0.1245 - AUC: 0.9296 - ssim_loss: 0.9755 - psnr_loss: 88.3154 - val_loss: 0.1895 - val_MSE: 0.1895 - val_AUC: 0.9139 - val_ssim_loss: 0.9902 - val_psnr_loss: 91.3844 - lr: 1.0000e-05\n",
      "Epoch 11/400\n",
      "468/468 [==============================] - 414s 885ms/step - loss: 0.2010 - MSE: 0.1229 - AUC: 0.9305 - ssim_loss: 0.9758 - psnr_loss: 88.2664 - val_loss: 0.1238 - val_MSE: 0.1238 - val_AUC: 0.9199 - val_ssim_loss: 0.9667 - val_psnr_loss: 88.4122 - lr: 1.0000e-06\n",
      "Epoch 12/400\n",
      "468/468 [==============================] - 413s 884ms/step - loss: 0.2008 - MSE: 0.1240 - AUC: 0.9306 - ssim_loss: 0.9753 - psnr_loss: 88.2981 - val_loss: 0.1309 - val_MSE: 0.1309 - val_AUC: 0.9195 - val_ssim_loss: 0.9730 - val_psnr_loss: 88.7868 - lr: 1.0000e-06\n",
      "Epoch 13/400\n",
      "468/468 [==============================] - ETA: 0s - loss: 0.2005 - MSE: 0.1231 - AUC: 0.9307 - ssim_loss: 0.9746 - psnr_loss: 88.2357\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "468/468 [==============================] - 418s 893ms/step - loss: 0.2005 - MSE: 0.1231 - AUC: 0.9307 - ssim_loss: 0.9746 - psnr_loss: 88.2357 - val_loss: 0.1283 - val_MSE: 0.1283 - val_AUC: 0.9194 - val_ssim_loss: 0.9701 - val_psnr_loss: 88.6590 - lr: 1.0000e-06\n",
      "Epoch 14/400\n",
      "468/468 [==============================] - 419s 896ms/step - loss: 0.2003 - MSE: 0.1225 - AUC: 0.9308 - ssim_loss: 0.9746 - psnr_loss: 88.2410 - val_loss: 0.1376 - val_MSE: 0.1376 - val_AUC: 0.9185 - val_ssim_loss: 0.9764 - val_psnr_loss: 89.1224 - lr: 1.0000e-07\n",
      "Epoch 15/400\n",
      "468/468 [==============================] - 416s 888ms/step - loss: 0.2005 - MSE: 0.1229 - AUC: 0.9307 - ssim_loss: 0.9745 - psnr_loss: 88.2471 - val_loss: 0.1382 - val_MSE: 0.1382 - val_AUC: 0.9192 - val_ssim_loss: 0.9766 - val_psnr_loss: 89.1884 - lr: 1.0000e-07\n",
      "Epoch 16/400\n",
      "468/468 [==============================] - ETA: 0s - loss: 0.2005 - MSE: 0.1229 - AUC: 0.9307 - ssim_loss: 0.9745 - psnr_loss: 88.2510Restoring model weights from the end of the best epoch: 4.\n",
      "\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n",
      "468/468 [==============================] - 416s 889ms/step - loss: 0.2005 - MSE: 0.1229 - AUC: 0.9307 - ssim_loss: 0.9745 - psnr_loss: 88.2510 - val_loss: 0.1384 - val_MSE: 0.1384 - val_AUC: 0.9194 - val_ssim_loss: 0.9764 - val_psnr_loss: 89.1575 - lr: 1.0000e-07\n",
      "Epoch 16: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x176deec13d0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding callbacks.\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, verbose=1, restore_best_weights=True)\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=1, verbose=1)\n",
    "\n",
    "# Train model.\n",
    "combo_model.fit(t_gen, \n",
    "                   epochs = 100, \n",
    "                   verbose = 1, \n",
    "                   batch_size = batch_size,\n",
    "                   validation_data = v_gen,\n",
    "                   callbacks = [early_stopping, reduce_lr],\n",
    "                   steps_per_epoch = len(meta_t) // batch_size,\n",
    "                   validation_steps = len(meta_v) // batch_size\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3b4822c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 18). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Models/CM4_2020\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Models/CM4_2020\\assets\n"
     ]
    }
   ],
   "source": [
    "combo_model.save('Models/CM4_2020')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c3d1009",
   "metadata": {},
   "outputs": [],
   "source": [
    "#combo_model = tf.keras.models.load_model('Models/CM1_2020', custom_objects = {'ssim_loss': ssim_loss, 'psnr_loss': psnr_loss})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbaf507d",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "59c292f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get entire validation set.\n",
    "x_val, v_val, y_val = [],[],[]\n",
    "for x in range(0,len(meta_v)):\n",
    "    x_val.append(np.load(meta_v.iloc[x].features_2d))\n",
    "    v_val.append(np.load(meta_v.iloc[x].features_1d))\n",
    "    y_val.append(np.load(meta_v.iloc[x].labels))\n",
    "    \n",
    "x_val = np.stack(x_val)\n",
    "v_val = np.stack(v_val)\n",
    "y_val = np.stack(y_val)\n",
    "\n",
    "# Dimension wrangling.\n",
    "v_val = tf.expand_dims(tf.expand_dims(v_val, 2), 2)\n",
    "y_val = np.moveaxis(y_val, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b013d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 33s 197ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict on all samples.\n",
    "all_preds = combo_model.predict([x_val, v_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e514643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Prediction Report\n",
      "SSIM: 0.19108872\n",
      "PSNR: 0.15968837\n",
      "MSE: 0.0781578\n"
     ]
    }
   ],
   "source": [
    "# Compute and show set scores.\n",
    "set_ssim = tf.image.ssim(tf.cast(y_val, dtype='float32'), all_preds, 1.0)\n",
    "set_psnr = tf.image.psnr(tf.cast(y_val, dtype='float32'), all_preds, 1.0)\n",
    "set_mse = tf.keras.metrics.mean_squared_error(y_val, all_preds)\n",
    "print('Model Prediction Report')\n",
    "print('SSIM:', np.mean(set_ssim))\n",
    "print('PSNR:', np.mean(set_psnr/100))\n",
    "print('MSE:', np.mean(set_mse))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
