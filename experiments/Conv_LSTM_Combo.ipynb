{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b873262",
   "metadata": {},
   "source": [
    "### Import Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b39397e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.utils import class_weight\n",
    "import skimage.measure\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826ee2d5",
   "metadata": {},
   "source": [
    "### Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cc6c49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loader functions\n",
    "# Inspiration: https://towardsdatascience.com/writing-custom-keras-generators-fe815d992c5a\n",
    "\n",
    "def get_2d_input(path):\n",
    "    # Load array.\n",
    "    t_2d_input = np.load(path)\n",
    "    \n",
    "    #return t_2d_input\n",
    "    return t_2d_input\n",
    "\n",
    "def get_1d_input(path):\n",
    "    # Load array.\n",
    "    t_1d_input = np.load(path)\n",
    "    \n",
    "    # Expand dimensions to match model input.\n",
    "    t_1d_input = tf.expand_dims(tf.expand_dims(t_1d_input, 2), 2)\n",
    "    \n",
    "    # Put channel dim at the end.\n",
    "    t_1d_input = np.moveaxis(t_1d_input, 1, -1)\n",
    "    \n",
    "    return t_1d_input\n",
    "\n",
    "def get_output(path):\n",
    "    # Load array.\n",
    "    t_output = np.load(path)\n",
    "    \n",
    "    # Put channel dim at the end.\n",
    "    t_output = np.moveaxis(t_output, 0, -1)\n",
    "    return t_output\n",
    "\n",
    "def data_generator(samples, num_samples, batch_size = 64, calculated_sample_weights = None):\n",
    "    \n",
    "    while True:\n",
    "        # Suffle data at the start of each epoch.\n",
    "        sample_indicies = np.arange(num_samples)\n",
    "        np.random.shuffle(sample_indicies)\n",
    "        n = 0\n",
    "        \n",
    "        while n + batch_size < num_samples:\n",
    "            # Get indicies for the batch\n",
    "            batch_samples  = sample_indicies[n:n + batch_size]\n",
    "            n += batch_size\n",
    "\n",
    "            batch_input_2d  = []\n",
    "            batch_input_1d  = []\n",
    "            batch_output = [] \n",
    "            batch_sample_weights = []\n",
    "\n",
    "            # Read in each input, perform preprocessing and get labels\n",
    "            for sample in batch_samples:\n",
    "                input_2d = get_2d_input(samples.iloc[sample].features_2d)\n",
    "                input_1d = get_1d_input(samples.iloc[sample].features_1d)\n",
    "                output = get_output(samples.iloc[sample].labels)\n",
    "                \n",
    "                batch_input_2d += [input_2d]\n",
    "                batch_input_1d += [input_1d]\n",
    "                batch_output += [output]\n",
    "\n",
    "                if type(calculated_sample_weights) != type(None):\n",
    "                    sample_weights = calculated_sample_weights[sample]\n",
    "                    batch_sample_weights += [sample_weights]\n",
    "                \n",
    "            # Return a tuple to feed the network\n",
    "            batch_x = np.array(batch_input_2d)\n",
    "            batch_v = np.array(batch_input_1d)\n",
    "            batch_y = np.minimum(np.array(batch_output),1)\n",
    "            \n",
    "            if type(calculated_sample_weights) == type(None):\n",
    "                yield([batch_x[:,:,:,:,:1], tf.squeeze(batch_x[:,:1,:,:,1:2], axis = 1), batch_v], batch_y)\n",
    "            else:\n",
    "                batch_sample_weights = np.array(batch_sample_weights)\n",
    "                yield([batch_x[:,:,:,:,:1], tf.squeeze(batch_x[:,:1,:,:,1:2], axis = 1), batch_v], batch_y, batch_sample_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b19ca035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution for problem with class_weights not working with 3D outputs in tensorflow.\n",
    "# From: https://github.com/keras-team/keras/issues/3653\n",
    "def generate_sample_weights(training_data, class_weights): \n",
    "    #replaces values for up to 3 classes with the values from class_weights#\n",
    "    sample_weights = [np.where(y==0,class_weights[0],\n",
    "                        np.where(y==1,class_weights[1],\n",
    "                        y)) for y in training_data]\n",
    "    return np.asarray(sample_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ff8eca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SSIM/PSNR loss functions.\n",
    "# Inspiration: https://stackoverflow.com/questions/57357146/use-ssim-loss-function-with-keras\n",
    "def ssim_loss(y_true, y_pred):\n",
    "    return 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, 1.0))\n",
    "\n",
    "def psnr_loss(y_true, y_pred):\n",
    "    return 100 - tf.reduce_mean(tf.image.psnr(y_true, y_pred, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65713e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dice loss functions.\n",
    "# From: https://stackoverflow.com/questions/72195156/correct-implementation-of-dice-loss-in-tensorflow-keras\n",
    "def dice_coef(y_true, y_pred, smooth=100):        \n",
    "    y_true_f = tf.keras.backend.flatten(y_true)\n",
    "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
    "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
    "    dice = (2. * intersection + smooth) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + smooth)\n",
    "    return dice\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1 - dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9621ad",
   "metadata": {},
   "source": [
    "### Model Assembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cc8a4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"fire_encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " fire_time_feature_1 (ConvLS  (None, 10, 32, 32, 128)  1651712   \n",
      " TM2D)                                                           \n",
      "                                                                 \n",
      " fire_time_feature_2 (ConvLS  (None, 10, 32, 32, 64)   442624    \n",
      " TM2D)                                                           \n",
      "                                                                 \n",
      " fire_to_2D (ConvLSTM2D)     (None, 32, 32, 64)        33024     \n",
      "                                                                 \n",
      " output (Conv2D)             (None, 32, 32, 1)         65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,127,425\n",
      "Trainable params: 2,127,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fire_encoder = tf.keras.models.load_model('Models/MINST_Agg_01'\n",
    "                                         , custom_objects = {'ssim_loss': ssim_loss, 'psnr_loss': psnr_loss})\n",
    "fire_encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b8a6562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"defo_encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " defo_input (InputLayer)     [(None, 32, 32, 1)]       0         \n",
      "                                                                 \n",
      " defo_conv_A (Conv2D)        (None, 32, 32, 128)       3328      \n",
      "                                                                 \n",
      " defo_conv_B (Conv2D)        (None, 32, 32, 64)        73792     \n",
      "                                                                 \n",
      " defo_conv_C (Conv2D)        (None, 32, 32, 32)        2080      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79,200\n",
      "Trainable params: 79,200\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "defo_input = layers.Input(shape = ((32,32,1)), name = 'defo_input')\n",
    "d = layers.Conv2D(128, (5,5), padding = 'same', name = 'defo_conv_A', activation = 'relu')(defo_input)\n",
    "d = layers.Conv2D(64, (3,3), padding = 'same', name = 'defo_conv_B', activation = 'relu')(d)\n",
    "d = layers.Conv2D(32, (1,1), padding = 'same', name = 'defo_conv_C', activation = 'relu')(d)\n",
    "\n",
    "defo_encoder = tf.keras.Model(inputs = defo_input, outputs = d, name = 'defo_encoder')\n",
    "defo_encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31c06077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"precip_encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " precip_input (InputLayer)   [(None, 10, 1, 1, 192)]   0         \n",
      "                                                                 \n",
      " precip_time_features (ConvL  (None, 10, 1, 1, 128)    164352    \n",
      " STM2D)                                                          \n",
      "                                                                 \n",
      " precip_to_FC (ConvLSTM2D)   (None, 1, 1, 32)          20608     \n",
      "                                                                 \n",
      " precip_to_grid_2x2 (Conv2DT  (None, 2, 2, 32)         4128      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " precip_to_grid_4x4 (Conv2DT  (None, 4, 4, 32)         9248      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " precip_to_grid_8x8 (Conv2DT  (None, 8, 8, 32)         9248      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " precip_to_grid_16x16 (Conv2  (None, 16, 16, 32)       9248      \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " precip_to_grid_32x32 (Conv2  (None, 32, 32, 32)       9248      \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 226,080\n",
      "Trainable params: 226,080\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "precip_input = layers.Input(shape = ((10,1,1,192)), name = 'precip_input')\n",
    "p = layers.ConvLSTM2D(\n",
    "    filters=128,\n",
    "    kernel_size=(1, 1),\n",
    "    padding='same',\n",
    "    return_sequences=True,\n",
    "    activation = 'relu',\n",
    "    name = 'precip_time_features')(precip_input)\n",
    "p = layers.ConvLSTM2D(\n",
    "    filters=32,\n",
    "    kernel_size=(1, 1),\n",
    "    padding='same',\n",
    "    return_sequences=False,\n",
    "    activation = 'relu',\n",
    "    name = 'precip_to_FC')(p)\n",
    "p = layers.Conv2DTranspose(32, (2,2), strides=(2,2), activation='relu', padding='same', name = 'precip_to_grid_2x2')(p)\n",
    "p = layers.Conv2DTranspose(32, (3,3), strides=(2,2), activation='relu', padding='same', name = 'precip_to_grid_4x4')(p)\n",
    "p = layers.Conv2DTranspose(32, (3,3), strides=(2,2), activation='relu', padding='same', name = 'precip_to_grid_8x8')(p)\n",
    "p = layers.Conv2DTranspose(32, (3,3), strides=(2,2), activation='relu', padding='same', name = 'precip_to_grid_16x16')(p)\n",
    "p = layers.Conv2DTranspose(32, (3,3), strides=(2,2), activation='relu', padding='same', name = 'precip_to_grid_32x32')(p)\n",
    "\n",
    "precip_encoder = tf.keras.Model(inputs = precip_input, outputs = p, name = 'precip_encoder')\n",
    "precip_encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63b5c33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " precip_input (InputLayer)      [(None, 10, 1, 1, 1  0           []                               \n",
      "                                92)]                                                              \n",
      "                                                                                                  \n",
      " precip_time_features (ConvLSTM  (None, 10, 1, 1, 12  164352     ['precip_input[0][0]']           \n",
      " 2D)                            8)                                                                \n",
      "                                                                                                  \n",
      " precip_to_FC (ConvLSTM2D)      (None, 1, 1, 32)     20608       ['precip_time_features[0][0]']   \n",
      "                                                                                                  \n",
      " precip_to_grid_2x2 (Conv2DTran  (None, 2, 2, 32)    4128        ['precip_to_FC[0][0]']           \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " fire_input (InputLayer)        [(None, 10, 32, 32,  0           []                               \n",
      "                                 1)]                                                              \n",
      "                                                                                                  \n",
      " defo_input (InputLayer)        [(None, 32, 32, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " precip_to_grid_4x4 (Conv2DTran  (None, 4, 4, 32)    9248        ['precip_to_grid_2x2[0][0]']     \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " fire_time_feature_1 (ConvLSTM2  (None, 10, 32, 32,   1651712    ['fire_input[0][0]']             \n",
      " D)                             128)                                                              \n",
      "                                                                                                  \n",
      " defo_conv_A (Conv2D)           (None, 32, 32, 128)  3328        ['defo_input[0][0]']             \n",
      "                                                                                                  \n",
      " precip_to_grid_8x8 (Conv2DTran  (None, 8, 8, 32)    9248        ['precip_to_grid_4x4[0][0]']     \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " fire_time_feature_2 (ConvLSTM2  (None, 10, 32, 32,   442624     ['fire_time_feature_1[0][0]']    \n",
      " D)                             64)                                                               \n",
      "                                                                                                  \n",
      " defo_conv_B (Conv2D)           (None, 32, 32, 64)   73792       ['defo_conv_A[0][0]']            \n",
      "                                                                                                  \n",
      " precip_to_grid_16x16 (Conv2DTr  (None, 16, 16, 32)  9248        ['precip_to_grid_8x8[0][0]']     \n",
      " anspose)                                                                                         \n",
      "                                                                                                  \n",
      " fire_to_2D (ConvLSTM2D)        (None, 32, 32, 64)   33024       ['fire_time_feature_2[0][0]']    \n",
      "                                                                                                  \n",
      " defo_conv_C (Conv2D)           (None, 32, 32, 32)   2080        ['defo_conv_B[0][0]']            \n",
      "                                                                                                  \n",
      " precip_to_grid_32x32 (Conv2DTr  (None, 32, 32, 32)  9248        ['precip_to_grid_16x16[0][0]']   \n",
      " anspose)                                                                                         \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 32, 32, 128)  0           ['fire_to_2D[0][0]',             \n",
      "                                                                  'defo_conv_C[0][0]',            \n",
      "                                                                  'precip_to_grid_32x32[0][0]']   \n",
      "                                                                                                  \n",
      " combo_conv_A (Conv2D)          (None, 32, 32, 64)   73792       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " combo_conv_B (Conv2D)          (None, 32, 32, 64)   36928       ['combo_conv_A[0][0]']           \n",
      "                                                                                                  \n",
      " combo_output (Conv2D)          (None, 32, 32, 1)    65          ['combo_conv_B[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,543,425\n",
      "Trainable params: 2,543,425\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fire_encoder_headless = tf.keras.Model(inputs=fire_encoder.input, outputs=fire_encoder.get_layer('fire_to_2D').output)\n",
    "cat_layer = layers.Concatenate(axis = -1)\n",
    "features_cat = cat_layer([fire_encoder_headless.output, defo_encoder.output, precip_encoder.output])\n",
    "c = layers.Conv2D(64, (3,3), padding = 'same', name = 'combo_conv_A', activation = 'relu')(features_cat)\n",
    "c = layers.Conv2D(64, (3,3), padding = 'same', name = 'combo_conv_B', activation = 'relu')(c)\n",
    "combo_out = layers.Conv2D(1, (1,1), padding = 'same', name = 'combo_output', activation = 'relu')(c)\n",
    "\n",
    "combo_model = tf.keras.Model(inputs = (fire_encoder.input, defo_encoder.input, precip_encoder.input),\n",
    "                             outputs = combo_out)\n",
    "combo_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9dec2eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model.\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "#loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "#loss_fn = ssim_loss()\n",
    "#loss_fn = dice_coef_loss\n",
    "combo_model.compile(loss=loss_fn, \n",
    "                    optimizer=opt, \n",
    "                    metrics=[tf.keras.metrics.MeanSquaredError(name='MSE'),\n",
    "                             tf.keras.metrics.AUC(name='AUC'),\n",
    "                             ssim_loss,\n",
    "                             psnr_loss\n",
    "                            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9404c289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 974ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8, 32, 32, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test on dummy data to see that shapes look right.\n",
    "fire_batch = tf.zeros([8,10,32,32,1], dtype = 'float32')\n",
    "defo_batch = tf.zeros([8,32,32,1], dtype = 'float32')\n",
    "precip_batch = tf.zeros([8,10,1,1,192], dtype = 'float32')\n",
    "combo_model.predict((fire_batch, defo_batch, precip_batch)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeda2405",
   "metadata": {},
   "source": [
    "### Train model on combined dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8398b51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precip_input True\n",
      "precip_time_features True\n",
      "precip_to_FC True\n",
      "precip_to_grid_2x2 True\n",
      "fire_input False\n",
      "defo_input True\n",
      "precip_to_grid_4x4 True\n",
      "fire_time_feature_1 False\n",
      "defo_conv_A True\n",
      "precip_to_grid_8x8 True\n",
      "fire_time_feature_2 False\n",
      "defo_conv_B True\n",
      "precip_to_grid_16x16 True\n",
      "fire_to_2D False\n",
      "defo_conv_C True\n",
      "precip_to_grid_32x32 True\n",
      "concatenate True\n",
      "combo_conv_A True\n",
      "combo_conv_B True\n",
      "combo_output True\n"
     ]
    }
   ],
   "source": [
    "# Freeze layers of the motion encoder to start, because it's already pretrained on MNIST.\n",
    "combo_model.layers[4].trainable = False\n",
    "combo_model.layers[7].trainable = False\n",
    "combo_model.layers[10].trainable = False\n",
    "combo_model.layers[13].trainable = False\n",
    "\n",
    "# Confirm that the right layers are frozen.\n",
    "for t_layer in combo_model.layers:\n",
    "    print(t_layer.name, t_layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "225a1e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\covad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass classes=[0, 1], y=[0. 0. 0. ... 0. 0. 0.] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    }
   ],
   "source": [
    "# Load metadata on yearly datasets.\n",
    "df_2017 = pd.read_csv('4fold_super/2017/meta.csv')\n",
    "df_2018 = pd.read_csv('4fold_super/2018/meta.csv')\n",
    "df_2019 = pd.read_csv('4fold_super/2019/meta.csv')\n",
    "df_2020 = pd.read_csv('4fold_super/2020/meta.csv')\n",
    "\n",
    "# Combine into desired train/val split.\n",
    "meta_t = pd.concat([df_2017, df_2018, df_2019]).reset_index()\n",
    "meta_v = df_2020\n",
    "\n",
    "# Get all labels for use in calculating weights.\n",
    "y_train = []\n",
    "for x in range(0,len(meta_t)):\n",
    "    y_train.append(np.load(meta_t.iloc[x].labels))\n",
    "y_train = np.stack(y_train)\n",
    "y_train = np.minimum(y_train,1)\n",
    "y_train = np.moveaxis(y_train, 1, -1)\n",
    "\n",
    "# Get weights.\n",
    "weights = class_weight.compute_class_weight('balanced',\n",
    "                                            [0,1],\n",
    "                                            y_train.flatten())\n",
    "calculated_sample_weights = generate_sample_weights(y_train, weights)\n",
    "\n",
    "# Get generators.\n",
    "batch_size = 32\n",
    "t_gen = data_generator(meta_t, len(meta_t), batch_size = batch_size, calculated_sample_weights = calculated_sample_weights)\n",
    "v_gen = data_generator(meta_v, len(meta_v), batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8bd392e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "468/468 [==============================] - 343s 717ms/step - loss: 0.4714 - MSE: 0.1234 - AUC: 0.8672 - ssim_loss: 0.9942 - psnr_loss: 90.2123 - val_loss: 0.4093 - val_MSE: 0.1199 - val_AUC: 0.8991 - val_ssim_loss: 0.9925 - val_psnr_loss: 90.0801 - lr: 1.0000e-04\n",
      "Epoch 2/20\n",
      "468/468 [==============================] - 334s 714ms/step - loss: 0.4232 - MSE: 0.1172 - AUC: 0.8856 - ssim_loss: 0.9932 - psnr_loss: 89.9306 - val_loss: 0.4459 - val_MSE: 0.1278 - val_AUC: 0.9057 - val_ssim_loss: 0.9919 - val_psnr_loss: 90.3248 - lr: 1.0000e-04\n",
      "Epoch 3/20\n",
      "468/468 [==============================] - 333s 713ms/step - loss: 0.4174 - MSE: 0.1187 - AUC: 0.8890 - ssim_loss: 0.9926 - psnr_loss: 89.9187 - val_loss: 0.3705 - val_MSE: 0.1141 - val_AUC: 0.9008 - val_ssim_loss: 0.9927 - val_psnr_loss: 89.8322 - lr: 1.0000e-04\n",
      "Epoch 4/20\n",
      "468/468 [==============================] - 334s 713ms/step - loss: 0.4246 - MSE: 0.1234 - AUC: 0.8858 - ssim_loss: 0.9930 - psnr_loss: 90.0464 - val_loss: 0.5240 - val_MSE: 0.1599 - val_AUC: 0.9067 - val_ssim_loss: 0.9935 - val_psnr_loss: 91.5414 - lr: 1.0000e-04\n",
      "Epoch 5/20\n",
      "468/468 [==============================] - ETA: 0s - loss: 0.4072 - MSE: 0.1167 - AUC: 0.8945 - ssim_loss: 0.9925 - psnr_loss: 89.8171\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "468/468 [==============================] - 334s 713ms/step - loss: 0.4072 - MSE: 0.1167 - AUC: 0.8945 - ssim_loss: 0.9925 - psnr_loss: 89.8171 - val_loss: 0.4173 - val_MSE: 0.1276 - val_AUC: 0.9096 - val_ssim_loss: 0.9912 - val_psnr_loss: 90.2008 - lr: 1.0000e-04\n",
      "Epoch 6/20\n",
      "468/468 [==============================] - 345s 737ms/step - loss: 0.3952 - MSE: 0.1148 - AUC: 0.9008 - ssim_loss: 0.9927 - psnr_loss: 89.7019 - val_loss: 0.4476 - val_MSE: 0.1352 - val_AUC: 0.9101 - val_ssim_loss: 0.9923 - val_psnr_loss: 90.5379 - lr: 1.0000e-05\n",
      "Epoch 7/20\n",
      "468/468 [==============================] - ETA: 0s - loss: 0.3941 - MSE: 0.1139 - AUC: 0.9016 - ssim_loss: 0.9927 - psnr_loss: 89.6539\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "468/468 [==============================] - 338s 723ms/step - loss: 0.3941 - MSE: 0.1139 - AUC: 0.9016 - ssim_loss: 0.9927 - psnr_loss: 89.6539 - val_loss: 0.4214 - val_MSE: 0.1280 - val_AUC: 0.9100 - val_ssim_loss: 0.9918 - val_psnr_loss: 90.2294 - lr: 1.0000e-05\n",
      "Epoch 8/20\n",
      "468/468 [==============================] - ETA: 0s - loss: 0.3924 - MSE: 0.1141 - AUC: 0.9026 - ssim_loss: 0.9927 - psnr_loss: 89.6535Restoring model weights from the end of the best epoch: 3.\n",
      "468/468 [==============================] - 334s 715ms/step - loss: 0.3924 - MSE: 0.1141 - AUC: 0.9026 - ssim_loss: 0.9927 - psnr_loss: 89.6535 - val_loss: 0.4121 - val_MSE: 0.1252 - val_AUC: 0.9107 - val_ssim_loss: 0.9914 - val_psnr_loss: 90.0924 - lr: 1.0000e-06\n",
      "Epoch 8: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dcac0b5b80>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding callbacks.\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1, restore_best_weights=True)\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=2, verbose=1)\n",
    "\n",
    "# Train model.\n",
    "combo_model.fit(t_gen, \n",
    "                   epochs = 20, \n",
    "                   verbose = 1, \n",
    "                   batch_size = batch_size,\n",
    "                   validation_data = v_gen,\n",
    "                   callbacks = [early_stopping, reduce_lr],\n",
    "                   steps_per_epoch = len(meta_t) // batch_size,\n",
    "                   validation_steps = len(meta_v) // batch_size\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5cbcfc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze, switch to dice loss, then recompile.\n",
    "for t_layer in combo_model.layers:\n",
    "    t_layer.trainable = True\n",
    "    \n",
    "# Compile model.\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
    "loss_fn = dice_coef_loss\n",
    "combo_model.compile(loss=loss_fn, \n",
    "                    optimizer=opt, \n",
    "                    metrics=[tf.keras.metrics.MeanSquaredError(name='MSE'),\n",
    "                             tf.keras.metrics.AUC(name='AUC'),\n",
    "                             ssim_loss,\n",
    "                             psnr_loss\n",
    "                            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f6d7681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get generators.\n",
    "batch_size = 32\n",
    "t_gen = data_generator(meta_t, len(meta_t), batch_size = batch_size)\n",
    "v_gen = data_generator(meta_v, len(meta_v), batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "049daeef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "468/468 [==============================] - 271s 563ms/step - loss: 0.6722 - MSE: 0.0247 - AUC: 0.6701 - ssim_loss: 0.2775 - psnr_loss: -inf - val_loss: 0.5623 - val_MSE: 0.0566 - val_AUC: 0.6633 - val_ssim_loss: 0.2725 - val_psnr_loss: -inf - lr: 1.0000e-05\n",
      "Epoch 2/40\n",
      "468/468 [==============================] - 262s 560ms/step - loss: 0.5763 - MSE: 0.0812 - AUC: 0.6112 - ssim_loss: 0.2357 - psnr_loss: -inf - val_loss: 0.4715 - val_MSE: 0.2155 - val_AUC: 0.6331 - val_ssim_loss: 0.2726 - val_psnr_loss: -inf - lr: 1.0000e-05\n",
      "Epoch 3/40\n",
      "468/468 [==============================] - 266s 568ms/step - loss: 0.5208 - MSE: 0.2090 - AUC: 0.5931 - ssim_loss: 0.2337 - psnr_loss: -inf - val_loss: 0.4158 - val_MSE: 0.5646 - val_AUC: 0.6218 - val_ssim_loss: 0.2751 - val_psnr_loss: -inf - lr: 1.0000e-05\n",
      "Epoch 4/40\n",
      "468/468 [==============================] - 269s 576ms/step - loss: 0.4827 - MSE: 0.4244 - AUC: 0.5814 - ssim_loss: 0.2325 - psnr_loss: -inf - val_loss: 0.3739 - val_MSE: 1.0111 - val_AUC: 0.6086 - val_ssim_loss: 0.2753 - val_psnr_loss: -inf - lr: 1.0000e-05\n",
      "Epoch 5/40\n",
      "468/468 [==============================] - 262s 560ms/step - loss: 0.4518 - MSE: 0.7158 - AUC: 0.5743 - ssim_loss: 0.2321 - psnr_loss: -inf - val_loss: 0.3682 - val_MSE: 1.4890 - val_AUC: 0.5927 - val_ssim_loss: 0.2715 - val_psnr_loss: -inf - lr: 1.0000e-05\n",
      "Epoch 6/40\n",
      "468/468 [==============================] - 261s 558ms/step - loss: 0.4222 - MSE: 1.0965 - AUC: 0.5673 - ssim_loss: 0.2306 - psnr_loss: -inf - val_loss: 0.3393 - val_MSE: 2.4260 - val_AUC: 0.5874 - val_ssim_loss: 0.2708 - val_psnr_loss: -inf - lr: 1.0000e-05\n",
      "Epoch 7/40\n",
      "468/468 [==============================] - 261s 558ms/step - loss: 0.4038 - MSE: 1.6603 - AUC: 0.5650 - ssim_loss: 0.2306 - psnr_loss: -inf - val_loss: 0.3317 - val_MSE: 3.3531 - val_AUC: 0.5858 - val_ssim_loss: 0.2719 - val_psnr_loss: -inf - lr: 1.0000e-05\n",
      "Epoch 8/40\n",
      "468/468 [==============================] - 261s 558ms/step - loss: 0.3873 - MSE: 2.2173 - AUC: 0.5614 - ssim_loss: 0.2296 - psnr_loss: -inf - val_loss: 0.3345 - val_MSE: 4.5704 - val_AUC: 0.5782 - val_ssim_loss: 0.2729 - val_psnr_loss: -inf - lr: 1.0000e-05\n",
      "Epoch 9/40\n",
      "468/468 [==============================] - 261s 558ms/step - loss: 0.3686 - MSE: 2.8383 - AUC: 0.5576 - ssim_loss: 0.2285 - psnr_loss: -inf - val_loss: 0.3031 - val_MSE: 5.5742 - val_AUC: 0.5682 - val_ssim_loss: 0.2697 - val_psnr_loss: -inf - lr: 1.0000e-05\n",
      "Epoch 10/40\n",
      "468/468 [==============================] - 261s 558ms/step - loss: 0.3534 - MSE: 3.6964 - AUC: 0.5555 - ssim_loss: 0.2274 - psnr_loss: -inf - val_loss: 0.3131 - val_MSE: 6.4606 - val_AUC: 0.5632 - val_ssim_loss: 0.2656 - val_psnr_loss: -inf - lr: 1.0000e-05\n",
      "Epoch 11/40\n",
      "468/468 [==============================] - 261s 558ms/step - loss: 0.3382 - MSE: 4.4743 - AUC: 0.5525 - ssim_loss: 0.2258 - psnr_loss: -inf - val_loss: 0.3016 - val_MSE: 9.2663 - val_AUC: 0.5664 - val_ssim_loss: 0.2700 - val_psnr_loss: -inf - lr: 1.0000e-05\n",
      "Epoch 12/40\n",
      "468/468 [==============================] - 261s 558ms/step - loss: 0.3348 - MSE: 5.3871 - AUC: 0.5508 - ssim_loss: 0.2255 - psnr_loss: -inf - val_loss: 0.2809 - val_MSE: 11.9201 - val_AUC: 0.5640 - val_ssim_loss: 0.2692 - val_psnr_loss: -inf - lr: 1.0000e-05\n",
      "Epoch 13/40\n",
      "468/468 [==============================] - 261s 558ms/step - loss: 0.3216 - MSE: 6.7381 - AUC: 0.5504 - ssim_loss: 0.2250 - psnr_loss: -inf - val_loss: 0.2751 - val_MSE: 13.6258 - val_AUC: 0.5639 - val_ssim_loss: 0.2679 - val_psnr_loss: -inf - lr: 1.0000e-05\n",
      "Epoch 14/40\n",
      "468/468 [==============================] - 261s 557ms/step - loss: 0.2976 - MSE: 7.8334 - AUC: 0.5491 - ssim_loss: 0.2240 - psnr_loss: -inf - val_loss: 0.2858 - val_MSE: 16.4823 - val_AUC: 0.5613 - val_ssim_loss: 0.2677 - val_psnr_loss: -inf - lr: 1.0000e-05\n",
      "Epoch 15/40\n",
      "468/468 [==============================] - ETA: 0s - loss: 0.2984 - MSE: 9.5035 - AUC: 0.5496 - ssim_loss: 0.2252 - psnr_loss: -inf\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "468/468 [==============================] - 261s 557ms/step - loss: 0.2984 - MSE: 9.5035 - AUC: 0.5496 - ssim_loss: 0.2252 - psnr_loss: -inf - val_loss: 0.2847 - val_MSE: 15.7323 - val_AUC: 0.5552 - val_ssim_loss: 0.2669 - val_psnr_loss: -inf - lr: 1.0000e-05\n",
      "Epoch 16/40\n",
      "468/468 [==============================] - 264s 565ms/step - loss: 0.2744 - MSE: 8.8710 - AUC: 0.5455 - ssim_loss: 0.2224 - psnr_loss: -inf - val_loss: 0.2624 - val_MSE: 17.5639 - val_AUC: 0.5585 - val_ssim_loss: 0.2662 - val_psnr_loss: -inf - lr: 1.0000e-06\n",
      "Epoch 17/40\n",
      "468/468 [==============================] - 274s 585ms/step - loss: 0.2888 - MSE: 9.2384 - AUC: 0.5460 - ssim_loss: 0.2228 - psnr_loss: -inf - val_loss: 0.2677 - val_MSE: 17.3216 - val_AUC: 0.5579 - val_ssim_loss: 0.2685 - val_psnr_loss: -inf - lr: 1.0000e-06\n",
      "Epoch 18/40\n",
      "468/468 [==============================] - 274s 585ms/step - loss: 0.2889 - MSE: 9.4944 - AUC: 0.5465 - ssim_loss: 0.2230 - psnr_loss: -inf - val_loss: 0.2546 - val_MSE: 17.2545 - val_AUC: 0.5584 - val_ssim_loss: 0.2679 - val_psnr_loss: -inf - lr: 1.0000e-06\n",
      "Epoch 19/40\n",
      "468/468 [==============================] - 274s 586ms/step - loss: 0.2900 - MSE: 9.5214 - AUC: 0.5459 - ssim_loss: 0.2229 - psnr_loss: -inf - val_loss: 0.2889 - val_MSE: 20.0994 - val_AUC: 0.5584 - val_ssim_loss: 0.2637 - val_psnr_loss: -inf - lr: 1.0000e-06\n",
      "Epoch 20/40\n",
      "468/468 [==============================] - ETA: 0s - loss: 0.2811 - MSE: 10.1076 - AUC: 0.5476 - ssim_loss: 0.2243 - psnr_loss: -inf\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "468/468 [==============================] - 273s 584ms/step - loss: 0.2811 - MSE: 10.1076 - AUC: 0.5476 - ssim_loss: 0.2243 - psnr_loss: -inf - val_loss: 0.2736 - val_MSE: 18.9846 - val_AUC: 0.5598 - val_ssim_loss: 0.2714 - val_psnr_loss: -inf - lr: 1.0000e-06\n",
      "Epoch 21/40\n",
      " 12/468 [..............................] - ETA: 3:50 - loss: 0.2882 - MSE: 8.3473 - AUC: 0.5375 - ssim_loss: 0.2132 - psnr_loss: -inf"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_28696/2952834103.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Train model.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m combo_model.fit(t_gen, \n\u001b[0m\u001b[0;32m      7\u001b[0m                    \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m40\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m                    \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1568\u001b[0m                             \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1569\u001b[0m                             \u001b[0mend_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1570\u001b[1;33m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1571\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1572\u001b[0m                                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    468\u001b[0m         \"\"\"\n\u001b[0;32m    469\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 470\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"end\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    471\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    472\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    315\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"end\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 317\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    318\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m             raise ValueError(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    338\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 340\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m             \u001b[0mhook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 388\u001b[1;33m             \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1079\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1081\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1155\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m             \u001b[1;31m# Only block async when verbose = 1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1157\u001b[1;33m             \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1158\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    633\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    626\u001b[0m         \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 628\u001b[1;33m             \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    629\u001b[0m         \u001b[1;31m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    630\u001b[0m         \u001b[1;31m# as-is.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1155\u001b[0m     \"\"\"\n\u001b[0;32m   1156\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1157\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1158\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1121\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1123\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1124\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1125\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Adding callbacks.\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1, restore_best_weights=True)\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=2, verbose=1)\n",
    "\n",
    "# Train model.\n",
    "combo_model.fit(t_gen, \n",
    "                   epochs = 40, \n",
    "                   verbose = 1, \n",
    "                   batch_size = batch_size,\n",
    "                   validation_data = v_gen,\n",
    "                   callbacks = [early_stopping, reduce_lr],\n",
    "                   steps_per_epoch = len(meta_t) // batch_size,\n",
    "                   validation_steps = len(meta_v) // batch_size\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892233d3",
   "metadata": {},
   "source": [
    "### Testing Fire Encoder on VIIRS Fire Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57059112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata on yearly datasets.\n",
    "df_2017 = pd.read_csv('4fold_super/2017/meta.csv')\n",
    "df_2018 = pd.read_csv('4fold_super/2018/meta.csv')\n",
    "df_2019 = pd.read_csv('4fold_super/2019/meta.csv')\n",
    "df_2020 = pd.read_csv('4fold_super/2020/meta.csv')\n",
    "\n",
    "# Combine into desired train/val split.\n",
    "meta_t = pd.concat([df_2017,df_2018,df_2019]).reset_index()\n",
    "meta_v = df_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "627d14ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, d_train, v_train, y_train, x_val, d_val, v_val, y_val = [],[],[],[],[],[],[],[]\n",
    "for x in range(0,len(meta_t)):\n",
    "    x_train.append(np.load(meta_t.iloc[x].features_2d)[:,:,:,:1])\n",
    "    d_train.append(np.load(meta_t.iloc[x].features_2d)[:,0,:,1:2])\n",
    "    v_train.append(np.load(meta_t.iloc[x].features_1d))\n",
    "    y_train.append(np.load(meta_t.iloc[x].labels))\n",
    "\n",
    "for x in range(0,len(meta_v)):\n",
    "    x_val.append(np.load(meta_v.iloc[x].features_2d)[:,:,:,:1])\n",
    "    d_val.append(np.load(meta_v.iloc[x].features_2d)[:,0,:,1:2])\n",
    "    v_val.append(np.load(meta_v.iloc[x].features_1d))\n",
    "    y_val.append(np.load(meta_v.iloc[x].labels))\n",
    "    \n",
    "    \n",
    "x_train = np.stack(x_train)\n",
    "d_train = np.stack(d_train)\n",
    "v_train = np.stack(v_train)\n",
    "y_train = np.stack(y_train)   \n",
    "x_val = np.stack(x_val)\n",
    "d_val = np.stack(d_val)\n",
    "v_val = np.stack(v_val)\n",
    "y_val = np.stack(y_val)\n",
    "\n",
    "x_train = np.minimum(x_train,1)\n",
    "d_train = np.minimum(d_train,1)\n",
    "y_train = np.minimum(y_train,1)\n",
    "y_train = np.moveaxis(y_train, 1, -1)\n",
    "\n",
    "x_val = np.minimum(x_val,1)\n",
    "d_val = np.minimum(x_val,1)\n",
    "y_val = np.minimum(y_val,1)\n",
    "y_val = np.moveaxis(y_val, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82714d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reload model from Phase 1.\n",
    "#combo_model = tf.keras.models.load_model('Models/MINST_Agg_01', custom_objects = {'ssim_loss': ssim_loss, 'psnr_loss': psnr_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87c26ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 41s 260ms/step\n"
     ]
    }
   ],
   "source": [
    "t_preds = combo_model.predict([x_val, d_val[:,0], np.expand_dims(v_val, [2,3])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "46e0ab05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Prediction Metrics:\n",
      "SSIM: 0.011483428999781609 \n",
      "PSNR: 0.12909388542175293 \n",
      "MSE: 0.051175386 \n",
      "Min Px: 0.0 \n",
      "Max Px: 0.80625504 \n",
      "Mean Px: 0.16635099 \n",
      "Sample ID: 291\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2304x576 with 11 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2304x1152 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_idx = np.random.randint(0, len(x_val))\n",
    "\n",
    "# Construct a figure for the original and new frames.\n",
    "fig, axes = plt.subplots(1, 11, figsize=(32, 8))\n",
    "\n",
    "# Plot the fire frames.\n",
    "for idx, ax in enumerate(axes):\n",
    "    if idx == 10:\n",
    "        ax.imshow(np.squeeze(y_val[sample_idx]), cmap=\"gray\")\n",
    "        ax.set_title('Target')\n",
    "        ax.title.set_fontsize(30)\n",
    "        ax.axis(\"off\")\n",
    "    else:\n",
    "        ax.imshow(np.squeeze(x_val[sample_idx][idx]), cmap=\"gray\")\n",
    "        ax.set_title(f\"Frame {idx + 1}\")\n",
    "        ax.title.set_fontsize(30)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(32, 16))\n",
    "axes[0].imshow(np.squeeze(x_val[sample_idx][9]), cmap=\"gray\")\n",
    "axes[0].set_title('Last Frame')\n",
    "axes[0].axis(\"off\")\n",
    "axes[0].title.set_fontsize(60)\n",
    "axes[1].imshow(np.squeeze(y_val[sample_idx]), cmap=\"gray\")\n",
    "axes[1].set_title('Target')\n",
    "axes[1].axis(\"off\")\n",
    "axes[1].title.set_fontsize(60)\n",
    "axes[2].imshow(np.squeeze(t_preds[sample_idx]), cmap=\"gray\")\n",
    "axes[2].set_title('Prediction')\n",
    "axes[2].axis(\"off\")\n",
    "axes[2].title.set_fontsize(60)\n",
    "\n",
    "t_preds[sample_idx].min(), t_preds[sample_idx].max(), t_preds[sample_idx].mean(),\n",
    "print('Sample Prediction Metrics:'\n",
    "      '\\nSSIM:', float(tf.image.ssim(tf.cast(y_val[sample_idx], dtype='float32'), t_preds[sample_idx], 1.0)),\n",
    "      '\\nPSNR:', float(tf.image.psnr(tf.cast(y_val[sample_idx], dtype='float32'), t_preds[sample_idx], 1.0) / 100),\n",
    "      '\\nMSE:', np.mean(tf.keras.metrics.mean_squared_error(y_val[sample_idx], t_preds[sample_idx])),\n",
    "      '\\nMin Px:', t_preds[sample_idx].min(),\n",
    "      '\\nMax Px:', t_preds[sample_idx].max(),\n",
    "      '\\nMean Px:', t_preds[sample_idx].mean(),\n",
    "      '\\nSample ID:', int(sample_idx)\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34163cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Prediction Report\n",
      "SSIM: 0.008481416\n",
      "PSNR: 0.10930078506469726\n",
      "MSE: 0.098883234\n"
     ]
    }
   ],
   "source": [
    "# Compute and show set scores.\n",
    "set_ssim = tf.image.ssim(tf.cast(y_val, dtype='float32'), t_preds, 1.0)\n",
    "set_psnr = tf.image.psnr(tf.cast(y_val, dtype='float32'), t_preds, 1.0)\n",
    "set_mse = tf.keras.metrics.mean_squared_error(y_val, t_preds)\n",
    "print('Model Prediction Report')\n",
    "print('SSIM:', np.mean(set_ssim))\n",
    "print('PSNR:', np.mean(set_psnr) / 100)\n",
    "print('MSE:', np.mean(set_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "02aaa6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 11). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Models/Combo_Blur\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Models/Combo_Blur\\assets\n"
     ]
    }
   ],
   "source": [
    "combo_model.save('Models/Combo_Blur')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
