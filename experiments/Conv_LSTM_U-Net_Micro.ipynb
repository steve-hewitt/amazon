{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3a3b751",
   "metadata": {},
   "source": [
    "# Model Name TBD\n",
    "Combines the time-distributed feature extraction of Convolutional LSTMs with the upsampling and skip connections of a U-Net to convert video-like input features and time-distributed vector metadata into a next frame semantic segmentation map."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65090d11",
   "metadata": {},
   "source": [
    "### Import Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afec3342",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "#from tensorflow.keras.models import Sequential\n",
    "#from tensorflow.keras.initializers import Constant\n",
    "#from skimage.metrics import structural_similarity as ssim\n",
    "#from skimage.metrics import mean_squared_error\n",
    "#from math import log10, sqrt\n",
    "\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7194276",
   "metadata": {},
   "source": [
    "### Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07c37bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loader functions\n",
    "# Inspiration: https://towardsdatascience.com/writing-custom-keras-generators-fe815d992c5a\n",
    "\n",
    "def get_2d_input(path):\n",
    "    # Load array.\n",
    "    t_2d_input = np.load(path)\n",
    "    \n",
    "    #return t_2d_input\n",
    "    return t_2d_input[:,:,:,:1]\n",
    "\n",
    "def get_1d_input(path):\n",
    "    # Load array.\n",
    "    t_1d_input = np.load(path)\n",
    "    \n",
    "    # Expand dimensions to match model input.\n",
    "    t_1d_input = tf.expand_dims(tf.expand_dims(t_1d_input, 2), 2)\n",
    "    \n",
    "    # Put channel dim at the end.\n",
    "    t_1d_input = np.moveaxis(t_1d_input, 1, -1)\n",
    "    \n",
    "    return t_1d_input\n",
    "\n",
    "def get_output(path):\n",
    "    # Load array.\n",
    "    t_output = np.load(path)\n",
    "    \n",
    "    # Put channel dim at the end.\n",
    "    t_output = np.moveaxis(t_output, 0, -1)\n",
    "    return t_output\n",
    "\n",
    "def data_generator(samples, num_samples, batch_size = 64, calculated_sample_weights = None):\n",
    "    \n",
    "    while True:\n",
    "        # Suffle data at the start of each epoch.\n",
    "        sample_indicies = np.arange(num_samples)\n",
    "        np.random.shuffle(sample_indicies)\n",
    "        n = 0\n",
    "        \n",
    "        while n + batch_size < num_samples:\n",
    "            # Get indicies for the batch\n",
    "            batch_samples  = sample_indicies[n:n + batch_size]\n",
    "            n += batch_size\n",
    "\n",
    "            batch_input_2d  = []\n",
    "            batch_input_1d  = []\n",
    "            batch_output = [] \n",
    "            batch_sample_weights = []\n",
    "\n",
    "            # Read in each input, perform preprocessing and get labels\n",
    "            for sample in batch_samples:\n",
    "                input_2d = get_2d_input(samples.iloc[sample].features_2d)\n",
    "                input_1d = get_1d_input(samples.iloc[sample].features_1d)\n",
    "                output = get_output(samples.iloc[sample].labels)\n",
    "                \n",
    "                batch_input_2d += [input_2d]\n",
    "                batch_input_1d += [input_1d]\n",
    "                batch_output += [output]\n",
    "\n",
    "                if type(calculated_sample_weights) != type(None):\n",
    "                    sample_weights = calculated_sample_weights[sample]\n",
    "                    batch_sample_weights += [sample_weights]\n",
    "                \n",
    "            # Return a tuple to feed the network\n",
    "            batch_x = np.array(batch_input_2d)\n",
    "            batch_v = np.array(batch_input_1d)\n",
    "            batch_y = np.array(batch_output)\n",
    "            \n",
    "            if type(calculated_sample_weights) == type(None):\n",
    "                yield(batch_x, batch_y)\n",
    "            else:\n",
    "                batch_sample_weights = np.array(batch_sample_weights)\n",
    "                yield(batch_x, batch_y, batch_sample_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cd53fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution for problem with class_weights not working with 3D outputs in tensorflow.\n",
    "# From: https://github.com/keras-team/keras/issues/3653\n",
    "def generate_sample_weights(training_data, class_weights): \n",
    "    #replaces values for up to 3 classes with the values from class_weights#\n",
    "    sample_weights = [np.where(y==0,class_weights[0],\n",
    "                        np.where(y==1,class_weights[1],\n",
    "                        y)) for y in training_data]\n",
    "    return np.asarray(sample_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca1725c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SSIM/PSNR loss functions.\n",
    "# Inspiration: https://stackoverflow.com/questions/57357146/use-ssim-loss-function-with-keras\n",
    "def ssim_loss(y_true, y_pred):\n",
    "    return 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, 1.0))\n",
    "\n",
    "def psnr_loss(y_true, y_pred):\n",
    "    return (100 - tf.reduce_mean(tf.image.psnr(y_true, y_pred, 1.0))) / 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9ebaa1",
   "metadata": {},
   "source": [
    "### Model Assembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf8370b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyperparameters\n",
    "top_features = 32\n",
    "condensed_features = 32\n",
    "upsample_filters = 32\n",
    "fc_filters = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d6ba115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs broken out by array and vector features.\n",
    "inputs_2d = layers.Input(shape=((10,32,32,1)))\n",
    "#inputs_1d = layers.Input(shape=((10,1,1,192)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a220cb2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 32, 32, 1) dtype=float32 (created by layer 'outputs')>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = layers.ConvLSTM2D(\n",
    "    filters=128,\n",
    "    kernel_size=(5, 5),\n",
    "    padding='same',\n",
    "    return_sequences=True,\n",
    ")(inputs_2d)\n",
    "x = layers.ConvLSTM2D(\n",
    "    filters=64,\n",
    "    kernel_size=(5, 5),\n",
    "    padding='same',\n",
    "    return_sequences=True,\n",
    ")(x)\n",
    "x = layers.ConvLSTM2D(\n",
    "    filters=64,\n",
    "    kernel_size=(5, 5),\n",
    "    padding='same',\n",
    "    return_sequences=False,\n",
    ")(x)\n",
    "outputs = layers.Conv2D(1, 1, padding='same', activation = 'sigmoid', name = 'outputs')(x)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a8eda4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "combo_model = tf.keras.Model(inputs = inputs_2d, outputs = outputs, name = 'micro_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c645b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"micro_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 10, 32, 32, 1)]   0         \n",
      "                                                                 \n",
      " conv_lstm2d (ConvLSTM2D)    (None, 10, 32, 32, 128)   1651712   \n",
      "                                                                 \n",
      " conv_lstm2d_1 (ConvLSTM2D)  (None, 10, 32, 32, 64)    1229056   \n",
      "                                                                 \n",
      " conv_lstm2d_2 (ConvLSTM2D)  (None, 32, 32, 64)        819456    \n",
      "                                                                 \n",
      " outputs (Conv2D)            (None, 32, 32, 1)         65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,700,289\n",
      "Trainable params: 3,700,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "combo_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae43747a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model.\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "#loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "combo_model.compile(loss=loss_fn, \n",
    "                    optimizer=opt, \n",
    "                    metrics=[tf.keras.metrics.MeanSquaredError(name='MSE'),\n",
    "                             tf.keras.metrics.AUC(name='AUC'),\n",
    "                             ssim_loss,\n",
    "                             psnr_loss\n",
    "                            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8208ab51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4, 32, 32, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test on dummy data to see that shapes look right.\n",
    "img_batch = tf.zeros([4,10,32,32,1], dtype = 'float32')\n",
    "#vector_batch = tf.zeros([4,10,1,1,192], dtype = 'float32')\n",
    "combo_model.predict(img_batch).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8adc91c",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38d6b54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata on yearly datasets.\n",
    "df_2017 = pd.read_csv('4fold_super/2017/meta.csv')\n",
    "df_2018 = pd.read_csv('4fold_super/2018/meta.csv')\n",
    "df_2019 = pd.read_csv('4fold_super/2019/meta.csv')\n",
    "df_2020 = pd.read_csv('4fold_super/2020/meta.csv')\n",
    "\n",
    "# Combine into desired train/val split.\n",
    "meta_t = pd.concat([df_2017,df_2018,df_2019]).reset_index()\n",
    "meta_v = df_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8f2472f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.5049593185573996, 1: 50.910151537247934}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load all labels from the training set into memory to get weights\n",
    "y_train = []\n",
    "\n",
    "# Iterate over dataset.\n",
    "for x in range(0,len(meta_t)):\n",
    "    y_train.append(np.load(meta_t.iloc[x].labels))\n",
    "\n",
    "y_train = np.stack(y_train)\n",
    "y_train = np.minimum(y_train,1)\n",
    "y_train = tf.expand_dims(y_train, axis = -1).numpy()\n",
    "\n",
    "# Get class weights for WBCE/MSE.\n",
    "weights = class_weight.compute_class_weight('balanced',\n",
    "                                            classes = [0,1],\n",
    "                                            y = y_train.flatten())\n",
    "# Examine weights.\n",
    "weights_dict = {0:weights[0], 1:weights[1]}\n",
    "weights_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb8fcef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment with reducing weights arbitrarily.\n",
    "#weights_dict = {0:0.6, 1:45.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "634b5158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get weights.\n",
    "calculated_sample_weights = generate_sample_weights(y_train, weights)\n",
    "\n",
    "# Drop y_train to save memory.\n",
    "y_train = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c820ec02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loaders.\n",
    "batch_size = 32\n",
    "t_gen = data_generator(meta_t, len(meta_t), batch_size = batch_size, calculated_sample_weights = calculated_sample_weights[:,0])\n",
    "v_gen = data_generator(meta_v, len(meta_v), batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dbf9e815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(next(t_gen)), len(next(v_gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4f61da3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 32, 32, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(v_gen)[0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32657102",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "502f5f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "468/468 [==============================] - 376s 794ms/step - loss: 0.2740 - MSE: 0.1953 - AUC: 0.8554 - ssim_loss: 0.9957 - psnr_loss: 0.9198 - val_loss: 0.1780 - val_MSE: 0.1780 - val_AUC: 0.8975 - val_ssim_loss: 0.9952 - val_psnr_loss: 0.9167\n",
      "Epoch 2/10\n",
      "468/468 [==============================] - 377s 807ms/step - loss: 0.2403 - MSE: 0.1506 - AUC: 0.8882 - ssim_loss: 0.9949 - psnr_loss: 0.9066 - val_loss: 0.1659 - val_MSE: 0.1659 - val_AUC: 0.9014 - val_ssim_loss: 0.9940 - val_psnr_loss: 0.9098\n",
      "Epoch 3/10\n",
      "468/468 [==============================] - 389s 831ms/step - loss: 0.2371 - MSE: 0.1466 - AUC: 0.8936 - ssim_loss: 0.9944 - psnr_loss: 0.9045 - val_loss: 0.1455 - val_MSE: 0.1455 - val_AUC: 0.9038 - val_ssim_loss: 0.9928 - val_psnr_loss: 0.9020\n",
      "Epoch 4/10\n",
      "468/468 [==============================] - 383s 819ms/step - loss: 0.2337 - MSE: 0.1437 - AUC: 0.8970 - ssim_loss: 0.9942 - psnr_loss: 0.9025 - val_loss: 0.1496 - val_MSE: 0.1496 - val_AUC: 0.9054 - val_ssim_loss: 0.9932 - val_psnr_loss: 0.9055\n",
      "Epoch 5/10\n",
      "468/468 [==============================] - 371s 792ms/step - loss: 0.2320 - MSE: 0.1418 - AUC: 0.8990 - ssim_loss: 0.9939 - psnr_loss: 0.9016 - val_loss: 0.1510 - val_MSE: 0.1510 - val_AUC: 0.9067 - val_ssim_loss: 0.9919 - val_psnr_loss: 0.9024\n",
      "Epoch 6/10\n",
      "468/468 [==============================] - 377s 805ms/step - loss: 0.2299 - MSE: 0.1395 - AUC: 0.9013 - ssim_loss: 0.9934 - psnr_loss: 0.9001 - val_loss: 0.1585 - val_MSE: 0.1585 - val_AUC: 0.9104 - val_ssim_loss: 0.9937 - val_psnr_loss: 0.9074\n",
      "Epoch 7/10\n",
      "468/468 [==============================] - 380s 812ms/step - loss: 0.2282 - MSE: 0.1381 - AUC: 0.9027 - ssim_loss: 0.9933 - psnr_loss: 0.8995 - val_loss: 0.1435 - val_MSE: 0.1435 - val_AUC: 0.9100 - val_ssim_loss: 0.9920 - val_psnr_loss: 0.9022\n",
      "Epoch 8/10\n",
      "468/468 [==============================] - 392s 838ms/step - loss: 0.2267 - MSE: 0.1365 - AUC: 0.9046 - ssim_loss: 0.9931 - psnr_loss: 0.8986 - val_loss: 0.1606 - val_MSE: 0.1606 - val_AUC: 0.9091 - val_ssim_loss: 0.9933 - val_psnr_loss: 0.9093\n",
      "Epoch 9/10\n",
      "468/468 [==============================] - 372s 796ms/step - loss: 0.2245 - MSE: 0.1348 - AUC: 0.9061 - ssim_loss: 0.9930 - psnr_loss: 0.8979 - val_loss: 0.1348 - val_MSE: 0.1348 - val_AUC: 0.9105 - val_ssim_loss: 0.9907 - val_psnr_loss: 0.8966\n",
      "Epoch 10/10\n",
      "468/468 [==============================] - 371s 794ms/step - loss: 0.2238 - MSE: 0.1332 - AUC: 0.9074 - ssim_loss: 0.9927 - psnr_loss: 0.8973 - val_loss: 0.1541 - val_MSE: 0.1541 - val_AUC: 0.9104 - val_ssim_loss: 0.9921 - val_psnr_loss: 0.9037\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c239813a90>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding callbacks.\n",
    "#early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1, restore_best_weights=True)\n",
    "#reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=2, verbose=1)\n",
    "\n",
    "# Train model.\n",
    "combo_model.fit(t_gen, \n",
    "                   epochs = 10, \n",
    "                   verbose = 1, \n",
    "                   batch_size = batch_size,\n",
    "                   validation_data = v_gen,\n",
    "                   #callbacks = [early_stopping, reduce_lr],\n",
    "                   steps_per_epoch = len(meta_t) // batch_size,\n",
    "                   validation_steps = len(meta_v) // batch_size\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "66c37ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Models/CM_micro1_ep10_2020\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Models/CM_micro1_ep10_2020\\assets\n"
     ]
    }
   ],
   "source": [
    "combo_model.save('Models/CM_micro1_ep10_2020')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c12f8f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "combo_model = tf.keras.models.load_model('Models/CM_micro1_ep10_2020'\n",
    "                                         , custom_objects = {'ssim_loss': ssim_loss, 'psnr_loss': psnr_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "65e23b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old LR: 1e-04\n",
      "New LR: 1e-05\n",
      "Epoch 1/10\n",
      "468/468 [==============================] - 380s 803ms/step - loss: 0.2201 - MSE: 0.1300 - AUC: 0.9105 - ssim_loss: 0.9923 - psnr_loss: 0.8952 - val_loss: 0.1461 - val_MSE: 0.1461 - val_AUC: 0.9114 - val_ssim_loss: 0.9921 - val_psnr_loss: 0.9020\n",
      "Epoch 2/10\n",
      "468/468 [==============================] - 371s 793ms/step - loss: 0.2195 - MSE: 0.1301 - AUC: 0.9111 - ssim_loss: 0.9925 - psnr_loss: 0.8957 - val_loss: 0.1446 - val_MSE: 0.1446 - val_AUC: 0.9122 - val_ssim_loss: 0.9919 - val_psnr_loss: 0.9013\n",
      "Epoch 3/10\n",
      "468/468 [==============================] - 371s 793ms/step - loss: 0.2189 - MSE: 0.1294 - AUC: 0.9116 - ssim_loss: 0.9923 - psnr_loss: 0.8952 - val_loss: 0.1466 - val_MSE: 0.1466 - val_AUC: 0.9106 - val_ssim_loss: 0.9920 - val_psnr_loss: 0.9019\n",
      "Epoch 4/10\n",
      "468/468 [==============================] - 371s 793ms/step - loss: 0.2189 - MSE: 0.1289 - AUC: 0.9119 - ssim_loss: 0.9922 - psnr_loss: 0.8949 - val_loss: 0.1489 - val_MSE: 0.1489 - val_AUC: 0.9118 - val_ssim_loss: 0.9922 - val_psnr_loss: 0.9030\n",
      "Epoch 5/10\n",
      "468/468 [==============================] - 371s 793ms/step - loss: 0.2184 - MSE: 0.1294 - AUC: 0.9123 - ssim_loss: 0.9923 - psnr_loss: 0.8953 - val_loss: 0.1450 - val_MSE: 0.1450 - val_AUC: 0.9111 - val_ssim_loss: 0.9917 - val_psnr_loss: 0.9013\n",
      "Epoch 6/10\n",
      "468/468 [==============================] - 371s 793ms/step - loss: 0.2182 - MSE: 0.1291 - AUC: 0.9124 - ssim_loss: 0.9922 - psnr_loss: 0.8951 - val_loss: 0.1408 - val_MSE: 0.1408 - val_AUC: 0.9136 - val_ssim_loss: 0.9914 - val_psnr_loss: 0.8996\n",
      "Epoch 7/10\n",
      "468/468 [==============================] - 374s 800ms/step - loss: 0.2179 - MSE: 0.1282 - AUC: 0.9127 - ssim_loss: 0.9920 - psnr_loss: 0.8946 - val_loss: 0.1435 - val_MSE: 0.1435 - val_AUC: 0.9115 - val_ssim_loss: 0.9916 - val_psnr_loss: 0.9009\n",
      "Epoch 8/10\n",
      "468/468 [==============================] - 480s 1s/step - loss: 0.2176 - MSE: 0.1282 - AUC: 0.9130 - ssim_loss: 0.9919 - psnr_loss: 0.8947 - val_loss: 0.1485 - val_MSE: 0.1485 - val_AUC: 0.9116 - val_ssim_loss: 0.9921 - val_psnr_loss: 0.9031\n",
      "Epoch 9/10\n",
      "468/468 [==============================] - 428s 916ms/step - loss: 0.2176 - MSE: 0.1288 - AUC: 0.9131 - ssim_loss: 0.9921 - psnr_loss: 0.8951 - val_loss: 0.1440 - val_MSE: 0.1440 - val_AUC: 0.9115 - val_ssim_loss: 0.9913 - val_psnr_loss: 0.9007\n",
      "Epoch 10/10\n",
      "468/468 [==============================] - 381s 815ms/step - loss: 0.2173 - MSE: 0.1284 - AUC: 0.9133 - ssim_loss: 0.9920 - psnr_loss: 0.8948 - val_loss: 0.1414 - val_MSE: 0.1414 - val_AUC: 0.9125 - val_ssim_loss: 0.9912 - val_psnr_loss: 0.8997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c34a511fd0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change learning rate.\n",
    "print('Old LR:',tf.keras.backend.eval(combo_model.optimizer.lr))\n",
    "tf.keras.backend.set_value(combo_model.optimizer.lr, 0.00001)\n",
    "print('New LR:',tf.keras.backend.eval(combo_model.optimizer.lr))\n",
    "\n",
    "# Reload generators.\n",
    "t_gen = data_generator(meta_t, len(meta_t), batch_size = batch_size, calculated_sample_weights = calculated_sample_weights[:,0])\n",
    "v_gen = data_generator(meta_v, len(meta_v), batch_size = batch_size)\n",
    "\n",
    "# Train more.\n",
    "combo_model.fit(t_gen, \n",
    "                   epochs = 10, \n",
    "                   verbose = 1, \n",
    "                   batch_size = batch_size,\n",
    "                   validation_data = v_gen,\n",
    "                   steps_per_epoch = len(meta_t) // batch_size,\n",
    "                   validation_steps = len(meta_v) // batch_size\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fa0f4a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Models/CM_micro1_ep20_2020\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Models/CM_micro1_ep20_2020\\assets\n"
     ]
    }
   ],
   "source": [
    "combo_model.save('Models/CM_micro1_ep20_2020')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "79c38526",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No file or directory found at Models/CM_micro1_ep20_2020",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1348/1952933983.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m combo_model = tf.keras.models.load_model('Models/CM_micro1_ep20_2020'\n\u001b[0m\u001b[0;32m      2\u001b[0m                                          , custom_objects = {'ssim_loss': ssim_loss, 'psnr_loss': psnr_loss})\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\saving\\save.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    224\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m                         raise IOError(\n\u001b[0m\u001b[0;32m    227\u001b[0m                             \u001b[1;34mf\"No file or directory found at {filepath_str}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m                         )\n",
      "\u001b[1;31mOSError\u001b[0m: No file or directory found at Models/CM_micro1_ep20_2020"
     ]
    }
   ],
   "source": [
    "combo_model = tf.keras.models.load_model('Models/CM_micro1_ep20_2020'\n",
    "                                         , custom_objects = {'ssim_loss': ssim_loss, 'psnr_loss': psnr_loss})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2984e6e",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "415dce42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get entire validation set.\n",
    "x_val, v_val, y_val = [],[],[]\n",
    "for x in range(0,len(meta_v)):\n",
    "    x_val.append(np.load(meta_v.iloc[x].features_2d))\n",
    "    v_val.append(np.load(meta_v.iloc[x].features_1d))\n",
    "    y_val.append(np.load(meta_v.iloc[x].labels))\n",
    "    \n",
    "x_val = np.stack(x_val)\n",
    "v_val = np.stack(v_val)\n",
    "y_val = np.stack(y_val)\n",
    "\n",
    "# Dimension wrangling.\n",
    "v_val = tf.expand_dims(tf.expand_dims(v_val, 2), 2)\n",
    "y_val = np.moveaxis(y_val, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4c71379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 10, 32, 32, 1), (10, 32, 32, 1))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val[:,:,:,:,:1].shape, next(t_gen)[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "027077bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 34s 216ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict on all samples.\n",
    "all_preds = combo_model.predict(x_val[:,:,:,:,:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e8ab49b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Prediction Report\n",
      "SSIM: 0.008846255\n",
      "PSNR: 0.09997410774230957\n",
      "MSE: 0.14208356\n"
     ]
    }
   ],
   "source": [
    "# Compute and show set scores.\n",
    "set_ssim = tf.image.ssim(tf.cast(y_val, dtype='float32'), all_preds, 1.0)\n",
    "set_psnr = tf.image.psnr(tf.cast(y_val, dtype='float32'), all_preds, 1.0)\n",
    "set_mse = tf.keras.metrics.mean_squared_error(y_val, all_preds)\n",
    "print('Model Prediction Report')\n",
    "print('SSIM:', np.mean(set_ssim))\n",
    "print('PSNR:', np.mean(set_psnr) / 100)\n",
    "print('MSE:', np.mean(set_mse))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
