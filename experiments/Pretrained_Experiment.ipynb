{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3a3b751",
   "metadata": {},
   "source": [
    "# Model Name TBD\n",
    "Combines the time-distributed feature extraction of Convolutional LSTMs with the upsampling and skip connections of a U-Net to convert video-like input features and time-distributed vector metadata into a next frame semantic segmentation map."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65090d11",
   "metadata": {},
   "source": [
    "### Import Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afec3342",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7194276",
   "metadata": {},
   "source": [
    "### Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07c37bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loader functions\n",
    "# Inspiration: https://towardsdatascience.com/writing-custom-keras-generators-fe815d992c5a\n",
    "\n",
    "def get_2d_input(path):\n",
    "    # Load array.\n",
    "    t_2d_input = np.load(path)\n",
    "    \n",
    "    #return t_2d_input\n",
    "    return t_2d_input[:,:,:,:1]\n",
    "\n",
    "def get_1d_input(path):\n",
    "    # Load array.\n",
    "    t_1d_input = np.load(path)\n",
    "    \n",
    "    # Expand dimensions to match model input.\n",
    "    t_1d_input = tf.expand_dims(tf.expand_dims(t_1d_input, 2), 2)\n",
    "    \n",
    "    # Put channel dim at the end.\n",
    "    t_1d_input = np.moveaxis(t_1d_input, 1, -1)\n",
    "    \n",
    "    return t_1d_input\n",
    "\n",
    "def get_output(path):\n",
    "    # Load array.\n",
    "    t_output = np.load(path)\n",
    "    \n",
    "    # Put channel dim at the end.\n",
    "    t_output = np.moveaxis(t_output, 0, -1)\n",
    "    return t_output\n",
    "\n",
    "def data_generator(samples, num_samples, batch_size = 64, calculated_sample_weights = None):\n",
    "    \n",
    "    while True:\n",
    "        # Suffle data at the start of each epoch.\n",
    "        sample_indicies = np.arange(num_samples)\n",
    "        np.random.shuffle(sample_indicies)\n",
    "        n = 0\n",
    "        \n",
    "        while n + batch_size < num_samples:\n",
    "            # Get indicies for the batch\n",
    "            batch_samples  = sample_indicies[n:n + batch_size]\n",
    "            n += batch_size\n",
    "\n",
    "            batch_input_2d  = []\n",
    "            batch_input_1d  = []\n",
    "            batch_output = [] \n",
    "            batch_sample_weights = []\n",
    "\n",
    "            # Read in each input, perform preprocessing and get labels\n",
    "            for sample in batch_samples:\n",
    "                input_2d = get_2d_input(samples.iloc[sample].features_2d)\n",
    "                input_1d = get_1d_input(samples.iloc[sample].features_1d)\n",
    "                output = get_output(samples.iloc[sample].labels)\n",
    "                \n",
    "                batch_input_2d += [input_2d]\n",
    "                batch_input_1d += [input_1d]\n",
    "                batch_output += [output]\n",
    "\n",
    "                if type(calculated_sample_weights) != type(None):\n",
    "                    sample_weights = calculated_sample_weights[sample]\n",
    "                    batch_sample_weights += [sample_weights]\n",
    "                \n",
    "            # Return a tuple to feed the network\n",
    "            batch_x = np.array(batch_input_2d)\n",
    "            batch_v = np.array(batch_input_1d)\n",
    "            batch_y = np.array(batch_output)\n",
    "            \n",
    "            if type(calculated_sample_weights) == type(None):\n",
    "                yield(batch_x, batch_y)\n",
    "            else:\n",
    "                batch_sample_weights = np.array(batch_sample_weights)\n",
    "                yield(batch_x, batch_y, batch_sample_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ef16812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution for problem with class_weights not working with 3D outputs in tensorflow.\n",
    "# From: https://github.com/keras-team/keras/issues/3653\n",
    "def generate_sample_weights(training_data, class_weights): \n",
    "    #replaces values for up to 3 classes with the values from class_weights#\n",
    "    sample_weights = [np.where(y==0,class_weights[0],\n",
    "                        np.where(y==1,class_weights[1],\n",
    "                        y)) for y in training_data]\n",
    "    return np.asarray(sample_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dca14d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SSIM/PSNR loss functions.\n",
    "# Inspiration: https://stackoverflow.com/questions/57357146/use-ssim-loss-function-with-keras\n",
    "def ssim_loss(y_true, y_pred):\n",
    "    return 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, 1.0))\n",
    "\n",
    "def psnr_loss(y_true, y_pred):\n",
    "    return 100 - tf.reduce_mean(tf.image.psnr(y_true, y_pred, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "989693bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dice loss functions.\n",
    "## From: https://stackoverflow.com/questions/72195156/correct-implementation-of-dice-loss-in-tensorflow-keras\n",
    "#def dice_coef(y_true, y_pred, smooth=100):        \n",
    "#    y_true_f = tf.keras.backend.flatten(y_true)\n",
    "#    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
    "#    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
    "#    dice = (2. * intersection + smooth) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + smooth)\n",
    "#    return dice\n",
    "#\n",
    "#def dice_coef_loss(y_true, y_pred):\n",
    "#    return 1 - dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e94590cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dice loss \n",
    "# From: https://lars76.github.io/2018/09/27/loss-functions-for-segmentation.html\n",
    "def dice_loss(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.math.sigmoid(y_pred)\n",
    "    numerator = 2 * tf.reduce_sum(y_true * y_pred)\n",
    "    denominator = tf.reduce_sum(y_true + y_pred)\n",
    "\n",
    "    return 1 - numerator / denominator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48387d28",
   "metadata": {},
   "source": [
    "### Model Assembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5de60bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained fire encoder.\n",
    "fire_encoder = tf.keras.models.load_model('Models/MINST_Agg_01', custom_objects = {'ssim_loss': ssim_loss, 'psnr_loss': psnr_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f835ce22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained VGG16\n",
    "vgg = tf.keras.applications.VGG16(include_top=False, weights='imagenet', input_shape=(32,32,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb2db18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all layers of pretrained models.\n",
    "for t_layer in fire_encoder.layers:\n",
    "    t_layer.trainable = False\n",
    "#for t_layer in vgg.layers:\n",
    "#    t_layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93c63a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine fire_encoder with VGG16.\n",
    "fire_encoder.add(layers.Lambda(lambda x: tf.keras.backend.repeat_elements(x=x, rep=3, axis=-1)))\n",
    "for t_layer in vgg.layers[1:]:\n",
    "    fire_encoder.add(t_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b84ea20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract weights from VGG16 model.\n",
    "vgg_weights = []\n",
    "for t_layer in vgg.layers:\n",
    "    vgg_weights.append(t_layer.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fbb22b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert entire model to JSON and back to model so that the stranded VGG input layer is ignored.\n",
    "fm_json = fire_encoder.to_json()\n",
    "fire_encoder, vgg = None, None\n",
    "fire_encoder = tf.keras.models.model_from_json(fm_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9d7924d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put VGG weights back.\n",
    "for t_layer, t_weights in zip(fire_encoder.layers[5:], vgg_weights[1:]):\n",
    "    t_layer.set_weights(t_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e73984d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'block1_conv2'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combo_model.layers[7].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d75a9f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "upsample_filters = 512\n",
    "\n",
    "# Apply U-Net deconvolution to fire encoder.\n",
    "from_fire = layers.Conv2D(upsample_filters, (3,3), padding=\"same\", activation='relu', name='UpConv_1_A')(fire_encoder.output)\n",
    "x2 = layers.BatchNormalization()(from_fire)\n",
    "x2 = layers.Conv2D(upsample_filters, (3,3), padding=\"same\", activation='relu', name='UpConv_1_B')(x2)\n",
    "x2 = layers.BatchNormalization()(x2)\n",
    "x2 = layers.Conv2DTranspose(upsample_filters, (3,3), strides=(2,2), activation='relu', padding='same', name = 'UpConv_to2')(x2)\n",
    "x2 = layers.BatchNormalization()(x2)\n",
    "x2 = layers.concatenate([x2, fire_encoder.get_layer('block5_conv3').output])\n",
    "\n",
    "x2 = layers.Conv2D(upsample_filters, (3,3), padding=\"same\", activation='relu', name='UpConv_2_A')(x2)\n",
    "x2 = layers.BatchNormalization()(x2)\n",
    "x2 = layers.Conv2D(upsample_filters, (3,3), padding=\"same\", activation='relu', name='UpConv_2_B')(x2)\n",
    "x2 = layers.BatchNormalization()(x2)\n",
    "x2 = layers.Conv2DTranspose(upsample_filters, (3,3), strides=(2,2), activation='relu', padding='same', name = 'UpConv_to4')(x2)\n",
    "x2 = layers.BatchNormalization()(x2)\n",
    "x2 = layers.concatenate([x2, fire_encoder.get_layer('block4_conv3').output])\n",
    "\n",
    "x2 = layers.Conv2D(upsample_filters // 2, (3,3), padding=\"same\", activation='relu', name='UpConv_3_A')(x2)\n",
    "x2 = layers.BatchNormalization()(x2)\n",
    "x2 = layers.Conv2D(upsample_filters // 2, (3,3), padding=\"same\", activation='relu', name='UpConv_3_B')(x2)\n",
    "x2 = layers.BatchNormalization()(x2)\n",
    "x2 = layers.Conv2DTranspose(upsample_filters // 2, (3,3), strides=(2,2), activation='relu', padding='same', name = 'UpConv_to8')(x2)\n",
    "x2 = layers.BatchNormalization()(x2)\n",
    "x2 = layers.concatenate([x2, fire_encoder.get_layer('block3_conv3').output])\n",
    "\n",
    "x2 = layers.Conv2D(upsample_filters // 4, (3,3), padding=\"same\", activation='relu', name='UpConv_4_A')(x2)\n",
    "x2 = layers.BatchNormalization()(x2)\n",
    "x2 = layers.Conv2D(upsample_filters // 4, (3,3), padding=\"same\", activation='relu', name='UpConv_4_B')(x2)\n",
    "x2 = layers.BatchNormalization()(x2)\n",
    "x2 = layers.Conv2DTranspose(upsample_filters // 4, (3,3), strides=(2,2), activation='relu', padding='same', name = 'UpConv_to16')(x2)\n",
    "x2 = layers.BatchNormalization()(x2)\n",
    "x2 = layers.concatenate([x2, fire_encoder.get_layer('block2_conv2').output])\n",
    "\n",
    "x2 = layers.Conv2D(upsample_filters // 8, (3,3), padding=\"same\", activation='relu', name='UpConv_5_A')(x2)\n",
    "x2 = layers.BatchNormalization()(x2)\n",
    "x2 = layers.Conv2D(upsample_filters // 8, (3,3), padding=\"same\", activation='relu', name='UpConv_5_B')(x2)\n",
    "x2 = layers.BatchNormalization()(x2)\n",
    "x2 = layers.Conv2DTranspose(upsample_filters // 8, (3,3), strides=(2,2), activation='relu', padding='same', name = 'UpConv_to32')(x2)\n",
    "x2 = layers.BatchNormalization()(x2)\n",
    "x2 = layers.concatenate([x2, fire_encoder.get_layer('block1_conv2').output])\n",
    "\n",
    "x2 = layers.Conv2D(upsample_filters // 16, (3,3), padding=\"same\", activation='relu', name='TopConv_A')(x2)\n",
    "x2 = layers.BatchNormalization()(x2)\n",
    "x2 = layers.Conv2D(1, (3,3), padding=\"same\", activation='sigmoid', name='TopConv_B')(x2)\n",
    "output = layers.BatchNormalization(name = 'unet_output')(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03e82254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"combo_model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " fire_input (InputLayer)        [(None, 10, 32, 32,  0           []                               \n",
      "                                 1)]                                                              \n",
      "                                                                                                  \n",
      " fire_time_feature_1 (ConvLSTM2  (None, 10, 32, 32,   1651712    ['fire_input[0][0]']             \n",
      " D)                             128)                                                              \n",
      "                                                                                                  \n",
      " fire_time_feature_2 (ConvLSTM2  (None, 10, 32, 32,   442624     ['fire_time_feature_1[0][0]']    \n",
      " D)                             64)                                                               \n",
      "                                                                                                  \n",
      " fire_to_2D (ConvLSTM2D)        (None, 32, 32, 64)   33024       ['fire_time_feature_2[0][0]']    \n",
      "                                                                                                  \n",
      " output (Conv2D)                (None, 32, 32, 1)    65          ['fire_to_2D[0][0]']             \n",
      "                                                                                                  \n",
      " lambda (Lambda)                (None, 32, 32, 3)    0           ['output[0][0]']                 \n",
      "                                                                                                  \n",
      " block1_conv1 (Conv2D)          (None, 32, 32, 64)   1792        ['lambda[0][0]']                 \n",
      "                                                                                                  \n",
      " block1_conv2 (Conv2D)          (None, 32, 32, 64)   36928       ['block1_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " block1_pool (MaxPooling2D)     (None, 16, 16, 64)   0           ['block1_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " block2_conv1 (Conv2D)          (None, 16, 16, 128)  73856       ['block1_pool[0][0]']            \n",
      "                                                                                                  \n",
      " block2_conv2 (Conv2D)          (None, 16, 16, 128)  147584      ['block2_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " block2_pool (MaxPooling2D)     (None, 8, 8, 128)    0           ['block2_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " block3_conv1 (Conv2D)          (None, 8, 8, 256)    295168      ['block2_pool[0][0]']            \n",
      "                                                                                                  \n",
      " block3_conv2 (Conv2D)          (None, 8, 8, 256)    590080      ['block3_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " block3_conv3 (Conv2D)          (None, 8, 8, 256)    590080      ['block3_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " block3_pool (MaxPooling2D)     (None, 4, 4, 256)    0           ['block3_conv3[0][0]']           \n",
      "                                                                                                  \n",
      " block4_conv1 (Conv2D)          (None, 4, 4, 512)    1180160     ['block3_pool[0][0]']            \n",
      "                                                                                                  \n",
      " block4_conv2 (Conv2D)          (None, 4, 4, 512)    2359808     ['block4_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " block4_conv3 (Conv2D)          (None, 4, 4, 512)    2359808     ['block4_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " block4_pool (MaxPooling2D)     (None, 2, 2, 512)    0           ['block4_conv3[0][0]']           \n",
      "                                                                                                  \n",
      " block5_conv1 (Conv2D)          (None, 2, 2, 512)    2359808     ['block4_pool[0][0]']            \n",
      "                                                                                                  \n",
      " block5_conv2 (Conv2D)          (None, 2, 2, 512)    2359808     ['block5_conv1[0][0]']           \n",
      "                                                                                                  \n",
      " block5_conv3 (Conv2D)          (None, 2, 2, 512)    2359808     ['block5_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " block5_pool (MaxPooling2D)     (None, 1, 1, 512)    0           ['block5_conv3[0][0]']           \n",
      "                                                                                                  \n",
      " UpConv_1_A (Conv2D)            (None, 1, 1, 512)    2359808     ['block5_pool[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1, 1, 512)   2048        ['UpConv_1_A[0][0]']             \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " UpConv_1_B (Conv2D)            (None, 1, 1, 512)    2359808     ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 1, 1, 512)   2048        ['UpConv_1_B[0][0]']             \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " UpConv_to2 (Conv2DTranspose)   (None, 2, 2, 512)    2359808     ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 2, 2, 512)   2048        ['UpConv_to2[0][0]']             \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 2, 2, 1024)   0           ['batch_normalization_2[0][0]',  \n",
      "                                                                  'block5_conv3[0][0]']           \n",
      "                                                                                                  \n",
      " UpConv_2_A (Conv2D)            (None, 2, 2, 512)    4719104     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 2, 2, 512)   2048        ['UpConv_2_A[0][0]']             \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " UpConv_2_B (Conv2D)            (None, 2, 2, 512)    2359808     ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 2, 2, 512)   2048        ['UpConv_2_B[0][0]']             \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " UpConv_to4 (Conv2DTranspose)   (None, 4, 4, 512)    2359808     ['batch_normalization_4[0][0]']  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 4, 4, 512)   2048        ['UpConv_to4[0][0]']             \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 4, 4, 1024)   0           ['batch_normalization_5[0][0]',  \n",
      "                                                                  'block4_conv3[0][0]']           \n",
      "                                                                                                  \n",
      " UpConv_3_A (Conv2D)            (None, 4, 4, 256)    2359552     ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 4, 4, 256)   1024        ['UpConv_3_A[0][0]']             \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " UpConv_3_B (Conv2D)            (None, 4, 4, 256)    590080      ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 4, 4, 256)   1024        ['UpConv_3_B[0][0]']             \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " UpConv_to8 (Conv2DTranspose)   (None, 8, 8, 256)    590080      ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 8, 8, 256)   1024        ['UpConv_to8[0][0]']             \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 8, 8, 512)    0           ['batch_normalization_8[0][0]',  \n",
      "                                                                  'block3_conv3[0][0]']           \n",
      "                                                                                                  \n",
      " UpConv_4_A (Conv2D)            (None, 8, 8, 128)    589952      ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 8, 8, 128)   512         ['UpConv_4_A[0][0]']             \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " UpConv_4_B (Conv2D)            (None, 8, 8, 128)    147584      ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 8, 8, 128)   512         ['UpConv_4_B[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " UpConv_to16 (Conv2DTranspose)  (None, 16, 16, 128)  147584      ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 16, 16, 128)  512        ['UpConv_to16[0][0]']            \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 16, 16, 256)  0           ['batch_normalization_11[0][0]', \n",
      "                                                                  'block2_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " UpConv_5_A (Conv2D)            (None, 16, 16, 64)   147520      ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 16, 16, 64)  256         ['UpConv_5_A[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " UpConv_5_B (Conv2D)            (None, 16, 16, 64)   36928       ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 16, 16, 64)  256         ['UpConv_5_B[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " UpConv_to32 (Conv2DTranspose)  (None, 32, 32, 64)   36928       ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 32, 32, 64)  256         ['UpConv_to32[0][0]']            \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 32, 32, 128)  0           ['batch_normalization_14[0][0]', \n",
      "                                                                  'block1_conv2[0][0]']           \n",
      "                                                                                                  \n",
      " TopConv_A (Conv2D)             (None, 32, 32, 32)   36896       ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 32, 32, 32)  128         ['TopConv_A[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " TopConv_B (Conv2D)             (None, 32, 32, 1)    289         ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " unet_output (BatchNormalizatio  (None, 32, 32, 1)   4           ['TopConv_B[0][0]']              \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 38,061,446\n",
      "Trainable params: 35,925,123\n",
      "Non-trainable params: 2,136,323\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "combo_model = tf.keras.Model(inputs = fire_encoder.input, outputs = output, name = 'combo_model')\n",
    "combo_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3df7f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model.\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "#loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "#loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "loss_fn = dice_loss\n",
    "combo_model.compile(loss=loss_fn, \n",
    "                    optimizer=opt, \n",
    "                    metrics=[tf.keras.metrics.MeanSquaredError(name='MSE'),\n",
    "                             tf.keras.metrics.AUC(name='AUC'),\n",
    "                             ssim_loss,\n",
    "                             psnr_loss\n",
    "                            ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8adc91c",
   "metadata": {},
   "source": [
    "### Pretrain full model on moving MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38a1a9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspiration: https://keras.io/examples/vision/conv_lstm/\n",
    "\n",
    "#Download and load the dataset.\n",
    "fpath = tf.keras.utils.get_file(\n",
    "    \"moving_mnist.npy\",\n",
    "    \"http://www.cs.toronto.edu/~nitish/unsupervised_video/mnist_test_seq.npy\",\n",
    ")\n",
    "dataset = np.load(fpath)\n",
    "\n",
    "# Swap the axes representing the number of frames and number of data samples.\n",
    "dataset = np.swapaxes(dataset, 0, 1)\n",
    "# Now we use the entire dataset.\n",
    "dataset = dataset#[1000:6000]\n",
    "# Add a channel dimension since the images are grayscale.\n",
    "dataset = np.expand_dims(dataset, axis=-1)\n",
    "\n",
    "# Split into train and validation sets using indexing to optimize memory.\n",
    "indexes = np.arange(dataset.shape[0])\n",
    "np.random.shuffle(indexes)\n",
    "train_index = indexes[: int(0.9 * dataset.shape[0])]\n",
    "val_index = indexes[int(0.9 * dataset.shape[0]) :]\n",
    "train_dataset = dataset[train_index]\n",
    "val_dataset = dataset[val_index]\n",
    "\n",
    "# Normalize the data to the 0-1 range.\n",
    "train_dataset = train_dataset / 255\n",
    "val_dataset = val_dataset / 255\n",
    "\n",
    "# Shift and stack frames.\n",
    "i,o = [],[]\n",
    "for f in range(0,10):\n",
    "    i.append(train_dataset[:,f:f+10])\n",
    "    o.append(train_dataset[:,f+10:f+11])\n",
    "    \n",
    "x_train = np.concatenate(i)\n",
    "y_train = np.squeeze(np.concatenate(o), axis=1)\n",
    "\n",
    "i,o = [],[]\n",
    "for f in range(0,10):\n",
    "    i.append(val_dataset[:,f:f+10])\n",
    "    o.append(val_dataset[:,f+10:f+11])\n",
    "    \n",
    "x_val = np.concatenate(i)\n",
    "y_val = np.squeeze(np.concatenate(o), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d68604a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "pooler = tf.keras.layers.MaxPool2D(pool_size=(2, 2))\n",
    "xt_pooled, yt_pooled, xv_pooled, yv_pooled = [],[],[],[]\n",
    "\n",
    "# Pool training set.\n",
    "for t in range(0,len(x_train),1000):\n",
    "    t_x_train = x_train[t:t+1000]\n",
    "    xt_pooled.append(layers.TimeDistributed(pooler, name = 'pool_to_32x32')(t_x_train).numpy())\n",
    "    t_y_train = y_train[t:t+1000]\n",
    "    yt_pooled.append(pooler(t_y_train).numpy())\n",
    "    \n",
    "# Pool validation set.\n",
    "for t in range(0,len(x_val),1000):\n",
    "    t_x_val = x_val[t:t+1000]\n",
    "    xv_pooled.append(layers.TimeDistributed(pooler, name = 'pool_to_32x32')(t_x_val).numpy())\n",
    "    t_y_val = y_val[t:t+1000]\n",
    "    yv_pooled.append(pooler(t_y_val).numpy())\n",
    "    \n",
    "# Stack\n",
    "x_train = np.concatenate(xt_pooled)\n",
    "y_train = np.concatenate(yt_pooled)\n",
    "x_val = np.concatenate(xv_pooled)\n",
    "y_val = np.concatenate(yv_pooled)\n",
    "\n",
    "# Shuffle each dataset in unison.\n",
    "# From: https://stackoverflow.com/questions/4601373/better-way-to-shuffle-two-numpy-arrays-in-unison\n",
    "randomize = np.arange(len(x_train))\n",
    "np.random.shuffle(randomize)\n",
    "x_train = x_train[randomize]\n",
    "y_train = y_train[randomize]\n",
    "\n",
    "randomize = np.arange(len(x_val))\n",
    "np.random.shuffle(randomize)\n",
    "x_val = x_val[randomize]\n",
    "y_val = y_val[randomize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b89184c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Throw out variables that will no longer be used to recover memory.\n",
    "train_dataset, val_dataset,train_index, val_index = None, None, None, None\n",
    "t_x_train, t_y_train, t_x_val, t_y_val = None, None, None, None\n",
    "xt_pooled, yt_pooled, xv_pooled, yv_pooled = None, None, None, None\n",
    "pooler, i, o, dataset = None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab056217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2304x576 with 11 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the dataset to make sure the shifting and shuffling operations worked properly.\n",
    "sample_idx = np.random.randint(0, len(x_train))\n",
    "fig, axes = plt.subplots(1, 11, figsize=(32, 8))\n",
    "\n",
    "# Plot the fire frames.\n",
    "for idx, ax in enumerate(axes):\n",
    "    if idx == 10:\n",
    "        ax.imshow(np.squeeze(y_train[sample_idx]), cmap=\"gray\")\n",
    "    else:\n",
    "        ax.imshow(np.squeeze(x_train[sample_idx][idx]), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01d145ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a simple generator\n",
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        return batch_x, batch_y\n",
    "\n",
    "batch_size = 32\n",
    "train_gen = DataGenerator(x_train, y_train, batch_size)\n",
    "val_gen = DataGenerator(x_val, y_val, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7fbfaf3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1266/2813 [============>.................] - ETA: 4:33 - loss: 0.7782 - MSE: 3.0744 - AUC: 0.7446 - ssim_loss: 0.9913 - psnr_loss: 104.3012"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23376/4263007037.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mreduce_lr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mReduceLROnPlateau\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m combo_model.fit(train_gen,\n\u001b[0m\u001b[0;32m      6\u001b[0m                    \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m                    \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1562\u001b[0m                         ):\n\u001b[0;32m   1563\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1564\u001b[1;33m                             \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1565\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1566\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2494\u001b[0m       (graph_function,\n\u001b[0;32m   2495\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2497\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2498\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1860\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1861\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1862\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1863\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1864\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define some callbacks to improve training.\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights = True, verbose = 1)\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', patience=2, verbose = 1)\n",
    "\n",
    "combo_model.fit(train_gen,\n",
    "                   epochs = 10, \n",
    "                   verbose = 1, \n",
    "                   batch_size = batch_size,\n",
    "                   validation_data = val_gen,\n",
    "                   callbacks = [early_stopping, reduce_lr],\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9bd6770a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 31). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Models/Combo_Rough_001\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Models/Combo_Rough_001\\assets\n"
     ]
    }
   ],
   "source": [
    "combo_model.save('Models/Combo_Rough_001')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024717a4",
   "metadata": {},
   "source": [
    "### Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47bf98fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 46s 145ms/step\n"
     ]
    }
   ],
   "source": [
    "t_preds = combo_model.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4376bd11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x269fe6007c0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2304x576 with 11 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2304x1152 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_idx = np.random.randint(0, len(x_val))\n",
    "\n",
    "# Construct a figure for the original and new frames.\n",
    "fig, axes = plt.subplots(1, 11, figsize=(32, 8))\n",
    "\n",
    "# Plot the fire frames.\n",
    "for idx, ax in enumerate(axes):\n",
    "    if idx == 10:\n",
    "        ax.imshow(np.squeeze(y_val[sample_idx]), cmap=\"gray\")\n",
    "    else:\n",
    "        ax.imshow(np.squeeze(x_val[sample_idx][idx]), cmap=\"gray\")\n",
    "    #ax.set_title(f\"F Frame {idx + 1}\")\n",
    "    #ax.axis(\"off\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(32, 16))\n",
    "axes[0].imshow(np.squeeze(x_val[sample_idx][9]), cmap=\"gray\")\n",
    "axes[1].imshow(np.squeeze(t_preds[sample_idx]), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a1233e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Prediction Report\n",
      "SSIM: 0.0068119196\n",
      "PSNR: -0.07871980667114258\n",
      "MSE: 6.127059\n"
     ]
    }
   ],
   "source": [
    "# Compute and show set scores.\n",
    "set_ssim = tf.image.ssim(tf.cast(y_val, dtype='float32'), t_preds, 1.0)\n",
    "set_psnr = tf.image.psnr(tf.cast(y_val, dtype='float32'), t_preds, 1.0)\n",
    "set_mse = tf.keras.metrics.mean_squared_error(y_val, t_preds)\n",
    "print('Model Prediction Report')\n",
    "print('SSIM:', np.mean(set_ssim))\n",
    "print('PSNR:', np.mean(set_psnr) / 100)\n",
    "print('MSE:', np.mean(set_mse))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
