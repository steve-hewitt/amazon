{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.initializers import Constant\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for available GPU.\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loader functions\n",
    "# Inspiration: https://towardsdatascience.com/writing-custom-keras-generators-fe815d992c5a\n",
    "\n",
    "def get_input(path):\n",
    "    # Load array.\n",
    "    t_input = np.load(path)\n",
    "    # Pad to even number of pixels\n",
    "    t_input = np.pad(t_input, [(0,0),(0,1),(0,1)])\n",
    "    # Resize to include a channel dimension.\n",
    "    t_input = tf.expand_dims(t_input, axis = -1)\n",
    "    return t_input\n",
    "\n",
    "def get_output(path):\n",
    "    # Load array.\n",
    "    t_output = np.load(path)\n",
    "    # Pad to even number of pixels\n",
    "    t_output = np.pad(t_output, [(0,0),(0,1),(0,1)])\n",
    "    # Resize to include a channel dimension.\n",
    "    t_output = tf.expand_dims(t_output, axis = -1)\n",
    "    return t_output\n",
    "\n",
    "def data_generator(samples, batch_size = 64):\n",
    "    \n",
    "    while True:\n",
    "        # Select files (paths/indices) for the batch\n",
    "        batch_samples  = np.random.choice(a = samples.index, \n",
    "                                      size = batch_size)\n",
    "        batch_input  = []\n",
    "        batch_output = [] \n",
    "\n",
    "        # Read in each input, perform preprocessing and get labels\n",
    "        for sample in batch_samples:\n",
    "          input = get_input(samples.loc[sample].features)\n",
    "          output = get_output(samples.loc[sample].labels)\n",
    "\n",
    "          batch_input += [input]\n",
    "          batch_output += [output]\n",
    "        # Return a tuple of (input, output) to feed the network\n",
    "        batch_x = np.array(batch_input)\n",
    "        batch_y = np.array(batch_output)\n",
    "        \n",
    "        yield(batch_x, batch_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Lon</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Date</th>\n",
       "      <th>features</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>356962</td>\n",
       "      <td>-53.345535</td>\n",
       "      <td>-6.535028</td>\n",
       "      <td>2017-07-30</td>\n",
       "      <td>Sample_CLSTM_Dataset/train/features/356962.npy</td>\n",
       "      <td>Sample_CLSTM_Dataset/train/labels/356962.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>546517</td>\n",
       "      <td>-47.329685</td>\n",
       "      <td>-8.260676</td>\n",
       "      <td>2017-08-20</td>\n",
       "      <td>Sample_CLSTM_Dataset/train/features/546517.npy</td>\n",
       "      <td>Sample_CLSTM_Dataset/train/labels/546517.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>799359</td>\n",
       "      <td>-50.967861</td>\n",
       "      <td>-8.255809</td>\n",
       "      <td>2017-09-04</td>\n",
       "      <td>Sample_CLSTM_Dataset/train/features/799359.npy</td>\n",
       "      <td>Sample_CLSTM_Dataset/train/labels/799359.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>714590</td>\n",
       "      <td>-66.144379</td>\n",
       "      <td>-12.624272</td>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>Sample_CLSTM_Dataset/train/features/714590.npy</td>\n",
       "      <td>Sample_CLSTM_Dataset/train/labels/714590.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>240012</td>\n",
       "      <td>-48.350338</td>\n",
       "      <td>-11.838207</td>\n",
       "      <td>2017-07-14</td>\n",
       "      <td>Sample_CLSTM_Dataset/train/features/240012.npy</td>\n",
       "      <td>Sample_CLSTM_Dataset/train/labels/240012.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6491</th>\n",
       "      <td>173827</td>\n",
       "      <td>-54.326607</td>\n",
       "      <td>-11.983384</td>\n",
       "      <td>2017-06-20</td>\n",
       "      <td>Sample_CLSTM_Dataset/train/features/173827.npy</td>\n",
       "      <td>Sample_CLSTM_Dataset/train/labels/173827.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6492</th>\n",
       "      <td>1377764</td>\n",
       "      <td>-47.425915</td>\n",
       "      <td>-7.486426</td>\n",
       "      <td>2017-09-26</td>\n",
       "      <td>Sample_CLSTM_Dataset/train/features/1377764.npy</td>\n",
       "      <td>Sample_CLSTM_Dataset/train/labels/1377764.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6493</th>\n",
       "      <td>1444041</td>\n",
       "      <td>-65.172768</td>\n",
       "      <td>-10.714162</td>\n",
       "      <td>2017-10-02</td>\n",
       "      <td>Sample_CLSTM_Dataset/train/features/1444041.npy</td>\n",
       "      <td>Sample_CLSTM_Dataset/train/labels/1444041.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6494</th>\n",
       "      <td>644793</td>\n",
       "      <td>-53.701656</td>\n",
       "      <td>-15.977278</td>\n",
       "      <td>2017-08-27</td>\n",
       "      <td>Sample_CLSTM_Dataset/train/features/644793.npy</td>\n",
       "      <td>Sample_CLSTM_Dataset/train/labels/644793.npy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6495</th>\n",
       "      <td>1780752</td>\n",
       "      <td>-51.322929</td>\n",
       "      <td>-3.104345</td>\n",
       "      <td>2017-10-25</td>\n",
       "      <td>Sample_CLSTM_Dataset/train/features/1780752.npy</td>\n",
       "      <td>Sample_CLSTM_Dataset/train/labels/1780752.npy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6496 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0        Lon        Lat        Date  \\\n",
       "0         356962 -53.345535  -6.535028  2017-07-30   \n",
       "1         546517 -47.329685  -8.260676  2017-08-20   \n",
       "2         799359 -50.967861  -8.255809  2017-09-04   \n",
       "3         714590 -66.144379 -12.624272  2017-08-31   \n",
       "4         240012 -48.350338 -11.838207  2017-07-14   \n",
       "...          ...        ...        ...         ...   \n",
       "6491      173827 -54.326607 -11.983384  2017-06-20   \n",
       "6492     1377764 -47.425915  -7.486426  2017-09-26   \n",
       "6493     1444041 -65.172768 -10.714162  2017-10-02   \n",
       "6494      644793 -53.701656 -15.977278  2017-08-27   \n",
       "6495     1780752 -51.322929  -3.104345  2017-10-25   \n",
       "\n",
       "                                             features  \\\n",
       "0      Sample_CLSTM_Dataset/train/features/356962.npy   \n",
       "1      Sample_CLSTM_Dataset/train/features/546517.npy   \n",
       "2      Sample_CLSTM_Dataset/train/features/799359.npy   \n",
       "3      Sample_CLSTM_Dataset/train/features/714590.npy   \n",
       "4      Sample_CLSTM_Dataset/train/features/240012.npy   \n",
       "...                                               ...   \n",
       "6491   Sample_CLSTM_Dataset/train/features/173827.npy   \n",
       "6492  Sample_CLSTM_Dataset/train/features/1377764.npy   \n",
       "6493  Sample_CLSTM_Dataset/train/features/1444041.npy   \n",
       "6494   Sample_CLSTM_Dataset/train/features/644793.npy   \n",
       "6495  Sample_CLSTM_Dataset/train/features/1780752.npy   \n",
       "\n",
       "                                             labels  \n",
       "0      Sample_CLSTM_Dataset/train/labels/356962.npy  \n",
       "1      Sample_CLSTM_Dataset/train/labels/546517.npy  \n",
       "2      Sample_CLSTM_Dataset/train/labels/799359.npy  \n",
       "3      Sample_CLSTM_Dataset/train/labels/714590.npy  \n",
       "4      Sample_CLSTM_Dataset/train/labels/240012.npy  \n",
       "...                                             ...  \n",
       "6491   Sample_CLSTM_Dataset/train/labels/173827.npy  \n",
       "6492  Sample_CLSTM_Dataset/train/labels/1377764.npy  \n",
       "6493  Sample_CLSTM_Dataset/train/labels/1444041.npy  \n",
       "6494   Sample_CLSTM_Dataset/train/labels/644793.npy  \n",
       "6495  Sample_CLSTM_Dataset/train/labels/1780752.npy  \n",
       "\n",
       "[6496 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = pd.read_csv('Sample_CLSTM_Dataset/train/meta.csv')\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 10, 32, 32, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get data from one chip\n",
    "sample_input = np.load('Sample_CLSTM_Dataset/train/features/3243.npy')\n",
    "\n",
    "# Pad to even number of pixels\n",
    "a = np.pad(sample_input, [(0,0),(0,1),(0,1)])\n",
    "# Resize to include a channel dimension.\n",
    "a = tf.expand_dims(a, axis = -1)\n",
    "# Resize to include a batch dimension.\n",
    "a = tf.expand_dims(a, axis = 0)\n",
    "# Display shape for verification.\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model assumbly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspired by: https://keras.io/examples/vision/conv_lstm/?fbclid=IwAR1QSJmF0bcz5pklHDHwl4mUi8inzHN4m8Zk6OpvVJizqDDv2-MKMq3LlJ8\n",
    "\n",
    "inputs = layers.Input(shape=((10,32,32,1)))\n",
    "x = layers.ConvLSTM2D(\n",
    "    filters=128,\n",
    "    kernel_size=(5, 5),\n",
    "    padding='same',\n",
    "    return_sequences=True,\n",
    "    activation='relu',\n",
    ")(inputs)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ConvLSTM2D(\n",
    "    filters=128,\n",
    "    kernel_size=(3, 3),\n",
    "    padding='same',\n",
    "    return_sequences=True,\n",
    "    activation='relu',\n",
    ")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ConvLSTM2D(\n",
    "    filters=128,\n",
    "    kernel_size=(1, 1),\n",
    "    padding='same',\n",
    "    return_sequences=True,\n",
    "    activation='relu',\n",
    ")(x)\n",
    "outputs = layers.Conv3D(\n",
    "    filters=1, kernel_size=(3, 3, 3), activation='sigmoid', padding='same'\n",
    ")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_model = tf.keras.Model(inputs, outputs, name=\"Conv_LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 10, 32, 32, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify output shape.\n",
    "forecast_model.predict(a).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Conv_LSTM\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 10, 32, 32, 1)]   0         \n",
      "                                                                 \n",
      " conv_lstm2d (ConvLSTM2D)    (None, 10, 32, 32, 128)   1651712   \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 10, 32, 32, 128)  512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv_lstm2d_1 (ConvLSTM2D)  (None, 10, 32, 32, 128)   1180160   \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 10, 32, 32, 128)  512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv_lstm2d_2 (ConvLSTM2D)  (None, 10, 32, 32, 128)   131584    \n",
      "                                                                 \n",
      " conv3d (Conv3D)             (None, 10, 32, 32, 1)     3457      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,967,937\n",
      "Trainable params: 2,967,425\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Display model details.\n",
    "forecast_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model.\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
    "forecast_model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loaders.\n",
    "batch_size = 64\n",
    "meta_t = pd.read_csv('Sample_CLSTM_Dataset/train/meta.csv')\n",
    "meta_v = pd.read_csv('Sample_CLSTM_Dataset/val/meta.csv')\n",
    "t_gen = data_generator(meta_t, batch_size = batch_size)\n",
    "v_gen = data_generator(meta_v, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying new approach to build dataset.\n",
    "x_train, y_train, x_val, y_val = [],[],[],[]\n",
    "\n",
    "# Iterate over dataset.\n",
    "for x in range(0,len(meta_t)):\n",
    "    x_train.append(np.load(meta_t.iloc[x].features))\n",
    "    y_train.append(np.load(meta_t.iloc[x].labels))\n",
    "for x in range(0,len(meta_v)):\n",
    "    x_val.append(np.load(meta_v.iloc[x].features))\n",
    "    y_val.append(np.load(meta_v.iloc[x].labels))\n",
    "    \n",
    "# Stack layers.\n",
    "x_train = np.stack(x_train)\n",
    "y_train = np.stack(y_train)\n",
    "x_val = np.stack(x_val)\n",
    "y_val = np.stack(y_val)\n",
    "\n",
    "# Convert values > 1 to 1.\n",
    "x_train = np.minimum(x_train,1)\n",
    "y_train = np.minimum(y_train,1)\n",
    "x_val = np.minimum(x_val,1)\n",
    "y_val = np.minimum(y_val,1)\n",
    "\n",
    "# Pad to even shape.\n",
    "x_train = np.pad(x_train, [(0,0),(0,0),(0,1),(0,1)])\n",
    "y_train = np.pad(y_train, [(0,0),(0,0),(0,1),(0,1)])\n",
    "x_val = np.pad(x_val, [(0,0),(0,0),(0,1),(0,1)])\n",
    "y_val = np.pad(y_val, [(0,0),(0,0),(0,1),(0,1)])\n",
    "\n",
    "# Add color channel dim.\n",
    "x_train = tf.expand_dims(x_train, axis = -1)\n",
    "y_train = tf.expand_dims(y_train, axis = -1)\n",
    "x_val = tf.expand_dims(x_val, axis = -1)\n",
    "y_val = tf.expand_dims(y_val, axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution for problem with class_weights not working with 3D outputs in tensorflow.\n",
    "# From: https://github.com/keras-team/keras/issues/3653\n",
    "def generate_sample_weights(training_data, class_weights): \n",
    "    #replaces values for up to 3 classes with the values from class_weights#\n",
    "    sample_weights = [np.where(y==0,class_weights[0],\n",
    "                        np.where(y==1,class_weights[1],\n",
    "                        y)) for y in training_data]\n",
    "    return np.asarray(sample_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\covad\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass classes=[0, 1], y=[0. 0. 0. ... 0. 0. 0.] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  0.50098477, 254.3651868 ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get class weights for weighted binary cross entropy loss.\n",
    "weights = class_weight.compute_class_weight('balanced',\n",
    "                                            [0,1],\n",
    "                                            y_train.numpy().flatten())\n",
    "# Examine weights.\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculated_sample_weights = generate_sample_weights(y_train, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "406/406 [==============================] - 148s 356ms/step - loss: 0.6667 - accuracy: 0.7042 - val_loss: 0.7337 - val_accuracy: 0.0980 - lr: 1.0000e-05\n",
      "Epoch 2/50\n",
      "406/406 [==============================] - 144s 355ms/step - loss: 0.6131 - accuracy: 0.6843 - val_loss: 0.6398 - val_accuracy: 0.7004 - lr: 1.0000e-05\n",
      "Epoch 3/50\n",
      "406/406 [==============================] - 147s 362ms/step - loss: 0.5940 - accuracy: 0.6898 - val_loss: 0.6341 - val_accuracy: 0.7043 - lr: 1.0000e-05\n",
      "Epoch 4/50\n",
      "406/406 [==============================] - 146s 361ms/step - loss: 0.5883 - accuracy: 0.6901 - val_loss: 0.5650 - val_accuracy: 0.7329 - lr: 1.0000e-05\n",
      "Epoch 5/50\n",
      "406/406 [==============================] - 147s 361ms/step - loss: 0.5855 - accuracy: 0.6950 - val_loss: 0.5964 - val_accuracy: 0.7265 - lr: 1.0000e-05\n",
      "Epoch 6/50\n",
      "406/406 [==============================] - 146s 360ms/step - loss: 0.5840 - accuracy: 0.6905 - val_loss: 0.5815 - val_accuracy: 0.7934 - lr: 1.0000e-05\n",
      "Epoch 7/50\n",
      "406/406 [==============================] - 146s 361ms/step - loss: 0.5829 - accuracy: 0.6962 - val_loss: 0.5290 - val_accuracy: 0.7438 - lr: 1.0000e-05\n",
      "Epoch 8/50\n",
      "406/406 [==============================] - 146s 359ms/step - loss: 0.5817 - accuracy: 0.6851 - val_loss: 0.5857 - val_accuracy: 0.6686 - lr: 1.0000e-05\n",
      "Epoch 9/50\n",
      "406/406 [==============================] - 144s 354ms/step - loss: 0.5812 - accuracy: 0.6959 - val_loss: 0.5965 - val_accuracy: 0.7267 - lr: 1.0000e-05\n",
      "Epoch 10/50\n",
      "406/406 [==============================] - 144s 354ms/step - loss: 0.5807 - accuracy: 0.6897 - val_loss: 0.6163 - val_accuracy: 0.6251 - lr: 1.0000e-05\n",
      "Epoch 11/50\n",
      "406/406 [==============================] - 144s 354ms/step - loss: 0.5797 - accuracy: 0.6976 - val_loss: 0.6085 - val_accuracy: 0.7211 - lr: 1.0000e-05\n",
      "Epoch 12/50\n",
      "406/406 [==============================] - 144s 354ms/step - loss: 0.5799 - accuracy: 0.6960 - val_loss: 0.5619 - val_accuracy: 0.7393 - lr: 1.0000e-05\n",
      "Epoch 13/50\n",
      "406/406 [==============================] - 143s 353ms/step - loss: 0.5778 - accuracy: 0.7203 - val_loss: 0.5898 - val_accuracy: 0.7276 - lr: 1.0000e-06\n",
      "Epoch 14/50\n",
      "406/406 [==============================] - 143s 353ms/step - loss: 0.5776 - accuracy: 0.7191 - val_loss: 0.5753 - val_accuracy: 0.7312 - lr: 1.0000e-06\n",
      "Epoch 15/50\n",
      "406/406 [==============================] - 143s 353ms/step - loss: 0.5775 - accuracy: 0.7184 - val_loss: 0.5752 - val_accuracy: 0.7305 - lr: 1.0000e-06\n",
      "Epoch 16/50\n",
      "406/406 [==============================] - 143s 353ms/step - loss: 0.5776 - accuracy: 0.7136 - val_loss: 0.5803 - val_accuracy: 0.7291 - lr: 1.0000e-06\n",
      "Epoch 17/50\n",
      "406/406 [==============================] - 143s 353ms/step - loss: 0.5774 - accuracy: 0.7139 - val_loss: 0.5771 - val_accuracy: 0.7305 - lr: 1.0000e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x210cbc82910>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Params\n",
    "batch_size = 16\n",
    "\n",
    "# Adding callbacks.\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=5)\n",
    "\n",
    "# Train model.\n",
    "forecast_model.fit(x_train,\n",
    "                   y_train,\n",
    "                   epochs = 50, \n",
    "                   verbose = 1, \n",
    "                   batch_size = batch_size,\n",
    "                   validation_data = (x_val, y_val),\n",
    "                   callbacks = [early_stopping, reduce_lr],\n",
    "                   sample_weight = calculated_sample_weights\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Models/010\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Models/010\\assets\n"
     ]
    }
   ],
   "source": [
    "# Save trained model.\n",
    "forecast_model.save('Models/010')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_model = tf.keras.models.load_model('Models/010')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine how model is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n"
     ]
    }
   ],
   "source": [
    "# Select a random example from the validation dataset.\n",
    "example = np.random.choice(range(len(x_val)), size=1)[0]\n",
    "\n",
    "# Pick the first/last ten frames from the example.\n",
    "feature_frames = x_val[example, ...]\n",
    "label_frames = y_val[example, ...]\n",
    "pred_frames = []\n",
    "\n",
    "# Predict a new set of 10 frames.\n",
    "for _ in range(10):\n",
    "    # Extract the model's prediction and post-process it.\n",
    "    new_prediction = forecast_model.predict(np.expand_dims(feature_frames, axis=0))\n",
    "    new_prediction = np.squeeze(new_prediction, axis=0)\n",
    "    predicted_frame = np.expand_dims(new_prediction[-1, ...], axis=0)\n",
    "    pred_frames.append(predicted_frame)\n",
    "    \n",
    "\n",
    "# Extend the set of prediction frames.\n",
    "pred_frames = np.concatenate(pred_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape verification.\n",
    "feature_frames.shape == label_frames.shape == pred_frames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x576 with 30 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Construct a figure for the original and new frames.\n",
    "fig, axes = plt.subplots(3, 10, figsize=(30, 8))\n",
    "\n",
    "# Plot the feature frames.\n",
    "for idx, ax in enumerate(axes[0]):\n",
    "    ax.imshow(np.squeeze(feature_frames[idx]), cmap=\"gray\")\n",
    "    ax.set_title(f\"F Frame {idx + 1}\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "# Plot the label frames.\n",
    "for idx, ax in enumerate(axes[1]):\n",
    "    ax.imshow(np.squeeze(label_frames[idx]), cmap=\"gray\")\n",
    "    ax.set_title(f\"L Frame {idx + 11}\")\n",
    "    ax.axis(\"off\")\n",
    "    \n",
    "# Plot the predicted frames.\n",
    "for idx, ax in enumerate(axes[2]):\n",
    "    ax.imshow(np.squeeze(pred_frames[idx]), cmap=\"gray\")\n",
    "    ax.set_title(f\"P Frame {idx + 11}\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "# Display the figure.\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
